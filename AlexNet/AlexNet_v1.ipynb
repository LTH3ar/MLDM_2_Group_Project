{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a5c64051bd059b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchmetrics import Accuracy\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.286926956Z",
     "start_time": "2024-01-03T05:42:59.252116479Z"
    }
   },
   "id": "initial_id",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Setting Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b57f7f91e5c6b06a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.300237168Z",
     "start_time": "2024-01-03T05:42:59.288902445Z"
    }
   },
   "id": "47189a400c9fa3c7",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Preparing Input Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c05cef9cb03b952"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preparing Input Data\n",
    "# prepare the dataset MNIST(1x28x28) -> (3x224x224) for AlexNet\n",
    "# Upscale the grayscale images to RGB size\n",
    "upscale_transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.1307], std=[0.3081])  # Normalize to [-1, 1] range\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.300603501Z",
     "start_time": "2024-01-03T05:42:59.298861294Z"
    }
   },
   "id": "43eb54b34ab07e86",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val_dataset length: 60000\n",
      "test_dataset length: 10000\n",
      "train_val_dataset shape: torch.Size([3, 227, 227])\n",
      "test_dataset shape: torch.Size([3, 227, 227])\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "train_val_dataset = datasets.MNIST(root='./dataset', train=True, transform=upscale_transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./dataset', train=False, transform=upscale_transform, download=True)\n",
    "\n",
    "# Dataset summary\n",
    "print('train_val_dataset length:', len(train_val_dataset))\n",
    "print('test_dataset length:', len(test_dataset))\n",
    "print('train_val_dataset shape:', train_val_dataset[0][0].shape)\n",
    "print('test_dataset shape:', test_dataset[0][0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.382428633Z",
     "start_time": "2024-01-03T05:42:59.298944231Z"
    }
   },
   "id": "54b4b930857f8cff",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset length: 48000\n",
      "val_dataset length: 12000\n",
      "test_dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and validation\n",
    "train_size = int(0.8 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "# Dataset summary\n",
    "print('train_dataset length:', len(train_dataset))\n",
    "print('val_dataset length:', len(val_dataset))\n",
    "print('test_dataset length:', len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.406806433Z",
     "start_time": "2024-01-03T05:42:59.362960696Z"
    }
   },
   "id": "e37052e65ce41d98",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader length: 375\n",
      "val_loader length: 94\n",
      "test_loader length: 79\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 128\n",
    "elif torch.backends.mps.is_available():\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# dataloaders summary\n",
    "print('train_loader length:', len(train_loader))\n",
    "print('val_loader length:', len(val_loader))\n",
    "print('test_loader length:', len(test_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.407352176Z",
     "start_time": "2024-01-03T05:42:59.403853745Z"
    }
   },
   "id": "2408fdd9969a3431",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Defining Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b4a9d85fc9feec9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the model AlexNet specific for the transformed MNIST\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # ============================================================================== #\n",
    "            # 1st conv layer\n",
    "            # input: 3x224x224 (upscaled from 1x28x28)\n",
    "            # output: 96x55x55\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0, ),\n",
    "            # activation function: ReLU\n",
    "            nn.ReLU(),\n",
    "            # max pooling layer with kernel size 3 and stride 2\n",
    "            # output: 96x27x27\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # 2nd conv layer\n",
    "            # input: 96x27x27\n",
    "            # output: 256x27x27\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "            # activation function: ReLU\n",
    "            nn.ReLU(),\n",
    "            # max pooling layer with kernel size 3 and stride 2\n",
    "            # output: 256x13x13\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # 3rd conv layer\n",
    "            # input: 256x13x13\n",
    "            # output: 384x13x13\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            # activation function: ReLU\n",
    "            nn.ReLU(),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # 4th conv layer\n",
    "            # input: 384x13x13\n",
    "            # output: 384x13x13\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            # activation function: ReLU\n",
    "            nn.ReLU(),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # 5th conv layer\n",
    "            # input: 384x13x13\n",
    "            # output: 256x13x13\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            # activation function: ReLU\n",
    "            nn.ReLU(),\n",
    "            # max pooling layer with kernel size 3 and stride 2\n",
    "            # output: 256x6x6\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            # ============================================================================== #\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # flatten\n",
    "            nn.Flatten(), # 256*5*5 = 6400\n",
    "            # ============================================================================== #\n",
    "            # 1st fc layer Dense: 4096 fully connected neurons\n",
    "            nn.Dropout(p=0.5), # dropout layer with p=0.5\n",
    "            nn.Linear(in_features=256 * 6 * 6, out_features=4096), # 256*5*5\n",
    "            nn.ReLU(),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # 2nd fc layer Dense: 4096 fully connected neurons\n",
    "            nn.Dropout(p=0.5), # dropout layer with p=0.5\n",
    "            nn.Linear(in_features=4096, out_features=4096), # 4096\n",
    "            nn.ReLU(),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # 3rd fc layer Dense: 10 fully connected neurons\n",
    "            nn.Linear(in_features=4096, out_features=num_classes) # 4096\n",
    "            # ============================================================================== #\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.407703642Z",
     "start_time": "2024-01-03T05:42:59.403946210Z"
    }
   },
   "id": "459d3e93ddc78a53",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = AlexNet().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.727788460Z",
     "start_time": "2024-01-03T05:42:59.404005392Z"
    }
   },
   "id": "98615f7aa89f388c",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AlexNet                                  [1, 10]                   --\n",
      "├─Sequential: 1-1                        [1, 256, 6, 6]            --\n",
      "│    └─0.weight                                                    ├─34,848\n",
      "│    └─0.bias                                                      ├─96\n",
      "│    └─3.weight                                                    ├─614,400\n",
      "│    └─3.bias                                                      ├─256\n",
      "│    └─6.weight                                                    ├─884,736\n",
      "│    └─6.bias                                                      ├─384\n",
      "│    └─8.weight                                                    ├─1,327,104\n",
      "│    └─8.bias                                                      ├─384\n",
      "│    └─10.weight                                                   ├─884,736\n",
      "│    └─10.bias                                                     └─256\n",
      "│    └─Conv2d: 2-1                       [1, 96, 55, 55]           34,944\n",
      "│    │    └─weight                                                 ├─34,848\n",
      "│    │    └─bias                                                   └─96\n",
      "│    └─ReLU: 2-2                         [1, 96, 55, 55]           --\n",
      "│    └─MaxPool2d: 2-3                    [1, 96, 27, 27]           --\n",
      "│    └─Conv2d: 2-4                       [1, 256, 27, 27]          614,656\n",
      "│    │    └─weight                                                 ├─614,400\n",
      "│    │    └─bias                                                   └─256\n",
      "│    └─ReLU: 2-5                         [1, 256, 27, 27]          --\n",
      "│    └─MaxPool2d: 2-6                    [1, 256, 13, 13]          --\n",
      "│    └─Conv2d: 2-7                       [1, 384, 13, 13]          885,120\n",
      "│    │    └─weight                                                 ├─884,736\n",
      "│    │    └─bias                                                   └─384\n",
      "│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n",
      "│    └─Conv2d: 2-9                       [1, 384, 13, 13]          1,327,488\n",
      "│    │    └─weight                                                 ├─1,327,104\n",
      "│    │    └─bias                                                   └─384\n",
      "│    └─ReLU: 2-10                        [1, 384, 13, 13]          --\n",
      "│    └─Conv2d: 2-11                      [1, 256, 13, 13]          884,992\n",
      "│    │    └─weight                                                 ├─884,736\n",
      "│    │    └─bias                                                   └─256\n",
      "│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n",
      "│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n",
      "├─Sequential: 1-2                        [1, 10]                   --\n",
      "│    └─2.weight                                                    ├─37,748,736\n",
      "│    └─2.bias                                                      ├─4,096\n",
      "│    └─5.weight                                                    ├─16,777,216\n",
      "│    └─5.bias                                                      ├─4,096\n",
      "│    └─7.weight                                                    ├─40,960\n",
      "│    └─7.bias                                                      └─10\n",
      "│    └─Flatten: 2-14                     [1, 9216]                 --\n",
      "│    └─Dropout: 2-15                     [1, 9216]                 --\n",
      "│    └─Linear: 2-16                      [1, 4096]                 37,752,832\n",
      "│    │    └─weight                                                 ├─37,748,736\n",
      "│    │    └─bias                                                   └─4,096\n",
      "│    └─ReLU: 2-17                        [1, 4096]                 --\n",
      "│    └─Dropout: 2-18                     [1, 4096]                 --\n",
      "│    └─Linear: 2-19                      [1, 4096]                 16,781,312\n",
      "│    │    └─weight                                                 ├─16,777,216\n",
      "│    │    └─bias                                                   └─4,096\n",
      "│    └─ReLU: 2-20                        [1, 4096]                 --\n",
      "│    └─Linear: 2-21                      [1, 10]                   40,970\n",
      "│    │    └─weight                                                 ├─40,960\n",
      "│    │    └─bias                                                   └─10\n",
      "==========================================================================================\n",
      "Total params: 58,322,314\n",
      "Trainable params: 58,322,314\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.13\n",
      "==========================================================================================\n",
      "Input size (MB): 0.62\n",
      "Forward/backward pass size (MB): 5.27\n",
      "Params size (MB): 233.29\n",
      "Estimated Total Size (MB): 239.17\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nAlexNet                                  [1, 10]                   --\n├─Sequential: 1-1                        [1, 256, 6, 6]            --\n│    └─0.weight                                                    ├─34,848\n│    └─0.bias                                                      ├─96\n│    └─3.weight                                                    ├─614,400\n│    └─3.bias                                                      ├─256\n│    └─6.weight                                                    ├─884,736\n│    └─6.bias                                                      ├─384\n│    └─8.weight                                                    ├─1,327,104\n│    └─8.bias                                                      ├─384\n│    └─10.weight                                                   ├─884,736\n│    └─10.bias                                                     └─256\n│    └─Conv2d: 2-1                       [1, 96, 55, 55]           34,944\n│    │    └─weight                                                 ├─34,848\n│    │    └─bias                                                   └─96\n│    └─ReLU: 2-2                         [1, 96, 55, 55]           --\n│    └─MaxPool2d: 2-3                    [1, 96, 27, 27]           --\n│    └─Conv2d: 2-4                       [1, 256, 27, 27]          614,656\n│    │    └─weight                                                 ├─614,400\n│    │    └─bias                                                   └─256\n│    └─ReLU: 2-5                         [1, 256, 27, 27]          --\n│    └─MaxPool2d: 2-6                    [1, 256, 13, 13]          --\n│    └─Conv2d: 2-7                       [1, 384, 13, 13]          885,120\n│    │    └─weight                                                 ├─884,736\n│    │    └─bias                                                   └─384\n│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n│    └─Conv2d: 2-9                       [1, 384, 13, 13]          1,327,488\n│    │    └─weight                                                 ├─1,327,104\n│    │    └─bias                                                   └─384\n│    └─ReLU: 2-10                        [1, 384, 13, 13]          --\n│    └─Conv2d: 2-11                      [1, 256, 13, 13]          884,992\n│    │    └─weight                                                 ├─884,736\n│    │    └─bias                                                   └─256\n│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n├─Sequential: 1-2                        [1, 10]                   --\n│    └─2.weight                                                    ├─37,748,736\n│    └─2.bias                                                      ├─4,096\n│    └─5.weight                                                    ├─16,777,216\n│    └─5.bias                                                      ├─4,096\n│    └─7.weight                                                    ├─40,960\n│    └─7.bias                                                      └─10\n│    └─Flatten: 2-14                     [1, 9216]                 --\n│    └─Dropout: 2-15                     [1, 9216]                 --\n│    └─Linear: 2-16                      [1, 4096]                 37,752,832\n│    │    └─weight                                                 ├─37,748,736\n│    │    └─bias                                                   └─4,096\n│    └─ReLU: 2-17                        [1, 4096]                 --\n│    └─Dropout: 2-18                     [1, 4096]                 --\n│    └─Linear: 2-19                      [1, 4096]                 16,781,312\n│    │    └─weight                                                 ├─16,777,216\n│    │    └─bias                                                   └─4,096\n│    └─ReLU: 2-20                        [1, 4096]                 --\n│    └─Linear: 2-21                      [1, 10]                   40,970\n│    │    └─weight                                                 ├─40,960\n│    │    └─bias                                                   └─10\n==========================================================================================\nTotal params: 58,322,314\nTrainable params: 58,322,314\nNon-trainable params: 0\nTotal mult-adds (G): 1.13\n==========================================================================================\nInput size (MB): 0.62\nForward/backward pass size (MB): 5.27\nParams size (MB): 233.29\nEstimated Total Size (MB): 239.17\n=========================================================================================="
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model summary\n",
    "# Detailed layer-wise summary\n",
    "summary(model, input_size=(1, 3, 227, 227), verbose=2, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.737954311Z",
     "start_time": "2024-01-03T05:42:59.729028317Z"
    }
   },
   "id": "c628ab4d26ae84d5",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy(task='multiclass', num_classes=10).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.769204850Z",
     "start_time": "2024-01-03T05:42:59.737410522Z"
    }
   },
   "id": "f9d48a09cc8fecc4",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e68e261f5fc5bec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training\n",
    "# Log training process to TensorBoard\n",
    "date_time = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "log_dir = os.path.join('train_logs', date_time)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.807956045Z",
     "start_time": "2024-01-03T05:42:59.767326966Z"
    }
   },
   "id": "f0e84690ff381c92",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "NUM_EPOCHS = 40\n",
    "NUM_BATCHES = len(train_loader)\n",
    "NUM_BATCHES_VAL = len(val_loader)\n",
    "NUM_BATCHES_TEST = len(test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:42:59.808642354Z",
     "start_time": "2024-01-03T05:42:59.807881965Z"
    }
   },
   "id": "160833a284c81c6f",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Step [0/375], Loss: 2.3009\n",
      "Epoch [1/40], Step [0/375], Accuracy: 0.1172\n",
      "Epoch [1/40], Step [10/375], Loss: 2.3110\n",
      "Epoch [1/40], Step [10/375], Accuracy: 0.0859\n",
      "Epoch [1/40], Step [20/375], Loss: 2.3051\n",
      "Epoch [1/40], Step [20/375], Accuracy: 0.0781\n",
      "Epoch [1/40], Step [30/375], Loss: 4.1996\n",
      "Epoch [1/40], Step [30/375], Accuracy: 0.1172\n",
      "Epoch [1/40], Step [40/375], Loss: 2.0961\n",
      "Epoch [1/40], Step [40/375], Accuracy: 0.2266\n",
      "Epoch [1/40], Step [50/375], Loss: 1.2279\n",
      "Epoch [1/40], Step [50/375], Accuracy: 0.6172\n",
      "Epoch [1/40], Step [60/375], Loss: 0.7604\n",
      "Epoch [1/40], Step [60/375], Accuracy: 0.7266\n",
      "Epoch [1/40], Step [70/375], Loss: 0.5695\n",
      "Epoch [1/40], Step [70/375], Accuracy: 0.8281\n",
      "Epoch [1/40], Step [80/375], Loss: 0.3691\n",
      "Epoch [1/40], Step [80/375], Accuracy: 0.8672\n",
      "Epoch [1/40], Step [90/375], Loss: 0.5013\n",
      "Epoch [1/40], Step [90/375], Accuracy: 0.8516\n",
      "Epoch [1/40], Step [100/375], Loss: 0.2758\n",
      "Epoch [1/40], Step [100/375], Accuracy: 0.9062\n",
      "Epoch [1/40], Step [110/375], Loss: 0.3548\n",
      "Epoch [1/40], Step [110/375], Accuracy: 0.8984\n",
      "Epoch [1/40], Step [120/375], Loss: 0.3242\n",
      "Epoch [1/40], Step [120/375], Accuracy: 0.8906\n",
      "Epoch [1/40], Step [130/375], Loss: 0.2211\n",
      "Epoch [1/40], Step [130/375], Accuracy: 0.9219\n",
      "Epoch [1/40], Step [140/375], Loss: 0.2789\n",
      "Epoch [1/40], Step [140/375], Accuracy: 0.8984\n",
      "Epoch [1/40], Step [150/375], Loss: 0.1561\n",
      "Epoch [1/40], Step [150/375], Accuracy: 0.9453\n",
      "Epoch [1/40], Step [160/375], Loss: 0.2758\n",
      "Epoch [1/40], Step [160/375], Accuracy: 0.9062\n",
      "Epoch [1/40], Step [170/375], Loss: 0.2345\n",
      "Epoch [1/40], Step [170/375], Accuracy: 0.9375\n",
      "Epoch [1/40], Step [180/375], Loss: 0.1460\n",
      "Epoch [1/40], Step [180/375], Accuracy: 0.9531\n",
      "Epoch [1/40], Step [190/375], Loss: 0.1822\n",
      "Epoch [1/40], Step [190/375], Accuracy: 0.9375\n",
      "Epoch [1/40], Step [200/375], Loss: 0.2438\n",
      "Epoch [1/40], Step [200/375], Accuracy: 0.9219\n",
      "Epoch [1/40], Step [210/375], Loss: 0.0890\n",
      "Epoch [1/40], Step [210/375], Accuracy: 0.9688\n",
      "Epoch [1/40], Step [220/375], Loss: 0.2445\n",
      "Epoch [1/40], Step [220/375], Accuracy: 0.9531\n",
      "Epoch [1/40], Step [230/375], Loss: 0.1428\n",
      "Epoch [1/40], Step [230/375], Accuracy: 0.9609\n",
      "Epoch [1/40], Step [240/375], Loss: 0.1260\n",
      "Epoch [1/40], Step [240/375], Accuracy: 0.9453\n",
      "Epoch [1/40], Step [250/375], Loss: 0.1316\n",
      "Epoch [1/40], Step [250/375], Accuracy: 0.9609\n",
      "Epoch [1/40], Step [260/375], Loss: 0.0719\n",
      "Epoch [1/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [1/40], Step [270/375], Loss: 0.1030\n",
      "Epoch [1/40], Step [270/375], Accuracy: 0.9531\n",
      "Epoch [1/40], Step [280/375], Loss: 0.1618\n",
      "Epoch [1/40], Step [280/375], Accuracy: 0.9531\n",
      "Epoch [1/40], Step [290/375], Loss: 0.1675\n",
      "Epoch [1/40], Step [290/375], Accuracy: 0.9609\n",
      "Epoch [1/40], Step [300/375], Loss: 0.0726\n",
      "Epoch [1/40], Step [300/375], Accuracy: 0.9688\n",
      "Epoch [1/40], Step [310/375], Loss: 0.1020\n",
      "Epoch [1/40], Step [310/375], Accuracy: 0.9688\n",
      "Epoch [1/40], Step [320/375], Loss: 0.1792\n",
      "Epoch [1/40], Step [320/375], Accuracy: 0.9453\n",
      "Epoch [1/40], Step [330/375], Loss: 0.1334\n",
      "Epoch [1/40], Step [330/375], Accuracy: 0.9531\n",
      "Epoch [1/40], Step [340/375], Loss: 0.0657\n",
      "Epoch [1/40], Step [340/375], Accuracy: 0.9766\n",
      "Epoch [1/40], Step [350/375], Loss: 0.0707\n",
      "Epoch [1/40], Step [350/375], Accuracy: 0.9766\n",
      "Epoch [1/40], Step [360/375], Loss: 0.1916\n",
      "Epoch [1/40], Step [360/375], Accuracy: 0.9453\n",
      "Epoch [1/40], Step [370/375], Loss: 0.0873\n",
      "Epoch [1/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [1/40], Step [0/94], Loss: 0.0883 Accuracy: 0.9766\n",
      "Epoch [1/40], Step [10/94], Loss: 0.0706 Accuracy: 0.9844\n",
      "Epoch [1/40], Step [20/94], Loss: 0.0513 Accuracy: 0.9922\n",
      "Epoch [1/40], Step [30/94], Loss: 0.1224 Accuracy: 0.9766\n",
      "Epoch [1/40], Step [40/94], Loss: 0.0915 Accuracy: 0.9766\n",
      "Epoch [1/40], Step [50/94], Loss: 0.0640 Accuracy: 0.9844\n",
      "Epoch [1/40], Step [60/94], Loss: 0.1563 Accuracy: 0.9375\n",
      "Epoch [1/40], Step [70/94], Loss: 0.1538 Accuracy: 0.9766\n",
      "Epoch [1/40], Step [80/94], Loss: 0.1582 Accuracy: 0.9531\n",
      "Epoch [1/40], Step [90/94], Loss: 0.1041 Accuracy: 0.9688\n",
      "Epoch: 0\tAverage Train Loss: 0.533093\tAverage Train Accuracy: 0.829917\n",
      "Epoch: 0\tAverage Validation Loss: 0.100298\tAverage Validation Accuracy: 0.972241\n",
      "Epoch: 0\tAverage Test Loss: 0.089842\tAverage Test Accuracy: 0.974090\n",
      "Epoch [2/40], Step [0/375], Loss: 0.1204\n",
      "Epoch [2/40], Step [0/375], Accuracy: 0.9531\n",
      "Epoch [2/40], Step [10/375], Loss: 0.0357\n",
      "Epoch [2/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [2/40], Step [20/375], Loss: 0.1133\n",
      "Epoch [2/40], Step [20/375], Accuracy: 0.9609\n",
      "Epoch [2/40], Step [30/375], Loss: 0.0897\n",
      "Epoch [2/40], Step [30/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [40/375], Loss: 0.1876\n",
      "Epoch [2/40], Step [40/375], Accuracy: 0.9531\n",
      "Epoch [2/40], Step [50/375], Loss: 0.1062\n",
      "Epoch [2/40], Step [50/375], Accuracy: 0.9609\n",
      "Epoch [2/40], Step [60/375], Loss: 0.0714\n",
      "Epoch [2/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [2/40], Step [70/375], Loss: 0.0935\n",
      "Epoch [2/40], Step [70/375], Accuracy: 0.9688\n",
      "Epoch [2/40], Step [80/375], Loss: 0.1249\n",
      "Epoch [2/40], Step [80/375], Accuracy: 0.9688\n",
      "Epoch [2/40], Step [90/375], Loss: 0.0990\n",
      "Epoch [2/40], Step [90/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [100/375], Loss: 0.1742\n",
      "Epoch [2/40], Step [100/375], Accuracy: 0.9453\n",
      "Epoch [2/40], Step [110/375], Loss: 0.1210\n",
      "Epoch [2/40], Step [110/375], Accuracy: 0.9531\n",
      "Epoch [2/40], Step [120/375], Loss: 0.0619\n",
      "Epoch [2/40], Step [120/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [130/375], Loss: 0.1305\n",
      "Epoch [2/40], Step [130/375], Accuracy: 0.9688\n",
      "Epoch [2/40], Step [140/375], Loss: 0.1026\n",
      "Epoch [2/40], Step [140/375], Accuracy: 0.9531\n",
      "Epoch [2/40], Step [150/375], Loss: 0.0180\n",
      "Epoch [2/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [2/40], Step [160/375], Loss: 0.0299\n",
      "Epoch [2/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [2/40], Step [170/375], Loss: 0.0606\n",
      "Epoch [2/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [2/40], Step [180/375], Loss: 0.0640\n",
      "Epoch [2/40], Step [180/375], Accuracy: 0.9844\n",
      "Epoch [2/40], Step [190/375], Loss: 0.0396\n",
      "Epoch [2/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [2/40], Step [200/375], Loss: 0.0832\n",
      "Epoch [2/40], Step [200/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [210/375], Loss: 0.1048\n",
      "Epoch [2/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [220/375], Loss: 0.0314\n",
      "Epoch [2/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [2/40], Step [230/375], Loss: 0.0563\n",
      "Epoch [2/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [2/40], Step [240/375], Loss: 0.1167\n",
      "Epoch [2/40], Step [240/375], Accuracy: 0.9688\n",
      "Epoch [2/40], Step [250/375], Loss: 0.0670\n",
      "Epoch [2/40], Step [250/375], Accuracy: 0.9688\n",
      "Epoch [2/40], Step [260/375], Loss: 0.0826\n",
      "Epoch [2/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [270/375], Loss: 0.0491\n",
      "Epoch [2/40], Step [270/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [280/375], Loss: 0.0669\n",
      "Epoch [2/40], Step [280/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [290/375], Loss: 0.0352\n",
      "Epoch [2/40], Step [290/375], Accuracy: 0.9844\n",
      "Epoch [2/40], Step [300/375], Loss: 0.0555\n",
      "Epoch [2/40], Step [300/375], Accuracy: 0.9844\n",
      "Epoch [2/40], Step [310/375], Loss: 0.1591\n",
      "Epoch [2/40], Step [310/375], Accuracy: 0.9688\n",
      "Epoch [2/40], Step [320/375], Loss: 0.0515\n",
      "Epoch [2/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [2/40], Step [330/375], Loss: 0.1463\n",
      "Epoch [2/40], Step [330/375], Accuracy: 0.9609\n",
      "Epoch [2/40], Step [340/375], Loss: 0.0795\n",
      "Epoch [2/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [2/40], Step [350/375], Loss: 0.0060\n",
      "Epoch [2/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [2/40], Step [360/375], Loss: 0.0840\n",
      "Epoch [2/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [370/375], Loss: 0.0535\n",
      "Epoch [2/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [2/40], Step [0/94], Loss: 0.0464 Accuracy: 0.9844\n",
      "Epoch [2/40], Step [10/94], Loss: 0.0086 Accuracy: 0.9922\n",
      "Epoch [2/40], Step [20/94], Loss: 0.0283 Accuracy: 0.9922\n",
      "Epoch [2/40], Step [30/94], Loss: 0.0938 Accuracy: 0.9766\n",
      "Epoch [2/40], Step [40/94], Loss: 0.0545 Accuracy: 0.9844\n",
      "Epoch [2/40], Step [50/94], Loss: 0.0595 Accuracy: 0.9922\n",
      "Epoch [2/40], Step [60/94], Loss: 0.0580 Accuracy: 0.9688\n",
      "Epoch [2/40], Step [70/94], Loss: 0.0763 Accuracy: 0.9766\n",
      "Epoch [2/40], Step [80/94], Loss: 0.0435 Accuracy: 0.9844\n",
      "Epoch [2/40], Step [90/94], Loss: 0.0380 Accuracy: 0.9922\n",
      "Epoch: 1\tAverage Train Loss: 0.314299\tAverage Train Accuracy: 0.900531\n",
      "Epoch: 1\tAverage Validation Loss: 0.075287\tAverage Validation Accuracy: 0.977934\n",
      "Epoch: 1\tAverage Test Loss: 0.068198\tAverage Test Accuracy: 0.979777\n",
      "Epoch [3/40], Step [0/375], Loss: 0.0193\n",
      "Epoch [3/40], Step [0/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [10/375], Loss: 0.0212\n",
      "Epoch [3/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [20/375], Loss: 0.0263\n",
      "Epoch [3/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [30/375], Loss: 0.0668\n",
      "Epoch [3/40], Step [30/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [40/375], Loss: 0.0733\n",
      "Epoch [3/40], Step [40/375], Accuracy: 0.9766\n",
      "Epoch [3/40], Step [50/375], Loss: 0.0776\n",
      "Epoch [3/40], Step [50/375], Accuracy: 0.9688\n",
      "Epoch [3/40], Step [60/375], Loss: 0.0606\n",
      "Epoch [3/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [70/375], Loss: 0.0938\n",
      "Epoch [3/40], Step [70/375], Accuracy: 0.9531\n",
      "Epoch [3/40], Step [80/375], Loss: 0.0548\n",
      "Epoch [3/40], Step [80/375], Accuracy: 0.9688\n",
      "Epoch [3/40], Step [90/375], Loss: 0.0996\n",
      "Epoch [3/40], Step [90/375], Accuracy: 0.9688\n",
      "Epoch [3/40], Step [100/375], Loss: 0.0448\n",
      "Epoch [3/40], Step [100/375], Accuracy: 0.9766\n",
      "Epoch [3/40], Step [110/375], Loss: 0.0347\n",
      "Epoch [3/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [120/375], Loss: 0.0650\n",
      "Epoch [3/40], Step [120/375], Accuracy: 0.9766\n",
      "Epoch [3/40], Step [130/375], Loss: 0.0507\n",
      "Epoch [3/40], Step [130/375], Accuracy: 0.9766\n",
      "Epoch [3/40], Step [140/375], Loss: 0.0604\n",
      "Epoch [3/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [150/375], Loss: 0.0267\n",
      "Epoch [3/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [160/375], Loss: 0.0195\n",
      "Epoch [3/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [170/375], Loss: 0.0885\n",
      "Epoch [3/40], Step [170/375], Accuracy: 0.9688\n",
      "Epoch [3/40], Step [180/375], Loss: 0.0308\n",
      "Epoch [3/40], Step [180/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [190/375], Loss: 0.0179\n",
      "Epoch [3/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [3/40], Step [200/375], Loss: 0.0456\n",
      "Epoch [3/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [210/375], Loss: 0.0538\n",
      "Epoch [3/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [3/40], Step [220/375], Loss: 0.0952\n",
      "Epoch [3/40], Step [220/375], Accuracy: 0.9688\n",
      "Epoch [3/40], Step [230/375], Loss: 0.0508\n",
      "Epoch [3/40], Step [230/375], Accuracy: 0.9766\n",
      "Epoch [3/40], Step [240/375], Loss: 0.0533\n",
      "Epoch [3/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [250/375], Loss: 0.0648\n",
      "Epoch [3/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [260/375], Loss: 0.0171\n",
      "Epoch [3/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [270/375], Loss: 0.0310\n",
      "Epoch [3/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [280/375], Loss: 0.1143\n",
      "Epoch [3/40], Step [280/375], Accuracy: 0.9688\n",
      "Epoch [3/40], Step [290/375], Loss: 0.0708\n",
      "Epoch [3/40], Step [290/375], Accuracy: 0.9766\n",
      "Epoch [3/40], Step [300/375], Loss: 0.0310\n",
      "Epoch [3/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [310/375], Loss: 0.0053\n",
      "Epoch [3/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [3/40], Step [320/375], Loss: 0.0337\n",
      "Epoch [3/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [330/375], Loss: 0.0094\n",
      "Epoch [3/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [3/40], Step [340/375], Loss: 0.0202\n",
      "Epoch [3/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [3/40], Step [350/375], Loss: 0.0376\n",
      "Epoch [3/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [360/375], Loss: 0.0533\n",
      "Epoch [3/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [3/40], Step [370/375], Loss: 0.0920\n",
      "Epoch [3/40], Step [370/375], Accuracy: 0.9844\n",
      "Epoch [3/40], Step [0/94], Loss: 0.0307 Accuracy: 0.9844\n",
      "Epoch [3/40], Step [10/94], Loss: 0.0240 Accuracy: 0.9922\n",
      "Epoch [3/40], Step [20/94], Loss: 0.0310 Accuracy: 0.9844\n",
      "Epoch [3/40], Step [30/94], Loss: 0.0975 Accuracy: 0.9766\n",
      "Epoch [3/40], Step [40/94], Loss: 0.0239 Accuracy: 1.0000\n",
      "Epoch [3/40], Step [50/94], Loss: 0.0177 Accuracy: 0.9922\n",
      "Epoch [3/40], Step [60/94], Loss: 0.0583 Accuracy: 0.9766\n",
      "Epoch [3/40], Step [70/94], Loss: 0.0885 Accuracy: 0.9766\n",
      "Epoch [3/40], Step [80/94], Loss: 0.0511 Accuracy: 0.9766\n",
      "Epoch [3/40], Step [90/94], Loss: 0.0411 Accuracy: 0.9922\n",
      "Epoch: 2\tAverage Train Loss: 0.232958\tAverage Train Accuracy: 0.927049\n",
      "Epoch: 2\tAverage Validation Loss: 0.065518\tAverage Validation Accuracy: 0.980460\n",
      "Epoch: 2\tAverage Test Loss: 0.057880\tAverage Test Accuracy: 0.983155\n",
      "Epoch [4/40], Step [0/375], Loss: 0.0295\n",
      "Epoch [4/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [10/375], Loss: 0.0092\n",
      "Epoch [4/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [20/375], Loss: 0.0851\n",
      "Epoch [4/40], Step [20/375], Accuracy: 0.9844\n",
      "Epoch [4/40], Step [30/375], Loss: 0.0554\n",
      "Epoch [4/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [40/375], Loss: 0.0828\n",
      "Epoch [4/40], Step [40/375], Accuracy: 0.9766\n",
      "Epoch [4/40], Step [50/375], Loss: 0.1338\n",
      "Epoch [4/40], Step [50/375], Accuracy: 0.9531\n",
      "Epoch [4/40], Step [60/375], Loss: 0.0887\n",
      "Epoch [4/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [4/40], Step [70/375], Loss: 0.1448\n",
      "Epoch [4/40], Step [70/375], Accuracy: 0.9766\n",
      "Epoch [4/40], Step [80/375], Loss: 0.1082\n",
      "Epoch [4/40], Step [80/375], Accuracy: 0.9688\n",
      "Epoch [4/40], Step [90/375], Loss: 0.0512\n",
      "Epoch [4/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [4/40], Step [100/375], Loss: 0.0253\n",
      "Epoch [4/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [110/375], Loss: 0.0731\n",
      "Epoch [4/40], Step [110/375], Accuracy: 0.9688\n",
      "Epoch [4/40], Step [120/375], Loss: 0.0784\n",
      "Epoch [4/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [4/40], Step [130/375], Loss: 0.0426\n",
      "Epoch [4/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [4/40], Step [140/375], Loss: 0.0599\n",
      "Epoch [4/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [4/40], Step [150/375], Loss: 0.0520\n",
      "Epoch [4/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [160/375], Loss: 0.0843\n",
      "Epoch [4/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [4/40], Step [170/375], Loss: 0.0458\n",
      "Epoch [4/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [180/375], Loss: 0.0225\n",
      "Epoch [4/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [190/375], Loss: 0.0274\n",
      "Epoch [4/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [200/375], Loss: 0.0451\n",
      "Epoch [4/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [210/375], Loss: 0.0541\n",
      "Epoch [4/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [4/40], Step [220/375], Loss: 0.0155\n",
      "Epoch [4/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [4/40], Step [230/375], Loss: 0.1533\n",
      "Epoch [4/40], Step [230/375], Accuracy: 0.9531\n",
      "Epoch [4/40], Step [240/375], Loss: 0.0893\n",
      "Epoch [4/40], Step [240/375], Accuracy: 0.9531\n",
      "Epoch [4/40], Step [250/375], Loss: 0.0286\n",
      "Epoch [4/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [260/375], Loss: 0.0789\n",
      "Epoch [4/40], Step [260/375], Accuracy: 0.9688\n",
      "Epoch [4/40], Step [270/375], Loss: 0.0932\n",
      "Epoch [4/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [280/375], Loss: 0.0343\n",
      "Epoch [4/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [290/375], Loss: 0.0607\n",
      "Epoch [4/40], Step [290/375], Accuracy: 0.9766\n",
      "Epoch [4/40], Step [300/375], Loss: 0.0155\n",
      "Epoch [4/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [4/40], Step [310/375], Loss: 0.0094\n",
      "Epoch [4/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [4/40], Step [320/375], Loss: 0.0216\n",
      "Epoch [4/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [4/40], Step [330/375], Loss: 0.0290\n",
      "Epoch [4/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [340/375], Loss: 0.0604\n",
      "Epoch [4/40], Step [340/375], Accuracy: 0.9766\n",
      "Epoch [4/40], Step [350/375], Loss: 0.0163\n",
      "Epoch [4/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [360/375], Loss: 0.0089\n",
      "Epoch [4/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [4/40], Step [370/375], Loss: 0.0593\n",
      "Epoch [4/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [4/40], Step [0/94], Loss: 0.0374 Accuracy: 0.9922\n",
      "Epoch [4/40], Step [10/94], Loss: 0.0126 Accuracy: 1.0000\n",
      "Epoch [4/40], Step [20/94], Loss: 0.0154 Accuracy: 0.9922\n",
      "Epoch [4/40], Step [30/94], Loss: 0.0895 Accuracy: 0.9609\n",
      "Epoch [4/40], Step [40/94], Loss: 0.0420 Accuracy: 0.9844\n",
      "Epoch [4/40], Step [50/94], Loss: 0.0489 Accuracy: 0.9766\n",
      "Epoch [4/40], Step [60/94], Loss: 0.0298 Accuracy: 0.9922\n",
      "Epoch [4/40], Step [70/94], Loss: 0.0623 Accuracy: 0.9766\n",
      "Epoch [4/40], Step [80/94], Loss: 0.0595 Accuracy: 0.9844\n",
      "Epoch [4/40], Step [90/94], Loss: 0.0258 Accuracy: 0.9844\n",
      "Epoch: 3\tAverage Train Loss: 0.190248\tAverage Train Accuracy: 0.940781\n",
      "Epoch: 3\tAverage Validation Loss: 0.059672\tAverage Validation Accuracy: 0.982228\n",
      "Epoch: 3\tAverage Test Loss: 0.052025\tAverage Test Accuracy: 0.984820\n",
      "Epoch [5/40], Step [0/375], Loss: 0.0719\n",
      "Epoch [5/40], Step [0/375], Accuracy: 0.9688\n",
      "Epoch [5/40], Step [10/375], Loss: 0.0513\n",
      "Epoch [5/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [5/40], Step [20/375], Loss: 0.0251\n",
      "Epoch [5/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [30/375], Loss: 0.0628\n",
      "Epoch [5/40], Step [30/375], Accuracy: 0.9844\n",
      "Epoch [5/40], Step [40/375], Loss: 0.0189\n",
      "Epoch [5/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [5/40], Step [50/375], Loss: 0.0444\n",
      "Epoch [5/40], Step [50/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [60/375], Loss: 0.0066\n",
      "Epoch [5/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [5/40], Step [70/375], Loss: 0.0573\n",
      "Epoch [5/40], Step [70/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [80/375], Loss: 0.0244\n",
      "Epoch [5/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [90/375], Loss: 0.0413\n",
      "Epoch [5/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [100/375], Loss: 0.1316\n",
      "Epoch [5/40], Step [100/375], Accuracy: 0.9688\n",
      "Epoch [5/40], Step [110/375], Loss: 0.0276\n",
      "Epoch [5/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [120/375], Loss: 0.0739\n",
      "Epoch [5/40], Step [120/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [130/375], Loss: 0.0176\n",
      "Epoch [5/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [140/375], Loss: 0.0277\n",
      "Epoch [5/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [150/375], Loss: 0.0438\n",
      "Epoch [5/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [160/375], Loss: 0.0081\n",
      "Epoch [5/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [5/40], Step [170/375], Loss: 0.0968\n",
      "Epoch [5/40], Step [170/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [180/375], Loss: 0.0265\n",
      "Epoch [5/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [190/375], Loss: 0.0694\n",
      "Epoch [5/40], Step [190/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [200/375], Loss: 0.0445\n",
      "Epoch [5/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [5/40], Step [210/375], Loss: 0.0393\n",
      "Epoch [5/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [220/375], Loss: 0.0364\n",
      "Epoch [5/40], Step [220/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [230/375], Loss: 0.0386\n",
      "Epoch [5/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [5/40], Step [240/375], Loss: 0.0145\n",
      "Epoch [5/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [250/375], Loss: 0.0187\n",
      "Epoch [5/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [260/375], Loss: 0.0466\n",
      "Epoch [5/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [270/375], Loss: 0.0061\n",
      "Epoch [5/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [5/40], Step [280/375], Loss: 0.0345\n",
      "Epoch [5/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [290/375], Loss: 0.0075\n",
      "Epoch [5/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [5/40], Step [300/375], Loss: 0.1177\n",
      "Epoch [5/40], Step [300/375], Accuracy: 0.9609\n",
      "Epoch [5/40], Step [310/375], Loss: 0.1012\n",
      "Epoch [5/40], Step [310/375], Accuracy: 0.9609\n",
      "Epoch [5/40], Step [320/375], Loss: 0.0244\n",
      "Epoch [5/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [5/40], Step [330/375], Loss: 0.0200\n",
      "Epoch [5/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [5/40], Step [340/375], Loss: 0.0894\n",
      "Epoch [5/40], Step [340/375], Accuracy: 0.9688\n",
      "Epoch [5/40], Step [350/375], Loss: 0.0957\n",
      "Epoch [5/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [5/40], Step [360/375], Loss: 0.0046\n",
      "Epoch [5/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [5/40], Step [370/375], Loss: 0.0533\n",
      "Epoch [5/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [5/40], Step [0/94], Loss: 0.0369 Accuracy: 0.9844\n",
      "Epoch [5/40], Step [10/94], Loss: 0.0042 Accuracy: 1.0000\n",
      "Epoch [5/40], Step [20/94], Loss: 0.0251 Accuracy: 0.9922\n",
      "Epoch [5/40], Step [30/94], Loss: 0.0778 Accuracy: 0.9766\n",
      "Epoch [5/40], Step [40/94], Loss: 0.0204 Accuracy: 1.0000\n",
      "Epoch [5/40], Step [50/94], Loss: 0.0248 Accuracy: 0.9922\n",
      "Epoch [5/40], Step [60/94], Loss: 0.0308 Accuracy: 0.9844\n",
      "Epoch [5/40], Step [70/94], Loss: 0.0602 Accuracy: 0.9688\n",
      "Epoch [5/40], Step [80/94], Loss: 0.0325 Accuracy: 0.9844\n",
      "Epoch [5/40], Step [90/94], Loss: 0.0879 Accuracy: 0.9766\n",
      "Epoch: 4\tAverage Train Loss: 0.164032\tAverage Train Accuracy: 0.949242\n",
      "Epoch: 4\tAverage Validation Loss: 0.053704\tAverage Validation Accuracy: 0.983804\n",
      "Epoch: 4\tAverage Test Loss: 0.047394\tAverage Test Accuracy: 0.986195\n",
      "Epoch [6/40], Step [0/375], Loss: 0.0177\n",
      "Epoch [6/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [6/40], Step [10/375], Loss: 0.0449\n",
      "Epoch [6/40], Step [10/375], Accuracy: 0.9766\n",
      "Epoch [6/40], Step [20/375], Loss: 0.0370\n",
      "Epoch [6/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [30/375], Loss: 0.1238\n",
      "Epoch [6/40], Step [30/375], Accuracy: 0.9688\n",
      "Epoch [6/40], Step [40/375], Loss: 0.0196\n",
      "Epoch [6/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [50/375], Loss: 0.0032\n",
      "Epoch [6/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [6/40], Step [60/375], Loss: 0.0561\n",
      "Epoch [6/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [70/375], Loss: 0.0336\n",
      "Epoch [6/40], Step [70/375], Accuracy: 0.9844\n",
      "Epoch [6/40], Step [80/375], Loss: 0.0690\n",
      "Epoch [6/40], Step [80/375], Accuracy: 0.9766\n",
      "Epoch [6/40], Step [90/375], Loss: 0.1020\n",
      "Epoch [6/40], Step [90/375], Accuracy: 0.9688\n",
      "Epoch [6/40], Step [100/375], Loss: 0.0698\n",
      "Epoch [6/40], Step [100/375], Accuracy: 0.9766\n",
      "Epoch [6/40], Step [110/375], Loss: 0.0217\n",
      "Epoch [6/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [6/40], Step [120/375], Loss: 0.0300\n",
      "Epoch [6/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [130/375], Loss: 0.0383\n",
      "Epoch [6/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [6/40], Step [140/375], Loss: 0.0185\n",
      "Epoch [6/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [6/40], Step [150/375], Loss: 0.0467\n",
      "Epoch [6/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [6/40], Step [160/375], Loss: 0.0267\n",
      "Epoch [6/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [6/40], Step [170/375], Loss: 0.0549\n",
      "Epoch [6/40], Step [170/375], Accuracy: 0.9766\n",
      "Epoch [6/40], Step [180/375], Loss: 0.0155\n",
      "Epoch [6/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [190/375], Loss: 0.2446\n",
      "Epoch [6/40], Step [190/375], Accuracy: 0.9453\n",
      "Epoch [6/40], Step [200/375], Loss: 0.0529\n",
      "Epoch [6/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [6/40], Step [210/375], Loss: 0.0144\n",
      "Epoch [6/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [220/375], Loss: 0.0922\n",
      "Epoch [6/40], Step [220/375], Accuracy: 0.9844\n",
      "Epoch [6/40], Step [230/375], Loss: 0.0434\n",
      "Epoch [6/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [6/40], Step [240/375], Loss: 0.0163\n",
      "Epoch [6/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [250/375], Loss: 0.0735\n",
      "Epoch [6/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [260/375], Loss: 0.1493\n",
      "Epoch [6/40], Step [260/375], Accuracy: 0.9375\n",
      "Epoch [6/40], Step [270/375], Loss: 0.0128\n",
      "Epoch [6/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [280/375], Loss: 0.0780\n",
      "Epoch [6/40], Step [280/375], Accuracy: 0.9766\n",
      "Epoch [6/40], Step [290/375], Loss: 0.0834\n",
      "Epoch [6/40], Step [290/375], Accuracy: 0.9766\n",
      "Epoch [6/40], Step [300/375], Loss: 0.0893\n",
      "Epoch [6/40], Step [300/375], Accuracy: 0.9688\n",
      "Epoch [6/40], Step [310/375], Loss: 0.0295\n",
      "Epoch [6/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [320/375], Loss: 0.0390\n",
      "Epoch [6/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [330/375], Loss: 0.0398\n",
      "Epoch [6/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [340/375], Loss: 0.0275\n",
      "Epoch [6/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [350/375], Loss: 0.0741\n",
      "Epoch [6/40], Step [350/375], Accuracy: 0.9688\n",
      "Epoch [6/40], Step [360/375], Loss: 0.1299\n",
      "Epoch [6/40], Step [360/375], Accuracy: 0.9688\n",
      "Epoch [6/40], Step [370/375], Loss: 0.0669\n",
      "Epoch [6/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [6/40], Step [0/94], Loss: 0.0088 Accuracy: 1.0000\n",
      "Epoch [6/40], Step [10/94], Loss: 0.0695 Accuracy: 0.9922\n",
      "Epoch [6/40], Step [20/94], Loss: 0.0304 Accuracy: 0.9844\n",
      "Epoch [6/40], Step [30/94], Loss: 0.0631 Accuracy: 0.9844\n",
      "Epoch [6/40], Step [40/94], Loss: 0.0285 Accuracy: 0.9844\n",
      "Epoch [6/40], Step [50/94], Loss: 0.0939 Accuracy: 0.9844\n",
      "Epoch [6/40], Step [60/94], Loss: 0.0951 Accuracy: 0.9766\n",
      "Epoch [6/40], Step [70/94], Loss: 0.0859 Accuracy: 0.9766\n",
      "Epoch [6/40], Step [80/94], Loss: 0.0626 Accuracy: 0.9766\n",
      "Epoch [6/40], Step [90/94], Loss: 0.0836 Accuracy: 0.9688\n",
      "Epoch: 5\tAverage Train Loss: 0.145579\tAverage Train Accuracy: 0.955142\n",
      "Epoch: 5\tAverage Validation Loss: 0.053209\tAverage Validation Accuracy: 0.984163\n",
      "Epoch: 5\tAverage Test Loss: 0.047483\tAverage Test Accuracy: 0.986254\n",
      "Epoch [7/40], Step [0/375], Loss: 0.1410\n",
      "Epoch [7/40], Step [0/375], Accuracy: 0.9766\n",
      "Epoch [7/40], Step [10/375], Loss: 0.0647\n",
      "Epoch [7/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [20/375], Loss: 0.0104\n",
      "Epoch [7/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [7/40], Step [30/375], Loss: 0.0252\n",
      "Epoch [7/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [40/375], Loss: 0.0326\n",
      "Epoch [7/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [50/375], Loss: 0.0240\n",
      "Epoch [7/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [60/375], Loss: 0.0246\n",
      "Epoch [7/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [70/375], Loss: 0.0910\n",
      "Epoch [7/40], Step [70/375], Accuracy: 0.9766\n",
      "Epoch [7/40], Step [80/375], Loss: 0.0191\n",
      "Epoch [7/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [7/40], Step [90/375], Loss: 0.0142\n",
      "Epoch [7/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [100/375], Loss: 0.0307\n",
      "Epoch [7/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [110/375], Loss: 0.1244\n",
      "Epoch [7/40], Step [110/375], Accuracy: 0.9688\n",
      "Epoch [7/40], Step [120/375], Loss: 0.0752\n",
      "Epoch [7/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [130/375], Loss: 0.0136\n",
      "Epoch [7/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [7/40], Step [140/375], Loss: 0.0907\n",
      "Epoch [7/40], Step [140/375], Accuracy: 0.9688\n",
      "Epoch [7/40], Step [150/375], Loss: 0.1035\n",
      "Epoch [7/40], Step [150/375], Accuracy: 0.9688\n",
      "Epoch [7/40], Step [160/375], Loss: 0.0792\n",
      "Epoch [7/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [170/375], Loss: 0.0538\n",
      "Epoch [7/40], Step [170/375], Accuracy: 0.9766\n",
      "Epoch [7/40], Step [180/375], Loss: 0.0144\n",
      "Epoch [7/40], Step [180/375], Accuracy: 1.0000\n",
      "Epoch [7/40], Step [190/375], Loss: 0.0909\n",
      "Epoch [7/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [200/375], Loss: 0.0827\n",
      "Epoch [7/40], Step [200/375], Accuracy: 0.9766\n",
      "Epoch [7/40], Step [210/375], Loss: 0.0297\n",
      "Epoch [7/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [220/375], Loss: 0.0911\n",
      "Epoch [7/40], Step [220/375], Accuracy: 0.9766\n",
      "Epoch [7/40], Step [230/375], Loss: 0.0707\n",
      "Epoch [7/40], Step [230/375], Accuracy: 0.9688\n",
      "Epoch [7/40], Step [240/375], Loss: 0.0514\n",
      "Epoch [7/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [250/375], Loss: 0.0048\n",
      "Epoch [7/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [7/40], Step [260/375], Loss: 0.0241\n",
      "Epoch [7/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [270/375], Loss: 0.0405\n",
      "Epoch [7/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [280/375], Loss: 0.0196\n",
      "Epoch [7/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [290/375], Loss: 0.0492\n",
      "Epoch [7/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [300/375], Loss: 0.0512\n",
      "Epoch [7/40], Step [300/375], Accuracy: 0.9844\n",
      "Epoch [7/40], Step [310/375], Loss: 0.0235\n",
      "Epoch [7/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [320/375], Loss: 0.1307\n",
      "Epoch [7/40], Step [320/375], Accuracy: 0.9688\n",
      "Epoch [7/40], Step [330/375], Loss: 0.0939\n",
      "Epoch [7/40], Step [330/375], Accuracy: 0.9766\n",
      "Epoch [7/40], Step [340/375], Loss: 0.0747\n",
      "Epoch [7/40], Step [340/375], Accuracy: 0.9688\n",
      "Epoch [7/40], Step [350/375], Loss: 0.0276\n",
      "Epoch [7/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [7/40], Step [360/375], Loss: 0.0684\n",
      "Epoch [7/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [7/40], Step [370/375], Loss: 0.0782\n",
      "Epoch [7/40], Step [370/375], Accuracy: 0.9609\n",
      "Epoch [7/40], Step [0/94], Loss: 0.0203 Accuracy: 0.9844\n",
      "Epoch [7/40], Step [10/94], Loss: 0.0204 Accuracy: 0.9922\n",
      "Epoch [7/40], Step [20/94], Loss: 0.0204 Accuracy: 0.9922\n",
      "Epoch [7/40], Step [30/94], Loss: 0.1083 Accuracy: 0.9766\n",
      "Epoch [7/40], Step [40/94], Loss: 0.0118 Accuracy: 1.0000\n",
      "Epoch [7/40], Step [50/94], Loss: 0.0675 Accuracy: 0.9766\n",
      "Epoch [7/40], Step [60/94], Loss: 0.0688 Accuracy: 0.9688\n",
      "Epoch [7/40], Step [70/94], Loss: 0.0848 Accuracy: 0.9844\n",
      "Epoch [7/40], Step [80/94], Loss: 0.0728 Accuracy: 0.9844\n",
      "Epoch [7/40], Step [90/94], Loss: 0.0123 Accuracy: 1.0000\n",
      "Epoch: 6\tAverage Train Loss: 0.132863\tAverage Train Accuracy: 0.959324\n",
      "Epoch: 6\tAverage Validation Loss: 0.052268\tAverage Validation Accuracy: 0.984383\n",
      "Epoch: 6\tAverage Test Loss: 0.046721\tAverage Test Accuracy: 0.986593\n",
      "Epoch [8/40], Step [0/375], Loss: 0.0304\n",
      "Epoch [8/40], Step [0/375], Accuracy: 0.9766\n",
      "Epoch [8/40], Step [10/375], Loss: 0.0361\n",
      "Epoch [8/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [20/375], Loss: 0.0869\n",
      "Epoch [8/40], Step [20/375], Accuracy: 0.9688\n",
      "Epoch [8/40], Step [30/375], Loss: 0.0270\n",
      "Epoch [8/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [40/375], Loss: 0.0052\n",
      "Epoch [8/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [8/40], Step [50/375], Loss: 0.0242\n",
      "Epoch [8/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [60/375], Loss: 0.0564\n",
      "Epoch [8/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [70/375], Loss: 0.0853\n",
      "Epoch [8/40], Step [70/375], Accuracy: 0.9688\n",
      "Epoch [8/40], Step [80/375], Loss: 0.0635\n",
      "Epoch [8/40], Step [80/375], Accuracy: 0.9766\n",
      "Epoch [8/40], Step [90/375], Loss: 0.0215\n",
      "Epoch [8/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [100/375], Loss: 0.0236\n",
      "Epoch [8/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [110/375], Loss: 0.0812\n",
      "Epoch [8/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [120/375], Loss: 0.0271\n",
      "Epoch [8/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [130/375], Loss: 0.0909\n",
      "Epoch [8/40], Step [130/375], Accuracy: 0.9766\n",
      "Epoch [8/40], Step [140/375], Loss: 0.0365\n",
      "Epoch [8/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [150/375], Loss: 0.0323\n",
      "Epoch [8/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [160/375], Loss: 0.0929\n",
      "Epoch [8/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [170/375], Loss: 0.0836\n",
      "Epoch [8/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [180/375], Loss: 0.0459\n",
      "Epoch [8/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [190/375], Loss: 0.1131\n",
      "Epoch [8/40], Step [190/375], Accuracy: 0.9609\n",
      "Epoch [8/40], Step [200/375], Loss: 0.0351\n",
      "Epoch [8/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [210/375], Loss: 0.0303\n",
      "Epoch [8/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [220/375], Loss: 0.0185\n",
      "Epoch [8/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [230/375], Loss: 0.0455\n",
      "Epoch [8/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [240/375], Loss: 0.0423\n",
      "Epoch [8/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [250/375], Loss: 0.0182\n",
      "Epoch [8/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [260/375], Loss: 0.1088\n",
      "Epoch [8/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [8/40], Step [270/375], Loss: 0.0230\n",
      "Epoch [8/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [280/375], Loss: 0.0617\n",
      "Epoch [8/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [290/375], Loss: 0.0064\n",
      "Epoch [8/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [8/40], Step [300/375], Loss: 0.0918\n",
      "Epoch [8/40], Step [300/375], Accuracy: 0.9688\n",
      "Epoch [8/40], Step [310/375], Loss: 0.0291\n",
      "Epoch [8/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [320/375], Loss: 0.0148\n",
      "Epoch [8/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [8/40], Step [330/375], Loss: 0.0352\n",
      "Epoch [8/40], Step [330/375], Accuracy: 0.9844\n",
      "Epoch [8/40], Step [340/375], Loss: 0.1642\n",
      "Epoch [8/40], Step [340/375], Accuracy: 0.9766\n",
      "Epoch [8/40], Step [350/375], Loss: 0.0199\n",
      "Epoch [8/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [8/40], Step [360/375], Loss: 0.0785\n",
      "Epoch [8/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [8/40], Step [370/375], Loss: 0.0855\n",
      "Epoch [8/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [8/40], Step [0/94], Loss: 0.0003 Accuracy: 1.0000\n",
      "Epoch [8/40], Step [10/94], Loss: 0.0320 Accuracy: 0.9922\n",
      "Epoch [8/40], Step [20/94], Loss: 0.0008 Accuracy: 1.0000\n",
      "Epoch [8/40], Step [30/94], Loss: 0.0380 Accuracy: 0.9844\n",
      "Epoch [8/40], Step [40/94], Loss: 0.0891 Accuracy: 0.9844\n",
      "Epoch [8/40], Step [50/94], Loss: 0.0399 Accuracy: 0.9922\n",
      "Epoch [8/40], Step [60/94], Loss: 0.0958 Accuracy: 0.9688\n",
      "Epoch [8/40], Step [70/94], Loss: 0.0428 Accuracy: 0.9766\n",
      "Epoch [8/40], Step [80/94], Loss: 0.0101 Accuracy: 1.0000\n",
      "Epoch [8/40], Step [90/94], Loss: 0.0084 Accuracy: 0.9922\n",
      "Epoch: 7\tAverage Train Loss: 0.122754\tAverage Train Accuracy: 0.962529\n",
      "Epoch: 7\tAverage Validation Loss: 0.050993\tAverage Validation Accuracy: 0.984891\n",
      "Epoch: 7\tAverage Test Loss: 0.045994\tAverage Test Accuracy: 0.987057\n",
      "Epoch [9/40], Step [0/375], Loss: 0.0955\n",
      "Epoch [9/40], Step [0/375], Accuracy: 0.9688\n",
      "Epoch [9/40], Step [10/375], Loss: 0.1941\n",
      "Epoch [9/40], Step [10/375], Accuracy: 0.9453\n",
      "Epoch [9/40], Step [20/375], Loss: 0.1555\n",
      "Epoch [9/40], Step [20/375], Accuracy: 0.9531\n",
      "Epoch [9/40], Step [30/375], Loss: 0.0922\n",
      "Epoch [9/40], Step [30/375], Accuracy: 0.9688\n",
      "Epoch [9/40], Step [40/375], Loss: 0.0497\n",
      "Epoch [9/40], Step [40/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [50/375], Loss: 0.0307\n",
      "Epoch [9/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [60/375], Loss: 0.0115\n",
      "Epoch [9/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [9/40], Step [70/375], Loss: 0.0704\n",
      "Epoch [9/40], Step [70/375], Accuracy: 0.9688\n",
      "Epoch [9/40], Step [80/375], Loss: 0.0141\n",
      "Epoch [9/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [9/40], Step [90/375], Loss: 0.0290\n",
      "Epoch [9/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [100/375], Loss: 0.0137\n",
      "Epoch [9/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [110/375], Loss: 0.0145\n",
      "Epoch [9/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [120/375], Loss: 0.0529\n",
      "Epoch [9/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [130/375], Loss: 0.0387\n",
      "Epoch [9/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [140/375], Loss: 0.0357\n",
      "Epoch [9/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [150/375], Loss: 0.0250\n",
      "Epoch [9/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [160/375], Loss: 0.0468\n",
      "Epoch [9/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [170/375], Loss: 0.0744\n",
      "Epoch [9/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [180/375], Loss: 0.0118\n",
      "Epoch [9/40], Step [180/375], Accuracy: 1.0000\n",
      "Epoch [9/40], Step [190/375], Loss: 0.0197\n",
      "Epoch [9/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [200/375], Loss: 0.1051\n",
      "Epoch [9/40], Step [200/375], Accuracy: 0.9766\n",
      "Epoch [9/40], Step [210/375], Loss: 0.0677\n",
      "Epoch [9/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [9/40], Step [220/375], Loss: 0.0222\n",
      "Epoch [9/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [230/375], Loss: 0.0125\n",
      "Epoch [9/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [240/375], Loss: 0.0400\n",
      "Epoch [9/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [250/375], Loss: 0.0777\n",
      "Epoch [9/40], Step [250/375], Accuracy: 0.9766\n",
      "Epoch [9/40], Step [260/375], Loss: 0.0824\n",
      "Epoch [9/40], Step [260/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [270/375], Loss: 0.0290\n",
      "Epoch [9/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [280/375], Loss: 0.1292\n",
      "Epoch [9/40], Step [280/375], Accuracy: 0.9609\n",
      "Epoch [9/40], Step [290/375], Loss: 0.0200\n",
      "Epoch [9/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [300/375], Loss: 0.0333\n",
      "Epoch [9/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [310/375], Loss: 0.0506\n",
      "Epoch [9/40], Step [310/375], Accuracy: 0.9844\n",
      "Epoch [9/40], Step [320/375], Loss: 0.0389\n",
      "Epoch [9/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [330/375], Loss: 0.0301\n",
      "Epoch [9/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [9/40], Step [340/375], Loss: 0.1047\n",
      "Epoch [9/40], Step [340/375], Accuracy: 0.9766\n",
      "Epoch [9/40], Step [350/375], Loss: 0.0533\n",
      "Epoch [9/40], Step [350/375], Accuracy: 0.9766\n",
      "Epoch [9/40], Step [360/375], Loss: 0.0067\n",
      "Epoch [9/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [9/40], Step [370/375], Loss: 0.0636\n",
      "Epoch [9/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [9/40], Step [0/94], Loss: 0.0023 Accuracy: 1.0000\n",
      "Epoch [9/40], Step [10/94], Loss: 0.0088 Accuracy: 0.9922\n",
      "Epoch [9/40], Step [20/94], Loss: 0.0053 Accuracy: 1.0000\n",
      "Epoch [9/40], Step [30/94], Loss: 0.0391 Accuracy: 0.9844\n",
      "Epoch [9/40], Step [40/94], Loss: 0.0231 Accuracy: 0.9844\n",
      "Epoch [9/40], Step [50/94], Loss: 0.0221 Accuracy: 0.9922\n",
      "Epoch [9/40], Step [60/94], Loss: 0.0167 Accuracy: 0.9922\n",
      "Epoch [9/40], Step [70/94], Loss: 0.0383 Accuracy: 0.9922\n",
      "Epoch [9/40], Step [80/94], Loss: 0.0459 Accuracy: 0.9844\n",
      "Epoch [9/40], Step [90/94], Loss: 0.0363 Accuracy: 0.9844\n",
      "Epoch: 8\tAverage Train Loss: 0.115002\tAverage Train Accuracy: 0.965037\n",
      "Epoch: 8\tAverage Validation Loss: 0.048510\tAverage Validation Accuracy: 0.985591\n",
      "Epoch: 8\tAverage Test Loss: 0.044364\tAverage Test Accuracy: 0.987474\n",
      "Epoch [10/40], Step [0/375], Loss: 0.0216\n",
      "Epoch [10/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [10/375], Loss: 0.0248\n",
      "Epoch [10/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [20/375], Loss: 0.0682\n",
      "Epoch [10/40], Step [20/375], Accuracy: 0.9688\n",
      "Epoch [10/40], Step [30/375], Loss: 0.0005\n",
      "Epoch [10/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [40/375], Loss: 0.0282\n",
      "Epoch [10/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [50/375], Loss: 0.1052\n",
      "Epoch [10/40], Step [50/375], Accuracy: 0.9766\n",
      "Epoch [10/40], Step [60/375], Loss: 0.0210\n",
      "Epoch [10/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [70/375], Loss: 0.0095\n",
      "Epoch [10/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [80/375], Loss: 0.0388\n",
      "Epoch [10/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [10/40], Step [90/375], Loss: 0.0074\n",
      "Epoch [10/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [100/375], Loss: 0.0450\n",
      "Epoch [10/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [110/375], Loss: 0.0253\n",
      "Epoch [10/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [120/375], Loss: 0.0228\n",
      "Epoch [10/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [130/375], Loss: 0.0360\n",
      "Epoch [10/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [10/40], Step [140/375], Loss: 0.0081\n",
      "Epoch [10/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [150/375], Loss: 0.0070\n",
      "Epoch [10/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [160/375], Loss: 0.0701\n",
      "Epoch [10/40], Step [160/375], Accuracy: 0.9766\n",
      "Epoch [10/40], Step [170/375], Loss: 0.0787\n",
      "Epoch [10/40], Step [170/375], Accuracy: 0.9688\n",
      "Epoch [10/40], Step [180/375], Loss: 0.0487\n",
      "Epoch [10/40], Step [180/375], Accuracy: 0.9844\n",
      "Epoch [10/40], Step [190/375], Loss: 0.0437\n",
      "Epoch [10/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [200/375], Loss: 0.0086\n",
      "Epoch [10/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [210/375], Loss: 0.0943\n",
      "Epoch [10/40], Step [210/375], Accuracy: 0.9688\n",
      "Epoch [10/40], Step [220/375], Loss: 0.0178\n",
      "Epoch [10/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [230/375], Loss: 0.0285\n",
      "Epoch [10/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [10/40], Step [240/375], Loss: 0.0129\n",
      "Epoch [10/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [250/375], Loss: 0.0371\n",
      "Epoch [10/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [10/40], Step [260/375], Loss: 0.0061\n",
      "Epoch [10/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [270/375], Loss: 0.0100\n",
      "Epoch [10/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [280/375], Loss: 0.0401\n",
      "Epoch [10/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [10/40], Step [290/375], Loss: 0.1681\n",
      "Epoch [10/40], Step [290/375], Accuracy: 0.9688\n",
      "Epoch [10/40], Step [300/375], Loss: 0.0279\n",
      "Epoch [10/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [310/375], Loss: 0.0698\n",
      "Epoch [10/40], Step [310/375], Accuracy: 0.9766\n",
      "Epoch [10/40], Step [320/375], Loss: 0.0992\n",
      "Epoch [10/40], Step [320/375], Accuracy: 0.9688\n",
      "Epoch [10/40], Step [330/375], Loss: 0.0269\n",
      "Epoch [10/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [340/375], Loss: 0.0174\n",
      "Epoch [10/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [350/375], Loss: 0.0139\n",
      "Epoch [10/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [360/375], Loss: 0.0105\n",
      "Epoch [10/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [10/40], Step [370/375], Loss: 0.0007\n",
      "Epoch [10/40], Step [370/375], Accuracy: 1.0000\n",
      "Epoch [10/40], Step [0/94], Loss: 0.0636 Accuracy: 0.9844\n",
      "Epoch [10/40], Step [10/94], Loss: 0.0302 Accuracy: 0.9922\n",
      "Epoch [10/40], Step [20/94], Loss: 0.0063 Accuracy: 1.0000\n",
      "Epoch [10/40], Step [30/94], Loss: 0.0357 Accuracy: 0.9844\n",
      "Epoch [10/40], Step [40/94], Loss: 0.0143 Accuracy: 0.9922\n",
      "Epoch [10/40], Step [50/94], Loss: 0.0522 Accuracy: 0.9922\n",
      "Epoch [10/40], Step [60/94], Loss: 0.0175 Accuracy: 1.0000\n",
      "Epoch [10/40], Step [70/94], Loss: 0.0075 Accuracy: 1.0000\n",
      "Epoch [10/40], Step [80/94], Loss: 0.0179 Accuracy: 0.9844\n",
      "Epoch [10/40], Step [90/94], Loss: 0.0597 Accuracy: 0.9844\n",
      "Epoch: 9\tAverage Train Loss: 0.107486\tAverage Train Accuracy: 0.967371\n",
      "Epoch: 9\tAverage Validation Loss: 0.047823\tAverage Validation Accuracy: 0.985857\n",
      "Epoch: 9\tAverage Test Loss: 0.044276\tAverage Test Accuracy: 0.987629\n",
      "Epoch [11/40], Step [0/375], Loss: 0.0992\n",
      "Epoch [11/40], Step [0/375], Accuracy: 0.9688\n",
      "Epoch [11/40], Step [10/375], Loss: 0.0885\n",
      "Epoch [11/40], Step [10/375], Accuracy: 0.9688\n",
      "Epoch [11/40], Step [20/375], Loss: 0.0083\n",
      "Epoch [11/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [30/375], Loss: 0.0068\n",
      "Epoch [11/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [40/375], Loss: 0.0782\n",
      "Epoch [11/40], Step [40/375], Accuracy: 0.9766\n",
      "Epoch [11/40], Step [50/375], Loss: 0.0711\n",
      "Epoch [11/40], Step [50/375], Accuracy: 0.9766\n",
      "Epoch [11/40], Step [60/375], Loss: 0.0391\n",
      "Epoch [11/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [70/375], Loss: 0.0029\n",
      "Epoch [11/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [80/375], Loss: 0.0137\n",
      "Epoch [11/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [90/375], Loss: 0.0503\n",
      "Epoch [11/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [100/375], Loss: 0.0022\n",
      "Epoch [11/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [110/375], Loss: 0.0883\n",
      "Epoch [11/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [120/375], Loss: 0.0187\n",
      "Epoch [11/40], Step [120/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [130/375], Loss: 0.0334\n",
      "Epoch [11/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [140/375], Loss: 0.0132\n",
      "Epoch [11/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [150/375], Loss: 0.0224\n",
      "Epoch [11/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [160/375], Loss: 0.0016\n",
      "Epoch [11/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [170/375], Loss: 0.0252\n",
      "Epoch [11/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [180/375], Loss: 0.1170\n",
      "Epoch [11/40], Step [180/375], Accuracy: 0.9766\n",
      "Epoch [11/40], Step [190/375], Loss: 0.0143\n",
      "Epoch [11/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [200/375], Loss: 0.0689\n",
      "Epoch [11/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [210/375], Loss: 0.0767\n",
      "Epoch [11/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [220/375], Loss: 0.1021\n",
      "Epoch [11/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [230/375], Loss: 0.0607\n",
      "Epoch [11/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [240/375], Loss: 0.0118\n",
      "Epoch [11/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [250/375], Loss: 0.0229\n",
      "Epoch [11/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [260/375], Loss: 0.1099\n",
      "Epoch [11/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [11/40], Step [270/375], Loss: 0.0044\n",
      "Epoch [11/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [280/375], Loss: 0.1128\n",
      "Epoch [11/40], Step [280/375], Accuracy: 0.9609\n",
      "Epoch [11/40], Step [290/375], Loss: 0.0656\n",
      "Epoch [11/40], Step [290/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [300/375], Loss: 0.0155\n",
      "Epoch [11/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [310/375], Loss: 0.0725\n",
      "Epoch [11/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [320/375], Loss: 0.0485\n",
      "Epoch [11/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [330/375], Loss: 0.0113\n",
      "Epoch [11/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [340/375], Loss: 0.0172\n",
      "Epoch [11/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [11/40], Step [350/375], Loss: 0.0447\n",
      "Epoch [11/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [11/40], Step [360/375], Loss: 0.0422\n",
      "Epoch [11/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [11/40], Step [370/375], Loss: 0.0120\n",
      "Epoch [11/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [11/40], Step [0/94], Loss: 0.0259 Accuracy: 0.9922\n",
      "Epoch [11/40], Step [10/94], Loss: 0.0253 Accuracy: 0.9844\n",
      "Epoch [11/40], Step [20/94], Loss: 0.0445 Accuracy: 0.9844\n",
      "Epoch [11/40], Step [30/94], Loss: 0.1014 Accuracy: 0.9922\n",
      "Epoch [11/40], Step [40/94], Loss: 0.0146 Accuracy: 0.9922\n",
      "Epoch [11/40], Step [50/94], Loss: 0.0817 Accuracy: 0.9844\n",
      "Epoch [11/40], Step [60/94], Loss: 0.0850 Accuracy: 0.9766\n",
      "Epoch [11/40], Step [70/94], Loss: 0.0409 Accuracy: 0.9922\n",
      "Epoch [11/40], Step [80/94], Loss: 0.0227 Accuracy: 0.9922\n",
      "Epoch [11/40], Step [90/94], Loss: 0.0620 Accuracy: 0.9688\n",
      "Epoch: 10\tAverage Train Loss: 0.101838\tAverage Train Accuracy: 0.969227\n",
      "Epoch: 10\tAverage Validation Loss: 0.047642\tAverage Validation Accuracy: 0.985891\n",
      "Epoch: 10\tAverage Test Loss: 0.043748\tAverage Test Accuracy: 0.987800\n",
      "Epoch [12/40], Step [0/375], Loss: 0.0492\n",
      "Epoch [12/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [10/375], Loss: 0.0558\n",
      "Epoch [12/40], Step [10/375], Accuracy: 0.9766\n",
      "Epoch [12/40], Step [20/375], Loss: 0.0028\n",
      "Epoch [12/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [30/375], Loss: 0.0076\n",
      "Epoch [12/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [40/375], Loss: 0.0077\n",
      "Epoch [12/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [50/375], Loss: 0.0323\n",
      "Epoch [12/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [60/375], Loss: 0.0432\n",
      "Epoch [12/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [70/375], Loss: 0.0253\n",
      "Epoch [12/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [80/375], Loss: 0.0256\n",
      "Epoch [12/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [90/375], Loss: 0.0284\n",
      "Epoch [12/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [100/375], Loss: 0.0279\n",
      "Epoch [12/40], Step [100/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [110/375], Loss: 0.0007\n",
      "Epoch [12/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [120/375], Loss: 0.0078\n",
      "Epoch [12/40], Step [120/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [130/375], Loss: 0.0517\n",
      "Epoch [12/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [140/375], Loss: 0.0556\n",
      "Epoch [12/40], Step [140/375], Accuracy: 0.9688\n",
      "Epoch [12/40], Step [150/375], Loss: 0.0719\n",
      "Epoch [12/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [160/375], Loss: 0.0179\n",
      "Epoch [12/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [170/375], Loss: 0.0408\n",
      "Epoch [12/40], Step [170/375], Accuracy: 0.9766\n",
      "Epoch [12/40], Step [180/375], Loss: 0.0249\n",
      "Epoch [12/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [190/375], Loss: 0.0036\n",
      "Epoch [12/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [200/375], Loss: 0.0348\n",
      "Epoch [12/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [210/375], Loss: 0.0911\n",
      "Epoch [12/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [12/40], Step [220/375], Loss: 0.0184\n",
      "Epoch [12/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [230/375], Loss: 0.0102\n",
      "Epoch [12/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [240/375], Loss: 0.2044\n",
      "Epoch [12/40], Step [240/375], Accuracy: 0.9609\n",
      "Epoch [12/40], Step [250/375], Loss: 0.1260\n",
      "Epoch [12/40], Step [250/375], Accuracy: 0.9609\n",
      "Epoch [12/40], Step [260/375], Loss: 0.0029\n",
      "Epoch [12/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [270/375], Loss: 0.0304\n",
      "Epoch [12/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [12/40], Step [280/375], Loss: 0.0385\n",
      "Epoch [12/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [290/375], Loss: 0.0254\n",
      "Epoch [12/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [300/375], Loss: 0.0358\n",
      "Epoch [12/40], Step [300/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [310/375], Loss: 0.0493\n",
      "Epoch [12/40], Step [310/375], Accuracy: 0.9766\n",
      "Epoch [12/40], Step [320/375], Loss: 0.0679\n",
      "Epoch [12/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [12/40], Step [330/375], Loss: 0.1544\n",
      "Epoch [12/40], Step [330/375], Accuracy: 0.9609\n",
      "Epoch [12/40], Step [340/375], Loss: 0.0358\n",
      "Epoch [12/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [350/375], Loss: 0.1349\n",
      "Epoch [12/40], Step [350/375], Accuracy: 0.9609\n",
      "Epoch [12/40], Step [360/375], Loss: 0.0778\n",
      "Epoch [12/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [370/375], Loss: 0.0195\n",
      "Epoch [12/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [12/40], Step [0/94], Loss: 0.0106 Accuracy: 0.9922\n",
      "Epoch [12/40], Step [10/94], Loss: 0.0004 Accuracy: 1.0000\n",
      "Epoch [12/40], Step [20/94], Loss: 0.0274 Accuracy: 0.9922\n",
      "Epoch [12/40], Step [30/94], Loss: 0.0254 Accuracy: 0.9844\n",
      "Epoch [12/40], Step [40/94], Loss: 0.0618 Accuracy: 0.9844\n",
      "Epoch [12/40], Step [50/94], Loss: 0.0009 Accuracy: 1.0000\n",
      "Epoch [12/40], Step [60/94], Loss: 0.0363 Accuracy: 0.9844\n",
      "Epoch [12/40], Step [70/94], Loss: 0.0353 Accuracy: 0.9844\n",
      "Epoch [12/40], Step [80/94], Loss: 0.0063 Accuracy: 1.0000\n",
      "Epoch [12/40], Step [90/94], Loss: 0.0139 Accuracy: 0.9922\n",
      "Epoch: 11\tAverage Train Loss: 0.097201\tAverage Train Accuracy: 0.970724\n",
      "Epoch: 11\tAverage Validation Loss: 0.046559\tAverage Validation Accuracy: 0.986243\n",
      "Epoch: 11\tAverage Test Loss: 0.042245\tAverage Test Accuracy: 0.988141\n",
      "Epoch [13/40], Step [0/375], Loss: 0.0551\n",
      "Epoch [13/40], Step [0/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [10/375], Loss: 0.0094\n",
      "Epoch [13/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [20/375], Loss: 0.0441\n",
      "Epoch [13/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [30/375], Loss: 0.0552\n",
      "Epoch [13/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [40/375], Loss: 0.0075\n",
      "Epoch [13/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [50/375], Loss: 0.0048\n",
      "Epoch [13/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [60/375], Loss: 0.0290\n",
      "Epoch [13/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [70/375], Loss: 0.0587\n",
      "Epoch [13/40], Step [70/375], Accuracy: 0.9766\n",
      "Epoch [13/40], Step [80/375], Loss: 0.0166\n",
      "Epoch [13/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [90/375], Loss: 0.0272\n",
      "Epoch [13/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [100/375], Loss: 0.0081\n",
      "Epoch [13/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [110/375], Loss: 0.0382\n",
      "Epoch [13/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [120/375], Loss: 0.0281\n",
      "Epoch [13/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [130/375], Loss: 0.0284\n",
      "Epoch [13/40], Step [130/375], Accuracy: 0.9766\n",
      "Epoch [13/40], Step [140/375], Loss: 0.0646\n",
      "Epoch [13/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [150/375], Loss: 0.0105\n",
      "Epoch [13/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [160/375], Loss: 0.0293\n",
      "Epoch [13/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [170/375], Loss: 0.0054\n",
      "Epoch [13/40], Step [170/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [180/375], Loss: 0.0455\n",
      "Epoch [13/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [190/375], Loss: 0.0591\n",
      "Epoch [13/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [200/375], Loss: 0.0341\n",
      "Epoch [13/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [210/375], Loss: 0.0734\n",
      "Epoch [13/40], Step [210/375], Accuracy: 0.9688\n",
      "Epoch [13/40], Step [220/375], Loss: 0.0774\n",
      "Epoch [13/40], Step [220/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [230/375], Loss: 0.0296\n",
      "Epoch [13/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [240/375], Loss: 0.0008\n",
      "Epoch [13/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [250/375], Loss: 0.0413\n",
      "Epoch [13/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [260/375], Loss: 0.0813\n",
      "Epoch [13/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [13/40], Step [270/375], Loss: 0.0164\n",
      "Epoch [13/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [280/375], Loss: 0.0240\n",
      "Epoch [13/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [290/375], Loss: 0.0225\n",
      "Epoch [13/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [300/375], Loss: 0.0210\n",
      "Epoch [13/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [310/375], Loss: 0.0352\n",
      "Epoch [13/40], Step [310/375], Accuracy: 0.9766\n",
      "Epoch [13/40], Step [320/375], Loss: 0.1238\n",
      "Epoch [13/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [13/40], Step [330/375], Loss: 0.0062\n",
      "Epoch [13/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [340/375], Loss: 0.1072\n",
      "Epoch [13/40], Step [340/375], Accuracy: 0.9766\n",
      "Epoch [13/40], Step [350/375], Loss: 0.1905\n",
      "Epoch [13/40], Step [350/375], Accuracy: 0.9688\n",
      "Epoch [13/40], Step [360/375], Loss: 0.0259\n",
      "Epoch [13/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [13/40], Step [370/375], Loss: 0.0306\n",
      "Epoch [13/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [13/40], Step [0/94], Loss: 0.0073 Accuracy: 1.0000\n",
      "Epoch [13/40], Step [10/94], Loss: 0.0035 Accuracy: 1.0000\n",
      "Epoch [13/40], Step [20/94], Loss: 0.0105 Accuracy: 0.9922\n",
      "Epoch [13/40], Step [30/94], Loss: 0.0196 Accuracy: 0.9922\n",
      "Epoch [13/40], Step [40/94], Loss: 0.0047 Accuracy: 1.0000\n",
      "Epoch [13/40], Step [50/94], Loss: 0.0335 Accuracy: 0.9844\n",
      "Epoch [13/40], Step [60/94], Loss: 0.0044 Accuracy: 1.0000\n",
      "Epoch [13/40], Step [70/94], Loss: 0.1332 Accuracy: 0.9844\n",
      "Epoch [13/40], Step [80/94], Loss: 0.0109 Accuracy: 1.0000\n",
      "Epoch [13/40], Step [90/94], Loss: 0.0096 Accuracy: 1.0000\n",
      "Epoch: 12\tAverage Train Loss: 0.092747\tAverage Train Accuracy: 0.972154\n",
      "Epoch: 12\tAverage Validation Loss: 0.045824\tAverage Validation Accuracy: 0.986566\n",
      "Epoch: 12\tAverage Test Loss: 0.042020\tAverage Test Accuracy: 0.988293\n",
      "Epoch [14/40], Step [0/375], Loss: 0.0051\n",
      "Epoch [14/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [10/375], Loss: 0.0878\n",
      "Epoch [14/40], Step [10/375], Accuracy: 0.9688\n",
      "Epoch [14/40], Step [20/375], Loss: 0.0099\n",
      "Epoch [14/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [30/375], Loss: 0.0449\n",
      "Epoch [14/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [40/375], Loss: 0.0796\n",
      "Epoch [14/40], Step [40/375], Accuracy: 0.9609\n",
      "Epoch [14/40], Step [50/375], Loss: 0.0168\n",
      "Epoch [14/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [60/375], Loss: 0.0206\n",
      "Epoch [14/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [70/375], Loss: 0.0167\n",
      "Epoch [14/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [80/375], Loss: 0.0021\n",
      "Epoch [14/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [90/375], Loss: 0.1006\n",
      "Epoch [14/40], Step [90/375], Accuracy: 0.9766\n",
      "Epoch [14/40], Step [100/375], Loss: 0.1763\n",
      "Epoch [14/40], Step [100/375], Accuracy: 0.9688\n",
      "Epoch [14/40], Step [110/375], Loss: 0.0620\n",
      "Epoch [14/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [14/40], Step [120/375], Loss: 0.0640\n",
      "Epoch [14/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [130/375], Loss: 0.0540\n",
      "Epoch [14/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [14/40], Step [140/375], Loss: 0.0178\n",
      "Epoch [14/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [150/375], Loss: 0.0197\n",
      "Epoch [14/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [160/375], Loss: 0.0762\n",
      "Epoch [14/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [14/40], Step [170/375], Loss: 0.0254\n",
      "Epoch [14/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [180/375], Loss: 0.0031\n",
      "Epoch [14/40], Step [180/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [190/375], Loss: 0.0322\n",
      "Epoch [14/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [200/375], Loss: 0.0045\n",
      "Epoch [14/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [210/375], Loss: 0.0100\n",
      "Epoch [14/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [220/375], Loss: 0.0109\n",
      "Epoch [14/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [230/375], Loss: 0.0982\n",
      "Epoch [14/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [240/375], Loss: 0.0150\n",
      "Epoch [14/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [250/375], Loss: 0.0752\n",
      "Epoch [14/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [14/40], Step [260/375], Loss: 0.0651\n",
      "Epoch [14/40], Step [260/375], Accuracy: 0.9844\n",
      "Epoch [14/40], Step [270/375], Loss: 0.1080\n",
      "Epoch [14/40], Step [270/375], Accuracy: 0.9688\n",
      "Epoch [14/40], Step [280/375], Loss: 0.0562\n",
      "Epoch [14/40], Step [280/375], Accuracy: 0.9766\n",
      "Epoch [14/40], Step [290/375], Loss: 0.0034\n",
      "Epoch [14/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [300/375], Loss: 0.0886\n",
      "Epoch [14/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [310/375], Loss: 0.0163\n",
      "Epoch [14/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [320/375], Loss: 0.0577\n",
      "Epoch [14/40], Step [320/375], Accuracy: 0.9609\n",
      "Epoch [14/40], Step [330/375], Loss: 0.0712\n",
      "Epoch [14/40], Step [330/375], Accuracy: 0.9688\n",
      "Epoch [14/40], Step [340/375], Loss: 0.0277\n",
      "Epoch [14/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [14/40], Step [350/375], Loss: 0.0084\n",
      "Epoch [14/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [14/40], Step [360/375], Loss: 0.1780\n",
      "Epoch [14/40], Step [360/375], Accuracy: 0.9453\n",
      "Epoch [14/40], Step [370/375], Loss: 0.0995\n",
      "Epoch [14/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [14/40], Step [0/94], Loss: 0.0090 Accuracy: 1.0000\n",
      "Epoch [14/40], Step [10/94], Loss: 0.0225 Accuracy: 0.9922\n",
      "Epoch [14/40], Step [20/94], Loss: 0.0091 Accuracy: 1.0000\n",
      "Epoch [14/40], Step [30/94], Loss: 0.0325 Accuracy: 0.9766\n",
      "Epoch [14/40], Step [40/94], Loss: 0.0116 Accuracy: 0.9922\n",
      "Epoch [14/40], Step [50/94], Loss: 0.0055 Accuracy: 1.0000\n",
      "Epoch [14/40], Step [60/94], Loss: 0.0277 Accuracy: 0.9922\n",
      "Epoch [14/40], Step [70/94], Loss: 0.0085 Accuracy: 1.0000\n",
      "Epoch [14/40], Step [80/94], Loss: 0.0355 Accuracy: 0.9844\n",
      "Epoch [14/40], Step [90/94], Loss: 0.0066 Accuracy: 1.0000\n",
      "Epoch: 13\tAverage Train Loss: 0.089104\tAverage Train Accuracy: 0.973295\n",
      "Epoch: 13\tAverage Validation Loss: 0.044737\tAverage Validation Accuracy: 0.986884\n",
      "Epoch: 13\tAverage Test Loss: 0.040885\tAverage Test Accuracy: 0.988606\n",
      "Epoch [15/40], Step [0/375], Loss: 0.0481\n",
      "Epoch [15/40], Step [0/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [10/375], Loss: 0.0362\n",
      "Epoch [15/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [20/375], Loss: 0.0149\n",
      "Epoch [15/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [30/375], Loss: 0.0078\n",
      "Epoch [15/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [40/375], Loss: 0.0339\n",
      "Epoch [15/40], Step [40/375], Accuracy: 0.9766\n",
      "Epoch [15/40], Step [50/375], Loss: 0.0279\n",
      "Epoch [15/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [60/375], Loss: 0.0300\n",
      "Epoch [15/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [70/375], Loss: 0.0399\n",
      "Epoch [15/40], Step [70/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [80/375], Loss: 0.0978\n",
      "Epoch [15/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [90/375], Loss: 0.0320\n",
      "Epoch [15/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [100/375], Loss: 0.0029\n",
      "Epoch [15/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [110/375], Loss: 0.0053\n",
      "Epoch [15/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [120/375], Loss: 0.0260\n",
      "Epoch [15/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [130/375], Loss: 0.0058\n",
      "Epoch [15/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [140/375], Loss: 0.0157\n",
      "Epoch [15/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [150/375], Loss: 0.0167\n",
      "Epoch [15/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [160/375], Loss: 0.0042\n",
      "Epoch [15/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [170/375], Loss: 0.0049\n",
      "Epoch [15/40], Step [170/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [180/375], Loss: 0.0254\n",
      "Epoch [15/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [190/375], Loss: 0.1189\n",
      "Epoch [15/40], Step [190/375], Accuracy: 0.9766\n",
      "Epoch [15/40], Step [200/375], Loss: 0.0439\n",
      "Epoch [15/40], Step [200/375], Accuracy: 0.9766\n",
      "Epoch [15/40], Step [210/375], Loss: 0.0262\n",
      "Epoch [15/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [220/375], Loss: 0.0025\n",
      "Epoch [15/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [230/375], Loss: 0.0286\n",
      "Epoch [15/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [240/375], Loss: 0.0169\n",
      "Epoch [15/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [250/375], Loss: 0.0039\n",
      "Epoch [15/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [15/40], Step [260/375], Loss: 0.0423\n",
      "Epoch [15/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [270/375], Loss: 0.0293\n",
      "Epoch [15/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [15/40], Step [280/375], Loss: 0.0145\n",
      "Epoch [15/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [290/375], Loss: 0.0972\n",
      "Epoch [15/40], Step [290/375], Accuracy: 0.9766\n",
      "Epoch [15/40], Step [300/375], Loss: 0.1082\n",
      "Epoch [15/40], Step [300/375], Accuracy: 0.9766\n",
      "Epoch [15/40], Step [310/375], Loss: 0.0203\n",
      "Epoch [15/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [320/375], Loss: 0.0365\n",
      "Epoch [15/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [330/375], Loss: 0.1251\n",
      "Epoch [15/40], Step [330/375], Accuracy: 0.9609\n",
      "Epoch [15/40], Step [340/375], Loss: 0.0131\n",
      "Epoch [15/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [350/375], Loss: 0.0585\n",
      "Epoch [15/40], Step [350/375], Accuracy: 0.9766\n",
      "Epoch [15/40], Step [360/375], Loss: 0.1599\n",
      "Epoch [15/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [15/40], Step [370/375], Loss: 0.0200\n",
      "Epoch [15/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [15/40], Step [0/94], Loss: 0.0712 Accuracy: 0.9766\n",
      "Epoch [15/40], Step [10/94], Loss: 0.0441 Accuracy: 0.9844\n",
      "Epoch [15/40], Step [20/94], Loss: 0.0367 Accuracy: 0.9922\n",
      "Epoch [15/40], Step [30/94], Loss: 0.0675 Accuracy: 0.9844\n",
      "Epoch [15/40], Step [40/94], Loss: 0.0199 Accuracy: 1.0000\n",
      "Epoch [15/40], Step [50/94], Loss: 0.0416 Accuracy: 0.9844\n",
      "Epoch [15/40], Step [60/94], Loss: 0.0431 Accuracy: 0.9922\n",
      "Epoch [15/40], Step [70/94], Loss: 0.0791 Accuracy: 0.9844\n",
      "Epoch [15/40], Step [80/94], Loss: 0.0340 Accuracy: 1.0000\n",
      "Epoch [15/40], Step [90/94], Loss: 0.0146 Accuracy: 1.0000\n",
      "Epoch: 14\tAverage Train Loss: 0.085744\tAverage Train Accuracy: 0.974354\n",
      "Epoch: 14\tAverage Validation Loss: 0.045537\tAverage Validation Accuracy: 0.986789\n",
      "Epoch: 14\tAverage Test Loss: 0.042256\tAverage Test Accuracy: 0.988350\n",
      "Epoch [16/40], Step [0/375], Loss: 0.0806\n",
      "Epoch [16/40], Step [0/375], Accuracy: 0.9688\n",
      "Epoch [16/40], Step [10/375], Loss: 0.0060\n",
      "Epoch [16/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [20/375], Loss: 0.0133\n",
      "Epoch [16/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [30/375], Loss: 0.0018\n",
      "Epoch [16/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [40/375], Loss: 0.0015\n",
      "Epoch [16/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [50/375], Loss: 0.0469\n",
      "Epoch [16/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [60/375], Loss: 0.0682\n",
      "Epoch [16/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [70/375], Loss: 0.0083\n",
      "Epoch [16/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [80/375], Loss: 0.0040\n",
      "Epoch [16/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [90/375], Loss: 0.0208\n",
      "Epoch [16/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [100/375], Loss: 0.0258\n",
      "Epoch [16/40], Step [100/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [110/375], Loss: 0.1620\n",
      "Epoch [16/40], Step [110/375], Accuracy: 0.9688\n",
      "Epoch [16/40], Step [120/375], Loss: 0.0850\n",
      "Epoch [16/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [130/375], Loss: 0.1229\n",
      "Epoch [16/40], Step [130/375], Accuracy: 0.9766\n",
      "Epoch [16/40], Step [140/375], Loss: 0.0456\n",
      "Epoch [16/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [16/40], Step [150/375], Loss: 0.0333\n",
      "Epoch [16/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [160/375], Loss: 0.0300\n",
      "Epoch [16/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [170/375], Loss: 0.0346\n",
      "Epoch [16/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [180/375], Loss: 0.0820\n",
      "Epoch [16/40], Step [180/375], Accuracy: 0.9609\n",
      "Epoch [16/40], Step [190/375], Loss: 0.0370\n",
      "Epoch [16/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [200/375], Loss: 0.0069\n",
      "Epoch [16/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [210/375], Loss: 0.0159\n",
      "Epoch [16/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [220/375], Loss: 0.0021\n",
      "Epoch [16/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [230/375], Loss: 0.0077\n",
      "Epoch [16/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [240/375], Loss: 0.0231\n",
      "Epoch [16/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [250/375], Loss: 0.0538\n",
      "Epoch [16/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [260/375], Loss: 0.0044\n",
      "Epoch [16/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [270/375], Loss: 0.0086\n",
      "Epoch [16/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [280/375], Loss: 0.0638\n",
      "Epoch [16/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [290/375], Loss: 0.0513\n",
      "Epoch [16/40], Step [290/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [300/375], Loss: 0.0179\n",
      "Epoch [16/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [310/375], Loss: 0.0201\n",
      "Epoch [16/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [16/40], Step [320/375], Loss: 0.0258\n",
      "Epoch [16/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [16/40], Step [330/375], Loss: 0.0166\n",
      "Epoch [16/40], Step [330/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [340/375], Loss: 0.0688\n",
      "Epoch [16/40], Step [340/375], Accuracy: 0.9766\n",
      "Epoch [16/40], Step [350/375], Loss: 0.1255\n",
      "Epoch [16/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [360/375], Loss: 0.0645\n",
      "Epoch [16/40], Step [360/375], Accuracy: 0.9688\n",
      "Epoch [16/40], Step [370/375], Loss: 0.0234\n",
      "Epoch [16/40], Step [370/375], Accuracy: 0.9844\n",
      "Epoch [16/40], Step [0/94], Loss: 0.0058 Accuracy: 1.0000\n",
      "Epoch [16/40], Step [10/94], Loss: 0.0065 Accuracy: 1.0000\n",
      "Epoch [16/40], Step [20/94], Loss: 0.0253 Accuracy: 0.9922\n",
      "Epoch [16/40], Step [30/94], Loss: 0.0720 Accuracy: 0.9844\n",
      "Epoch [16/40], Step [40/94], Loss: 0.0097 Accuracy: 0.9922\n",
      "Epoch [16/40], Step [50/94], Loss: 0.0027 Accuracy: 1.0000\n",
      "Epoch [16/40], Step [60/94], Loss: 0.0048 Accuracy: 1.0000\n",
      "Epoch [16/40], Step [70/94], Loss: 0.0593 Accuracy: 0.9844\n",
      "Epoch [16/40], Step [80/94], Loss: 0.0328 Accuracy: 0.9844\n",
      "Epoch [16/40], Step [90/94], Loss: 0.0846 Accuracy: 0.9844\n",
      "Epoch: 15\tAverage Train Loss: 0.083181\tAverage Train Accuracy: 0.975172\n",
      "Epoch: 15\tAverage Validation Loss: 0.046305\tAverage Validation Accuracy: 0.986737\n",
      "Epoch: 15\tAverage Test Loss: 0.043159\tAverage Test Accuracy: 0.988294\n",
      "Epoch [17/40], Step [0/375], Loss: 0.0320\n",
      "Epoch [17/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [10/375], Loss: 0.0131\n",
      "Epoch [17/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [20/375], Loss: 0.0307\n",
      "Epoch [17/40], Step [20/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [30/375], Loss: 0.0275\n",
      "Epoch [17/40], Step [30/375], Accuracy: 0.9766\n",
      "Epoch [17/40], Step [40/375], Loss: 0.0010\n",
      "Epoch [17/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [17/40], Step [50/375], Loss: 0.0291\n",
      "Epoch [17/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [60/375], Loss: 0.0040\n",
      "Epoch [17/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [17/40], Step [70/375], Loss: 0.0222\n",
      "Epoch [17/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [80/375], Loss: 0.0321\n",
      "Epoch [17/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [90/375], Loss: 0.0422\n",
      "Epoch [17/40], Step [90/375], Accuracy: 0.9766\n",
      "Epoch [17/40], Step [100/375], Loss: 0.0277\n",
      "Epoch [17/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [110/375], Loss: 0.0418\n",
      "Epoch [17/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [120/375], Loss: 0.0998\n",
      "Epoch [17/40], Step [120/375], Accuracy: 0.9609\n",
      "Epoch [17/40], Step [130/375], Loss: 0.0116\n",
      "Epoch [17/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [17/40], Step [140/375], Loss: 0.0243\n",
      "Epoch [17/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [150/375], Loss: 0.0489\n",
      "Epoch [17/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [160/375], Loss: 0.0211\n",
      "Epoch [17/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [170/375], Loss: 0.0367\n",
      "Epoch [17/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [180/375], Loss: 0.0785\n",
      "Epoch [17/40], Step [180/375], Accuracy: 0.9766\n",
      "Epoch [17/40], Step [190/375], Loss: 0.0590\n",
      "Epoch [17/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [200/375], Loss: 0.0330\n",
      "Epoch [17/40], Step [200/375], Accuracy: 0.9766\n",
      "Epoch [17/40], Step [210/375], Loss: 0.0309\n",
      "Epoch [17/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [220/375], Loss: 0.0243\n",
      "Epoch [17/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [230/375], Loss: 0.0029\n",
      "Epoch [17/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [17/40], Step [240/375], Loss: 0.0653\n",
      "Epoch [17/40], Step [240/375], Accuracy: 0.9688\n",
      "Epoch [17/40], Step [250/375], Loss: 0.0086\n",
      "Epoch [17/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [17/40], Step [260/375], Loss: 0.0316\n",
      "Epoch [17/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [270/375], Loss: 0.0226\n",
      "Epoch [17/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [280/375], Loss: 0.0093\n",
      "Epoch [17/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [290/375], Loss: 0.0593\n",
      "Epoch [17/40], Step [290/375], Accuracy: 0.9766\n",
      "Epoch [17/40], Step [300/375], Loss: 0.0375\n",
      "Epoch [17/40], Step [300/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [310/375], Loss: 0.1060\n",
      "Epoch [17/40], Step [310/375], Accuracy: 0.9688\n",
      "Epoch [17/40], Step [320/375], Loss: 0.0273\n",
      "Epoch [17/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [330/375], Loss: 0.0254\n",
      "Epoch [17/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [17/40], Step [340/375], Loss: 0.0252\n",
      "Epoch [17/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [17/40], Step [350/375], Loss: 0.0713\n",
      "Epoch [17/40], Step [350/375], Accuracy: 0.9766\n",
      "Epoch [17/40], Step [360/375], Loss: 0.0328\n",
      "Epoch [17/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [17/40], Step [370/375], Loss: 0.0041\n",
      "Epoch [17/40], Step [370/375], Accuracy: 1.0000\n",
      "Epoch [17/40], Step [0/94], Loss: 0.0029 Accuracy: 1.0000\n",
      "Epoch [17/40], Step [10/94], Loss: 0.0008 Accuracy: 1.0000\n",
      "Epoch [17/40], Step [20/94], Loss: 0.0869 Accuracy: 0.9844\n",
      "Epoch [17/40], Step [30/94], Loss: 0.0069 Accuracy: 1.0000\n",
      "Epoch [17/40], Step [40/94], Loss: 0.0094 Accuracy: 1.0000\n",
      "Epoch [17/40], Step [50/94], Loss: 0.0004 Accuracy: 1.0000\n",
      "Epoch [17/40], Step [60/94], Loss: 0.0141 Accuracy: 1.0000\n",
      "Epoch [17/40], Step [70/94], Loss: 0.0636 Accuracy: 0.9766\n",
      "Epoch [17/40], Step [80/94], Loss: 0.0502 Accuracy: 0.9844\n",
      "Epoch [17/40], Step [90/94], Loss: 0.0202 Accuracy: 0.9922\n",
      "Epoch: 16\tAverage Train Loss: 0.080511\tAverage Train Accuracy: 0.975995\n",
      "Epoch: 16\tAverage Validation Loss: 0.045222\tAverage Validation Accuracy: 0.987048\n",
      "Epoch: 16\tAverage Test Loss: 0.042431\tAverage Test Accuracy: 0.988558\n",
      "Epoch [18/40], Step [0/375], Loss: 0.0044\n",
      "Epoch [18/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [10/375], Loss: 0.0256\n",
      "Epoch [18/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [20/375], Loss: 0.0047\n",
      "Epoch [18/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [30/375], Loss: 0.0082\n",
      "Epoch [18/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [40/375], Loss: 0.0228\n",
      "Epoch [18/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [50/375], Loss: 0.0466\n",
      "Epoch [18/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [60/375], Loss: 0.1308\n",
      "Epoch [18/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [70/375], Loss: 0.0394\n",
      "Epoch [18/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [80/375], Loss: 0.0891\n",
      "Epoch [18/40], Step [80/375], Accuracy: 0.9766\n",
      "Epoch [18/40], Step [90/375], Loss: 0.0696\n",
      "Epoch [18/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [100/375], Loss: 0.0413\n",
      "Epoch [18/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [110/375], Loss: 0.0240\n",
      "Epoch [18/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [120/375], Loss: 0.0006\n",
      "Epoch [18/40], Step [120/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [130/375], Loss: 0.0165\n",
      "Epoch [18/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [140/375], Loss: 0.0266\n",
      "Epoch [18/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [150/375], Loss: 0.0009\n",
      "Epoch [18/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [160/375], Loss: 0.0706\n",
      "Epoch [18/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [170/375], Loss: 0.0631\n",
      "Epoch [18/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [180/375], Loss: 0.0497\n",
      "Epoch [18/40], Step [180/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [190/375], Loss: 0.0103\n",
      "Epoch [18/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [200/375], Loss: 0.0387\n",
      "Epoch [18/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [210/375], Loss: 0.0757\n",
      "Epoch [18/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [18/40], Step [220/375], Loss: 0.0463\n",
      "Epoch [18/40], Step [220/375], Accuracy: 0.9766\n",
      "Epoch [18/40], Step [230/375], Loss: 0.0415\n",
      "Epoch [18/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [240/375], Loss: 0.0046\n",
      "Epoch [18/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [250/375], Loss: 0.0561\n",
      "Epoch [18/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [260/375], Loss: 0.0608\n",
      "Epoch [18/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [270/375], Loss: 0.1570\n",
      "Epoch [18/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [280/375], Loss: 0.0278\n",
      "Epoch [18/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [290/375], Loss: 0.0048\n",
      "Epoch [18/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [300/375], Loss: 0.0065\n",
      "Epoch [18/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [18/40], Step [310/375], Loss: 0.0610\n",
      "Epoch [18/40], Step [310/375], Accuracy: 0.9609\n",
      "Epoch [18/40], Step [320/375], Loss: 0.0187\n",
      "Epoch [18/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [330/375], Loss: 0.0434\n",
      "Epoch [18/40], Step [330/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [340/375], Loss: 0.0438\n",
      "Epoch [18/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [350/375], Loss: 0.0787\n",
      "Epoch [18/40], Step [350/375], Accuracy: 0.9766\n",
      "Epoch [18/40], Step [360/375], Loss: 0.0406\n",
      "Epoch [18/40], Step [360/375], Accuracy: 0.9844\n",
      "Epoch [18/40], Step [370/375], Loss: 0.0178\n",
      "Epoch [18/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [18/40], Step [0/94], Loss: 0.0096 Accuracy: 0.9922\n",
      "Epoch [18/40], Step [10/94], Loss: 0.0155 Accuracy: 0.9922\n",
      "Epoch [18/40], Step [20/94], Loss: 0.0160 Accuracy: 0.9922\n",
      "Epoch [18/40], Step [30/94], Loss: 0.0162 Accuracy: 1.0000\n",
      "Epoch [18/40], Step [40/94], Loss: 0.0108 Accuracy: 1.0000\n",
      "Epoch [18/40], Step [50/94], Loss: 0.0514 Accuracy: 0.9844\n",
      "Epoch [18/40], Step [60/94], Loss: 0.0139 Accuracy: 0.9922\n",
      "Epoch [18/40], Step [70/94], Loss: 0.0961 Accuracy: 0.9766\n",
      "Epoch [18/40], Step [80/94], Loss: 0.0463 Accuracy: 0.9844\n",
      "Epoch [18/40], Step [90/94], Loss: 0.0483 Accuracy: 0.9766\n",
      "Epoch: 17\tAverage Train Loss: 0.078145\tAverage Train Accuracy: 0.976755\n",
      "Epoch: 17\tAverage Validation Loss: 0.044809\tAverage Validation Accuracy: 0.987269\n",
      "Epoch: 17\tAverage Test Loss: 0.041954\tAverage Test Accuracy: 0.988737\n",
      "Epoch [19/40], Step [0/375], Loss: 0.0073\n",
      "Epoch [19/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [19/40], Step [10/375], Loss: 0.0024\n",
      "Epoch [19/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [19/40], Step [20/375], Loss: 0.0480\n",
      "Epoch [19/40], Step [20/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [30/375], Loss: 0.0613\n",
      "Epoch [19/40], Step [30/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [40/375], Loss: 0.0554\n",
      "Epoch [19/40], Step [40/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [50/375], Loss: 0.0291\n",
      "Epoch [19/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [60/375], Loss: 0.0088\n",
      "Epoch [19/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [19/40], Step [70/375], Loss: 0.0355\n",
      "Epoch [19/40], Step [70/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [80/375], Loss: 0.0457\n",
      "Epoch [19/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [90/375], Loss: 0.0014\n",
      "Epoch [19/40], Step [90/375], Accuracy: 1.0000\n",
      "Epoch [19/40], Step [100/375], Loss: 0.0517\n",
      "Epoch [19/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [110/375], Loss: 0.0016\n",
      "Epoch [19/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [19/40], Step [120/375], Loss: 0.0124\n",
      "Epoch [19/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [130/375], Loss: 0.0884\n",
      "Epoch [19/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [140/375], Loss: 0.0453\n",
      "Epoch [19/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [150/375], Loss: 0.0138\n",
      "Epoch [19/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [160/375], Loss: 0.0443\n",
      "Epoch [19/40], Step [160/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [170/375], Loss: 0.0609\n",
      "Epoch [19/40], Step [170/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [180/375], Loss: 0.0648\n",
      "Epoch [19/40], Step [180/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [190/375], Loss: 0.0408\n",
      "Epoch [19/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [200/375], Loss: 0.0519\n",
      "Epoch [19/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [210/375], Loss: 0.0949\n",
      "Epoch [19/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [220/375], Loss: 0.0317\n",
      "Epoch [19/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [230/375], Loss: 0.1241\n",
      "Epoch [19/40], Step [230/375], Accuracy: 0.9688\n",
      "Epoch [19/40], Step [240/375], Loss: 0.0402\n",
      "Epoch [19/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [250/375], Loss: 0.1036\n",
      "Epoch [19/40], Step [250/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [260/375], Loss: 0.0930\n",
      "Epoch [19/40], Step [260/375], Accuracy: 0.9609\n",
      "Epoch [19/40], Step [270/375], Loss: 0.0123\n",
      "Epoch [19/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [280/375], Loss: 0.0668\n",
      "Epoch [19/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [290/375], Loss: 0.1131\n",
      "Epoch [19/40], Step [290/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [300/375], Loss: 0.0627\n",
      "Epoch [19/40], Step [300/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [310/375], Loss: 0.0610\n",
      "Epoch [19/40], Step [310/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [320/375], Loss: 0.0101\n",
      "Epoch [19/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [19/40], Step [330/375], Loss: 0.0417\n",
      "Epoch [19/40], Step [330/375], Accuracy: 0.9766\n",
      "Epoch [19/40], Step [340/375], Loss: 0.0057\n",
      "Epoch [19/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [19/40], Step [350/375], Loss: 0.0260\n",
      "Epoch [19/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [360/375], Loss: 0.0120\n",
      "Epoch [19/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [19/40], Step [370/375], Loss: 0.0469\n",
      "Epoch [19/40], Step [370/375], Accuracy: 0.9844\n",
      "Epoch [19/40], Step [0/94], Loss: 0.0016 Accuracy: 1.0000\n",
      "Epoch [19/40], Step [10/94], Loss: 0.0200 Accuracy: 0.9922\n",
      "Epoch [19/40], Step [20/94], Loss: 0.0100 Accuracy: 0.9922\n",
      "Epoch [19/40], Step [30/94], Loss: 0.0509 Accuracy: 0.9844\n",
      "Epoch [19/40], Step [40/94], Loss: 0.0182 Accuracy: 0.9922\n",
      "Epoch [19/40], Step [50/94], Loss: 0.0127 Accuracy: 0.9922\n",
      "Epoch [19/40], Step [60/94], Loss: 0.0238 Accuracy: 0.9922\n",
      "Epoch [19/40], Step [70/94], Loss: 0.0514 Accuracy: 0.9766\n",
      "Epoch [19/40], Step [80/94], Loss: 0.0627 Accuracy: 0.9844\n",
      "Epoch [19/40], Step [90/94], Loss: 0.0501 Accuracy: 0.9844\n",
      "Epoch: 18\tAverage Train Loss: 0.076327\tAverage Train Accuracy: 0.977385\n",
      "Epoch: 18\tAverage Validation Loss: 0.044206\tAverage Validation Accuracy: 0.987422\n",
      "Epoch: 18\tAverage Test Loss: 0.041662\tAverage Test Accuracy: 0.988830\n",
      "Epoch [20/40], Step [0/375], Loss: 0.0209\n",
      "Epoch [20/40], Step [0/375], Accuracy: 0.9844\n",
      "Epoch [20/40], Step [10/375], Loss: 0.0209\n",
      "Epoch [20/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [20/375], Loss: 0.0066\n",
      "Epoch [20/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [30/375], Loss: 0.0103\n",
      "Epoch [20/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [40/375], Loss: 0.0029\n",
      "Epoch [20/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [50/375], Loss: 0.0396\n",
      "Epoch [20/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [60/375], Loss: 0.1451\n",
      "Epoch [20/40], Step [60/375], Accuracy: 0.9766\n",
      "Epoch [20/40], Step [70/375], Loss: 0.0231\n",
      "Epoch [20/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [80/375], Loss: 0.0412\n",
      "Epoch [20/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [20/40], Step [90/375], Loss: 0.0637\n",
      "Epoch [20/40], Step [90/375], Accuracy: 0.9766\n",
      "Epoch [20/40], Step [100/375], Loss: 0.0830\n",
      "Epoch [20/40], Step [100/375], Accuracy: 0.9844\n",
      "Epoch [20/40], Step [110/375], Loss: 0.0284\n",
      "Epoch [20/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [120/375], Loss: 0.0090\n",
      "Epoch [20/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [130/375], Loss: 0.0417\n",
      "Epoch [20/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [20/40], Step [140/375], Loss: 0.0050\n",
      "Epoch [20/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [150/375], Loss: 0.0131\n",
      "Epoch [20/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [160/375], Loss: 0.0247\n",
      "Epoch [20/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [170/375], Loss: 0.0714\n",
      "Epoch [20/40], Step [170/375], Accuracy: 0.9766\n",
      "Epoch [20/40], Step [180/375], Loss: 0.0292\n",
      "Epoch [20/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [190/375], Loss: 0.0054\n",
      "Epoch [20/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [200/375], Loss: 0.0022\n",
      "Epoch [20/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [210/375], Loss: 0.0436\n",
      "Epoch [20/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [220/375], Loss: 0.0003\n",
      "Epoch [20/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [230/375], Loss: 0.0365\n",
      "Epoch [20/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [240/375], Loss: 0.0133\n",
      "Epoch [20/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [250/375], Loss: 0.0390\n",
      "Epoch [20/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [260/375], Loss: 0.0016\n",
      "Epoch [20/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [270/375], Loss: 0.0005\n",
      "Epoch [20/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [280/375], Loss: 0.0795\n",
      "Epoch [20/40], Step [280/375], Accuracy: 0.9766\n",
      "Epoch [20/40], Step [290/375], Loss: 0.0513\n",
      "Epoch [20/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [300/375], Loss: 0.0162\n",
      "Epoch [20/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [310/375], Loss: 0.0020\n",
      "Epoch [20/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [320/375], Loss: 0.0192\n",
      "Epoch [20/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [330/375], Loss: 0.0021\n",
      "Epoch [20/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [340/375], Loss: 0.0128\n",
      "Epoch [20/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [350/375], Loss: 0.0021\n",
      "Epoch [20/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [20/40], Step [360/375], Loss: 0.0434\n",
      "Epoch [20/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [20/40], Step [370/375], Loss: 0.0461\n",
      "Epoch [20/40], Step [370/375], Accuracy: 0.9844\n",
      "Epoch [20/40], Step [0/94], Loss: 0.0041 Accuracy: 1.0000\n",
      "Epoch [20/40], Step [10/94], Loss: 0.0045 Accuracy: 1.0000\n",
      "Epoch [20/40], Step [20/94], Loss: 0.0130 Accuracy: 0.9922\n",
      "Epoch [20/40], Step [30/94], Loss: 0.0224 Accuracy: 1.0000\n",
      "Epoch [20/40], Step [40/94], Loss: 0.0096 Accuracy: 1.0000\n",
      "Epoch [20/40], Step [50/94], Loss: 0.0016 Accuracy: 1.0000\n",
      "Epoch [20/40], Step [60/94], Loss: 0.0218 Accuracy: 0.9922\n",
      "Epoch [20/40], Step [70/94], Loss: 0.0132 Accuracy: 0.9922\n",
      "Epoch [20/40], Step [80/94], Loss: 0.0154 Accuracy: 0.9922\n",
      "Epoch [20/40], Step [90/94], Loss: 0.0980 Accuracy: 0.9922\n",
      "Epoch: 19\tAverage Train Loss: 0.074222\tAverage Train Accuracy: 0.978047\n",
      "Epoch: 19\tAverage Validation Loss: 0.043881\tAverage Validation Accuracy: 0.987619\n",
      "Epoch: 19\tAverage Test Loss: 0.041198\tAverage Test Accuracy: 0.989013\n",
      "Epoch [21/40], Step [0/375], Loss: 0.0098\n",
      "Epoch [21/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [10/375], Loss: 0.0005\n",
      "Epoch [21/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [20/375], Loss: 0.0917\n",
      "Epoch [21/40], Step [20/375], Accuracy: 0.9766\n",
      "Epoch [21/40], Step [30/375], Loss: 0.0060\n",
      "Epoch [21/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [40/375], Loss: 0.0050\n",
      "Epoch [21/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [50/375], Loss: 0.0077\n",
      "Epoch [21/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [60/375], Loss: 0.0079\n",
      "Epoch [21/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [70/375], Loss: 0.0023\n",
      "Epoch [21/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [80/375], Loss: 0.0328\n",
      "Epoch [21/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [90/375], Loss: 0.0190\n",
      "Epoch [21/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [100/375], Loss: 0.0267\n",
      "Epoch [21/40], Step [100/375], Accuracy: 0.9844\n",
      "Epoch [21/40], Step [110/375], Loss: 0.0129\n",
      "Epoch [21/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [120/375], Loss: 0.1002\n",
      "Epoch [21/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [130/375], Loss: 0.1258\n",
      "Epoch [21/40], Step [130/375], Accuracy: 0.9766\n",
      "Epoch [21/40], Step [140/375], Loss: 0.0014\n",
      "Epoch [21/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [150/375], Loss: 0.0039\n",
      "Epoch [21/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [160/375], Loss: 0.0254\n",
      "Epoch [21/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [170/375], Loss: 0.0229\n",
      "Epoch [21/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [180/375], Loss: 0.0001\n",
      "Epoch [21/40], Step [180/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [190/375], Loss: 0.1774\n",
      "Epoch [21/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [21/40], Step [200/375], Loss: 0.0087\n",
      "Epoch [21/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [210/375], Loss: 0.0155\n",
      "Epoch [21/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [220/375], Loss: 0.0013\n",
      "Epoch [21/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [230/375], Loss: 0.0151\n",
      "Epoch [21/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [240/375], Loss: 0.0409\n",
      "Epoch [21/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [250/375], Loss: 0.0032\n",
      "Epoch [21/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [260/375], Loss: 0.0107\n",
      "Epoch [21/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [270/375], Loss: 0.0235\n",
      "Epoch [21/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [280/375], Loss: 0.0137\n",
      "Epoch [21/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [290/375], Loss: 0.0075\n",
      "Epoch [21/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [300/375], Loss: 0.0084\n",
      "Epoch [21/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [310/375], Loss: 0.0027\n",
      "Epoch [21/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [320/375], Loss: 0.0229\n",
      "Epoch [21/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [330/375], Loss: 0.0021\n",
      "Epoch [21/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [21/40], Step [340/375], Loss: 0.0947\n",
      "Epoch [21/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [21/40], Step [350/375], Loss: 0.0179\n",
      "Epoch [21/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [360/375], Loss: 0.0201\n",
      "Epoch [21/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [21/40], Step [370/375], Loss: 0.0875\n",
      "Epoch [21/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [21/40], Step [0/94], Loss: 0.0056 Accuracy: 1.0000\n",
      "Epoch [21/40], Step [10/94], Loss: 0.0008 Accuracy: 1.0000\n",
      "Epoch [21/40], Step [20/94], Loss: 0.0026 Accuracy: 1.0000\n",
      "Epoch [21/40], Step [30/94], Loss: 0.0480 Accuracy: 0.9844\n",
      "Epoch [21/40], Step [40/94], Loss: 0.0051 Accuracy: 1.0000\n",
      "Epoch [21/40], Step [50/94], Loss: 0.0033 Accuracy: 1.0000\n",
      "Epoch [21/40], Step [60/94], Loss: 0.0282 Accuracy: 0.9922\n",
      "Epoch [21/40], Step [70/94], Loss: 0.0622 Accuracy: 0.9844\n",
      "Epoch [21/40], Step [80/94], Loss: 0.0554 Accuracy: 0.9688\n",
      "Epoch [21/40], Step [90/94], Loss: 0.0124 Accuracy: 0.9922\n",
      "Epoch: 20\tAverage Train Loss: 0.072078\tAverage Train Accuracy: 0.978718\n",
      "Epoch: 20\tAverage Validation Loss: 0.043055\tAverage Validation Accuracy: 0.987852\n",
      "Epoch: 20\tAverage Test Loss: 0.040505\tAverage Test Accuracy: 0.989235\n",
      "Epoch [22/40], Step [0/375], Loss: 0.0107\n",
      "Epoch [22/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [10/375], Loss: 0.0272\n",
      "Epoch [22/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [20/375], Loss: 0.0754\n",
      "Epoch [22/40], Step [20/375], Accuracy: 0.9844\n",
      "Epoch [22/40], Step [30/375], Loss: 0.0071\n",
      "Epoch [22/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [40/375], Loss: 0.0623\n",
      "Epoch [22/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [50/375], Loss: 0.1170\n",
      "Epoch [22/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [60/375], Loss: 0.0329\n",
      "Epoch [22/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [70/375], Loss: 0.0281\n",
      "Epoch [22/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [80/375], Loss: 0.0658\n",
      "Epoch [22/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [90/375], Loss: 0.0390\n",
      "Epoch [22/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [22/40], Step [100/375], Loss: 0.0174\n",
      "Epoch [22/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [110/375], Loss: 0.0216\n",
      "Epoch [22/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [120/375], Loss: 0.0719\n",
      "Epoch [22/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [130/375], Loss: 0.0024\n",
      "Epoch [22/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [140/375], Loss: 0.0006\n",
      "Epoch [22/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [150/375], Loss: 0.0430\n",
      "Epoch [22/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [22/40], Step [160/375], Loss: 0.0118\n",
      "Epoch [22/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [170/375], Loss: 0.0248\n",
      "Epoch [22/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [180/375], Loss: 0.0140\n",
      "Epoch [22/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [190/375], Loss: 0.0119\n",
      "Epoch [22/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [200/375], Loss: 0.0080\n",
      "Epoch [22/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [210/375], Loss: 0.0500\n",
      "Epoch [22/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [22/40], Step [220/375], Loss: 0.0383\n",
      "Epoch [22/40], Step [220/375], Accuracy: 0.9844\n",
      "Epoch [22/40], Step [230/375], Loss: 0.0195\n",
      "Epoch [22/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [240/375], Loss: 0.0438\n",
      "Epoch [22/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [250/375], Loss: 0.0115\n",
      "Epoch [22/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [260/375], Loss: 0.0184\n",
      "Epoch [22/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [270/375], Loss: 0.0150\n",
      "Epoch [22/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [280/375], Loss: 0.0374\n",
      "Epoch [22/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [290/375], Loss: 0.0034\n",
      "Epoch [22/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [300/375], Loss: 0.0079\n",
      "Epoch [22/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [310/375], Loss: 0.0838\n",
      "Epoch [22/40], Step [310/375], Accuracy: 0.9844\n",
      "Epoch [22/40], Step [320/375], Loss: 0.0397\n",
      "Epoch [22/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [22/40], Step [330/375], Loss: 0.0222\n",
      "Epoch [22/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [340/375], Loss: 0.0160\n",
      "Epoch [22/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [350/375], Loss: 0.0046\n",
      "Epoch [22/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [22/40], Step [360/375], Loss: 0.0125\n",
      "Epoch [22/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [370/375], Loss: 0.0249\n",
      "Epoch [22/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [22/40], Step [0/94], Loss: 0.0017 Accuracy: 1.0000\n",
      "Epoch [22/40], Step [10/94], Loss: 0.0107 Accuracy: 1.0000\n",
      "Epoch [22/40], Step [20/94], Loss: 0.0384 Accuracy: 0.9922\n",
      "Epoch [22/40], Step [30/94], Loss: 0.0495 Accuracy: 0.9688\n",
      "Epoch [22/40], Step [40/94], Loss: 0.0142 Accuracy: 1.0000\n",
      "Epoch [22/40], Step [50/94], Loss: 0.0024 Accuracy: 1.0000\n",
      "Epoch [22/40], Step [60/94], Loss: 0.0293 Accuracy: 0.9844\n",
      "Epoch [22/40], Step [70/94], Loss: 0.0792 Accuracy: 0.9688\n",
      "Epoch [22/40], Step [80/94], Loss: 0.0191 Accuracy: 0.9922\n",
      "Epoch [22/40], Step [90/94], Loss: 0.0067 Accuracy: 1.0000\n",
      "Epoch: 21\tAverage Train Loss: 0.070168\tAverage Train Accuracy: 0.979296\n",
      "Epoch: 21\tAverage Validation Loss: 0.042655\tAverage Validation Accuracy: 0.988023\n",
      "Epoch: 21\tAverage Test Loss: 0.040330\tAverage Test Accuracy: 0.989297\n",
      "Epoch [23/40], Step [0/375], Loss: 0.0078\n",
      "Epoch [23/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [10/375], Loss: 0.0044\n",
      "Epoch [23/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [23/40], Step [20/375], Loss: 0.0216\n",
      "Epoch [23/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [30/375], Loss: 0.0142\n",
      "Epoch [23/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [40/375], Loss: 0.0015\n",
      "Epoch [23/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [23/40], Step [50/375], Loss: 0.0968\n",
      "Epoch [23/40], Step [50/375], Accuracy: 0.9688\n",
      "Epoch [23/40], Step [60/375], Loss: 0.0790\n",
      "Epoch [23/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [70/375], Loss: 0.0287\n",
      "Epoch [23/40], Step [70/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [80/375], Loss: 0.0049\n",
      "Epoch [23/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [23/40], Step [90/375], Loss: 0.0296\n",
      "Epoch [23/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [100/375], Loss: 0.0182\n",
      "Epoch [23/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [110/375], Loss: 0.0808\n",
      "Epoch [23/40], Step [110/375], Accuracy: 0.9609\n",
      "Epoch [23/40], Step [120/375], Loss: 0.0036\n",
      "Epoch [23/40], Step [120/375], Accuracy: 1.0000\n",
      "Epoch [23/40], Step [130/375], Loss: 0.0072\n",
      "Epoch [23/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [23/40], Step [140/375], Loss: 0.2066\n",
      "Epoch [23/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [23/40], Step [150/375], Loss: 0.0395\n",
      "Epoch [23/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [160/375], Loss: 0.0367\n",
      "Epoch [23/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [170/375], Loss: 0.0311\n",
      "Epoch [23/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [180/375], Loss: 0.0633\n",
      "Epoch [23/40], Step [180/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [190/375], Loss: 0.1099\n",
      "Epoch [23/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [200/375], Loss: 0.0134\n",
      "Epoch [23/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [210/375], Loss: 0.0744\n",
      "Epoch [23/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [220/375], Loss: 0.1748\n",
      "Epoch [23/40], Step [220/375], Accuracy: 0.9766\n",
      "Epoch [23/40], Step [230/375], Loss: 0.0109\n",
      "Epoch [23/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [240/375], Loss: 0.0046\n",
      "Epoch [23/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [23/40], Step [250/375], Loss: 0.0541\n",
      "Epoch [23/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [260/375], Loss: 0.0482\n",
      "Epoch [23/40], Step [260/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [270/375], Loss: 0.1611\n",
      "Epoch [23/40], Step [270/375], Accuracy: 0.9766\n",
      "Epoch [23/40], Step [280/375], Loss: 0.0131\n",
      "Epoch [23/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [290/375], Loss: 0.0170\n",
      "Epoch [23/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [300/375], Loss: 0.0146\n",
      "Epoch [23/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [310/375], Loss: 0.0241\n",
      "Epoch [23/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [320/375], Loss: 0.0716\n",
      "Epoch [23/40], Step [320/375], Accuracy: 0.9531\n",
      "Epoch [23/40], Step [330/375], Loss: 0.0041\n",
      "Epoch [23/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [23/40], Step [340/375], Loss: 0.0225\n",
      "Epoch [23/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [350/375], Loss: 0.1422\n",
      "Epoch [23/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [23/40], Step [360/375], Loss: 0.1629\n",
      "Epoch [23/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [23/40], Step [370/375], Loss: 0.0206\n",
      "Epoch [23/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [23/40], Step [0/94], Loss: 0.0065 Accuracy: 1.0000\n",
      "Epoch [23/40], Step [10/94], Loss: 0.0038 Accuracy: 1.0000\n",
      "Epoch [23/40], Step [20/94], Loss: 0.0040 Accuracy: 1.0000\n",
      "Epoch [23/40], Step [30/94], Loss: 0.0071 Accuracy: 1.0000\n",
      "Epoch [23/40], Step [40/94], Loss: 0.0040 Accuracy: 1.0000\n",
      "Epoch [23/40], Step [50/94], Loss: 0.0011 Accuracy: 1.0000\n",
      "Epoch [23/40], Step [60/94], Loss: 0.0151 Accuracy: 0.9922\n",
      "Epoch [23/40], Step [70/94], Loss: 0.0339 Accuracy: 0.9766\n",
      "Epoch [23/40], Step [80/94], Loss: 0.0246 Accuracy: 0.9922\n",
      "Epoch [23/40], Step [90/94], Loss: 0.0232 Accuracy: 0.9922\n",
      "Epoch: 22\tAverage Train Loss: 0.068667\tAverage Train Accuracy: 0.979803\n",
      "Epoch: 22\tAverage Validation Loss: 0.042306\tAverage Validation Accuracy: 0.988164\n",
      "Epoch: 22\tAverage Test Loss: 0.039731\tAverage Test Accuracy: 0.989449\n",
      "Epoch [24/40], Step [0/375], Loss: 0.0785\n",
      "Epoch [24/40], Step [0/375], Accuracy: 0.9688\n",
      "Epoch [24/40], Step [10/375], Loss: 0.0083\n",
      "Epoch [24/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [20/375], Loss: 0.0052\n",
      "Epoch [24/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [30/375], Loss: 0.0268\n",
      "Epoch [24/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [40/375], Loss: 0.0571\n",
      "Epoch [24/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [50/375], Loss: 0.1611\n",
      "Epoch [24/40], Step [50/375], Accuracy: 0.9688\n",
      "Epoch [24/40], Step [60/375], Loss: 0.0225\n",
      "Epoch [24/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [70/375], Loss: 0.0073\n",
      "Epoch [24/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [80/375], Loss: 0.0650\n",
      "Epoch [24/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [90/375], Loss: 0.0648\n",
      "Epoch [24/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [100/375], Loss: 0.0224\n",
      "Epoch [24/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [110/375], Loss: 0.0800\n",
      "Epoch [24/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [120/375], Loss: 0.0355\n",
      "Epoch [24/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [130/375], Loss: 0.0527\n",
      "Epoch [24/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [140/375], Loss: 0.1113\n",
      "Epoch [24/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [150/375], Loss: 0.0028\n",
      "Epoch [24/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [160/375], Loss: 0.0653\n",
      "Epoch [24/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [170/375], Loss: 0.0059\n",
      "Epoch [24/40], Step [170/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [180/375], Loss: 0.0133\n",
      "Epoch [24/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [190/375], Loss: 0.0462\n",
      "Epoch [24/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [200/375], Loss: 0.0007\n",
      "Epoch [24/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [210/375], Loss: 0.0651\n",
      "Epoch [24/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [220/375], Loss: 0.1069\n",
      "Epoch [24/40], Step [220/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [230/375], Loss: 0.0365\n",
      "Epoch [24/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [240/375], Loss: 0.0709\n",
      "Epoch [24/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [250/375], Loss: 0.1249\n",
      "Epoch [24/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [260/375], Loss: 0.1118\n",
      "Epoch [24/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [24/40], Step [270/375], Loss: 0.0885\n",
      "Epoch [24/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [280/375], Loss: 0.0819\n",
      "Epoch [24/40], Step [280/375], Accuracy: 0.9766\n",
      "Epoch [24/40], Step [290/375], Loss: 0.0102\n",
      "Epoch [24/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [300/375], Loss: 0.0826\n",
      "Epoch [24/40], Step [300/375], Accuracy: 0.9766\n",
      "Epoch [24/40], Step [310/375], Loss: 0.0109\n",
      "Epoch [24/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [24/40], Step [320/375], Loss: 0.0622\n",
      "Epoch [24/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [330/375], Loss: 0.0498\n",
      "Epoch [24/40], Step [330/375], Accuracy: 0.9844\n",
      "Epoch [24/40], Step [340/375], Loss: 0.0014\n",
      "Epoch [24/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [350/375], Loss: 0.0113\n",
      "Epoch [24/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [360/375], Loss: 0.0703\n",
      "Epoch [24/40], Step [360/375], Accuracy: 0.9688\n",
      "Epoch [24/40], Step [370/375], Loss: 0.0013\n",
      "Epoch [24/40], Step [370/375], Accuracy: 1.0000\n",
      "Epoch [24/40], Step [0/94], Loss: 0.0085 Accuracy: 0.9922\n",
      "Epoch [24/40], Step [10/94], Loss: 0.0021 Accuracy: 1.0000\n",
      "Epoch [24/40], Step [20/94], Loss: 0.0227 Accuracy: 0.9922\n",
      "Epoch [24/40], Step [30/94], Loss: 0.0298 Accuracy: 0.9844\n",
      "Epoch [24/40], Step [40/94], Loss: 0.0038 Accuracy: 1.0000\n",
      "Epoch [24/40], Step [50/94], Loss: 0.0029 Accuracy: 1.0000\n",
      "Epoch [24/40], Step [60/94], Loss: 0.0024 Accuracy: 1.0000\n",
      "Epoch [24/40], Step [70/94], Loss: 0.0122 Accuracy: 0.9922\n",
      "Epoch [24/40], Step [80/94], Loss: 0.0397 Accuracy: 0.9766\n",
      "Epoch [24/40], Step [90/94], Loss: 0.0193 Accuracy: 0.9922\n",
      "Epoch: 23\tAverage Train Loss: 0.067495\tAverage Train Accuracy: 0.980222\n",
      "Epoch: 23\tAverage Validation Loss: 0.041888\tAverage Validation Accuracy: 0.988308\n",
      "Epoch: 23\tAverage Test Loss: 0.039274\tAverage Test Accuracy: 0.989567\n",
      "Epoch [25/40], Step [0/375], Loss: 0.0012\n",
      "Epoch [25/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [10/375], Loss: 0.0536\n",
      "Epoch [25/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [20/375], Loss: 0.0108\n",
      "Epoch [25/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [30/375], Loss: 0.0022\n",
      "Epoch [25/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [40/375], Loss: 0.0044\n",
      "Epoch [25/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [50/375], Loss: 0.0115\n",
      "Epoch [25/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [60/375], Loss: 0.0025\n",
      "Epoch [25/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [70/375], Loss: 0.0099\n",
      "Epoch [25/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [80/375], Loss: 0.0435\n",
      "Epoch [25/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [90/375], Loss: 0.0451\n",
      "Epoch [25/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [25/40], Step [100/375], Loss: 0.0221\n",
      "Epoch [25/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [110/375], Loss: 0.0074\n",
      "Epoch [25/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [120/375], Loss: 0.0460\n",
      "Epoch [25/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [130/375], Loss: 0.0235\n",
      "Epoch [25/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [140/375], Loss: 0.0792\n",
      "Epoch [25/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [25/40], Step [150/375], Loss: 0.0850\n",
      "Epoch [25/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [160/375], Loss: 0.0095\n",
      "Epoch [25/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [170/375], Loss: 0.0537\n",
      "Epoch [25/40], Step [170/375], Accuracy: 0.9688\n",
      "Epoch [25/40], Step [180/375], Loss: 0.0479\n",
      "Epoch [25/40], Step [180/375], Accuracy: 0.9844\n",
      "Epoch [25/40], Step [190/375], Loss: 0.0330\n",
      "Epoch [25/40], Step [190/375], Accuracy: 0.9766\n",
      "Epoch [25/40], Step [200/375], Loss: 0.0927\n",
      "Epoch [25/40], Step [200/375], Accuracy: 0.9766\n",
      "Epoch [25/40], Step [210/375], Loss: 0.0036\n",
      "Epoch [25/40], Step [210/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [220/375], Loss: 0.0014\n",
      "Epoch [25/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [230/375], Loss: 0.0370\n",
      "Epoch [25/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [240/375], Loss: 0.1254\n",
      "Epoch [25/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [250/375], Loss: 0.0238\n",
      "Epoch [25/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [260/375], Loss: 0.0232\n",
      "Epoch [25/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [270/375], Loss: 0.1038\n",
      "Epoch [25/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [25/40], Step [280/375], Loss: 0.0043\n",
      "Epoch [25/40], Step [280/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [290/375], Loss: 0.0048\n",
      "Epoch [25/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [300/375], Loss: 0.0086\n",
      "Epoch [25/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [25/40], Step [310/375], Loss: 0.0284\n",
      "Epoch [25/40], Step [310/375], Accuracy: 0.9844\n",
      "Epoch [25/40], Step [320/375], Loss: 0.0051\n",
      "Epoch [25/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [330/375], Loss: 0.0058\n",
      "Epoch [25/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [340/375], Loss: 0.0693\n",
      "Epoch [25/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [25/40], Step [350/375], Loss: 0.0028\n",
      "Epoch [25/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [360/375], Loss: 0.0009\n",
      "Epoch [25/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [25/40], Step [370/375], Loss: 0.1041\n",
      "Epoch [25/40], Step [370/375], Accuracy: 0.9688\n",
      "Epoch [25/40], Step [0/94], Loss: 0.0003 Accuracy: 1.0000\n",
      "Epoch [25/40], Step [10/94], Loss: 0.0003 Accuracy: 1.0000\n",
      "Epoch [25/40], Step [20/94], Loss: 0.0421 Accuracy: 0.9922\n",
      "Epoch [25/40], Step [30/94], Loss: 0.0481 Accuracy: 0.9922\n",
      "Epoch [25/40], Step [40/94], Loss: 0.0136 Accuracy: 0.9922\n",
      "Epoch [25/40], Step [50/94], Loss: 0.0666 Accuracy: 0.9844\n",
      "Epoch [25/40], Step [60/94], Loss: 0.0349 Accuracy: 0.9922\n",
      "Epoch [25/40], Step [70/94], Loss: 0.0061 Accuracy: 1.0000\n",
      "Epoch [25/40], Step [80/94], Loss: 0.0399 Accuracy: 0.9922\n",
      "Epoch [25/40], Step [90/94], Loss: 0.0021 Accuracy: 1.0000\n",
      "Epoch: 24\tAverage Train Loss: 0.066125\tAverage Train Accuracy: 0.980644\n",
      "Epoch: 24\tAverage Validation Loss: 0.041838\tAverage Validation Accuracy: 0.988380\n",
      "Epoch: 24\tAverage Test Loss: 0.039495\tAverage Test Accuracy: 0.989632\n",
      "Epoch [26/40], Step [0/375], Loss: 0.0513\n",
      "Epoch [26/40], Step [0/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [10/375], Loss: 0.0028\n",
      "Epoch [26/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [20/375], Loss: 0.0274\n",
      "Epoch [26/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [30/375], Loss: 0.1023\n",
      "Epoch [26/40], Step [30/375], Accuracy: 0.9766\n",
      "Epoch [26/40], Step [40/375], Loss: 0.0980\n",
      "Epoch [26/40], Step [40/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [50/375], Loss: 0.0645\n",
      "Epoch [26/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [60/375], Loss: 0.0007\n",
      "Epoch [26/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [70/375], Loss: 0.0065\n",
      "Epoch [26/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [80/375], Loss: 0.0327\n",
      "Epoch [26/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [90/375], Loss: 0.0231\n",
      "Epoch [26/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [100/375], Loss: 0.0011\n",
      "Epoch [26/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [110/375], Loss: 0.0163\n",
      "Epoch [26/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [120/375], Loss: 0.0084\n",
      "Epoch [26/40], Step [120/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [130/375], Loss: 0.0326\n",
      "Epoch [26/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [140/375], Loss: 0.0455\n",
      "Epoch [26/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [26/40], Step [150/375], Loss: 0.0086\n",
      "Epoch [26/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [160/375], Loss: 0.0509\n",
      "Epoch [26/40], Step [160/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [170/375], Loss: 0.0346\n",
      "Epoch [26/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [180/375], Loss: 0.0536\n",
      "Epoch [26/40], Step [180/375], Accuracy: 0.9766\n",
      "Epoch [26/40], Step [190/375], Loss: 0.0564\n",
      "Epoch [26/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [200/375], Loss: 0.0281\n",
      "Epoch [26/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [210/375], Loss: 0.0458\n",
      "Epoch [26/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [26/40], Step [220/375], Loss: 0.0007\n",
      "Epoch [26/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [230/375], Loss: 0.0020\n",
      "Epoch [26/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [240/375], Loss: 0.0012\n",
      "Epoch [26/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [250/375], Loss: 0.0298\n",
      "Epoch [26/40], Step [250/375], Accuracy: 0.9766\n",
      "Epoch [26/40], Step [260/375], Loss: 0.0652\n",
      "Epoch [26/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [270/375], Loss: 0.0036\n",
      "Epoch [26/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [26/40], Step [280/375], Loss: 0.0127\n",
      "Epoch [26/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [290/375], Loss: 0.0278\n",
      "Epoch [26/40], Step [290/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [300/375], Loss: 0.0125\n",
      "Epoch [26/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [310/375], Loss: 0.0892\n",
      "Epoch [26/40], Step [310/375], Accuracy: 0.9766\n",
      "Epoch [26/40], Step [320/375], Loss: 0.0665\n",
      "Epoch [26/40], Step [320/375], Accuracy: 0.9688\n",
      "Epoch [26/40], Step [330/375], Loss: 0.0334\n",
      "Epoch [26/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [340/375], Loss: 0.0451\n",
      "Epoch [26/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [350/375], Loss: 0.0405\n",
      "Epoch [26/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [360/375], Loss: 0.0454\n",
      "Epoch [26/40], Step [360/375], Accuracy: 0.9844\n",
      "Epoch [26/40], Step [370/375], Loss: 0.0131\n",
      "Epoch [26/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [26/40], Step [0/94], Loss: 0.0037 Accuracy: 1.0000\n",
      "Epoch [26/40], Step [10/94], Loss: 0.0001 Accuracy: 1.0000\n",
      "Epoch [26/40], Step [20/94], Loss: 0.0136 Accuracy: 0.9922\n",
      "Epoch [26/40], Step [30/94], Loss: 0.0141 Accuracy: 0.9922\n",
      "Epoch [26/40], Step [40/94], Loss: 0.0024 Accuracy: 1.0000\n",
      "Epoch [26/40], Step [50/94], Loss: 0.0007 Accuracy: 1.0000\n",
      "Epoch [26/40], Step [60/94], Loss: 0.0359 Accuracy: 0.9922\n",
      "Epoch [26/40], Step [70/94], Loss: 0.0147 Accuracy: 1.0000\n",
      "Epoch [26/40], Step [80/94], Loss: 0.0198 Accuracy: 0.9922\n",
      "Epoch [26/40], Step [90/94], Loss: 0.0091 Accuracy: 1.0000\n",
      "Epoch: 25\tAverage Train Loss: 0.064761\tAverage Train Accuracy: 0.981068\n",
      "Epoch: 25\tAverage Validation Loss: 0.041536\tAverage Validation Accuracy: 0.988504\n",
      "Epoch: 25\tAverage Test Loss: 0.039127\tAverage Test Accuracy: 0.989730\n",
      "Epoch [27/40], Step [0/375], Loss: 0.0373\n",
      "Epoch [27/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [10/375], Loss: 0.0321\n",
      "Epoch [27/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [20/375], Loss: 0.1723\n",
      "Epoch [27/40], Step [20/375], Accuracy: 0.9688\n",
      "Epoch [27/40], Step [30/375], Loss: 0.0035\n",
      "Epoch [27/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [40/375], Loss: 0.0491\n",
      "Epoch [27/40], Step [40/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [50/375], Loss: 0.0482\n",
      "Epoch [27/40], Step [50/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [60/375], Loss: 0.0409\n",
      "Epoch [27/40], Step [60/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [70/375], Loss: 0.0093\n",
      "Epoch [27/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [80/375], Loss: 0.0645\n",
      "Epoch [27/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [90/375], Loss: 0.0206\n",
      "Epoch [27/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [100/375], Loss: 0.0677\n",
      "Epoch [27/40], Step [100/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [110/375], Loss: 0.0207\n",
      "Epoch [27/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [120/375], Loss: 0.0226\n",
      "Epoch [27/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [130/375], Loss: 0.0369\n",
      "Epoch [27/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [140/375], Loss: 0.0681\n",
      "Epoch [27/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [150/375], Loss: 0.0241\n",
      "Epoch [27/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [160/375], Loss: 0.0089\n",
      "Epoch [27/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [170/375], Loss: 0.0518\n",
      "Epoch [27/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [180/375], Loss: 0.0123\n",
      "Epoch [27/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [190/375], Loss: 0.0528\n",
      "Epoch [27/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [200/375], Loss: 0.0011\n",
      "Epoch [27/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [210/375], Loss: 0.0063\n",
      "Epoch [27/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [220/375], Loss: 0.0033\n",
      "Epoch [27/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [230/375], Loss: 0.0176\n",
      "Epoch [27/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [240/375], Loss: 0.0153\n",
      "Epoch [27/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [250/375], Loss: 0.0064\n",
      "Epoch [27/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [260/375], Loss: 0.0154\n",
      "Epoch [27/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [270/375], Loss: 0.0061\n",
      "Epoch [27/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [280/375], Loss: 0.0755\n",
      "Epoch [27/40], Step [280/375], Accuracy: 0.9766\n",
      "Epoch [27/40], Step [290/375], Loss: 0.0500\n",
      "Epoch [27/40], Step [290/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [300/375], Loss: 0.0035\n",
      "Epoch [27/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [310/375], Loss: 0.0493\n",
      "Epoch [27/40], Step [310/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [320/375], Loss: 0.0118\n",
      "Epoch [27/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [330/375], Loss: 0.0196\n",
      "Epoch [27/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [340/375], Loss: 0.0670\n",
      "Epoch [27/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [27/40], Step [350/375], Loss: 0.0441\n",
      "Epoch [27/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [360/375], Loss: 0.1300\n",
      "Epoch [27/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [27/40], Step [370/375], Loss: 0.0040\n",
      "Epoch [27/40], Step [370/375], Accuracy: 1.0000\n",
      "Epoch [27/40], Step [0/94], Loss: 0.0032 Accuracy: 1.0000\n",
      "Epoch [27/40], Step [10/94], Loss: 0.0211 Accuracy: 0.9922\n",
      "Epoch [27/40], Step [20/94], Loss: 0.0156 Accuracy: 0.9922\n",
      "Epoch [27/40], Step [30/94], Loss: 0.0178 Accuracy: 0.9922\n",
      "Epoch [27/40], Step [40/94], Loss: 0.0260 Accuracy: 0.9922\n",
      "Epoch [27/40], Step [50/94], Loss: 0.0056 Accuracy: 1.0000\n",
      "Epoch [27/40], Step [60/94], Loss: 0.0721 Accuracy: 0.9922\n",
      "Epoch [27/40], Step [70/94], Loss: 0.0757 Accuracy: 0.9922\n",
      "Epoch [27/40], Step [80/94], Loss: 0.0755 Accuracy: 0.9922\n",
      "Epoch [27/40], Step [90/94], Loss: 0.0169 Accuracy: 0.9922\n",
      "Epoch: 26\tAverage Train Loss: 0.063554\tAverage Train Accuracy: 0.981452\n",
      "Epoch: 26\tAverage Validation Loss: 0.041605\tAverage Validation Accuracy: 0.988622\n",
      "Epoch: 26\tAverage Test Loss: 0.038923\tAverage Test Accuracy: 0.989818\n",
      "Epoch [28/40], Step [0/375], Loss: 0.0024\n",
      "Epoch [28/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [10/375], Loss: 0.0048\n",
      "Epoch [28/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [20/375], Loss: 0.0224\n",
      "Epoch [28/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [30/375], Loss: 0.0037\n",
      "Epoch [28/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [40/375], Loss: 0.0295\n",
      "Epoch [28/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [50/375], Loss: 0.0074\n",
      "Epoch [28/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [60/375], Loss: 0.0178\n",
      "Epoch [28/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [28/40], Step [70/375], Loss: 0.0008\n",
      "Epoch [28/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [80/375], Loss: 0.0655\n",
      "Epoch [28/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [90/375], Loss: 0.0269\n",
      "Epoch [28/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [100/375], Loss: 0.0051\n",
      "Epoch [28/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [110/375], Loss: 0.0456\n",
      "Epoch [28/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [28/40], Step [120/375], Loss: 0.0205\n",
      "Epoch [28/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [130/375], Loss: 0.0008\n",
      "Epoch [28/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [140/375], Loss: 0.1719\n",
      "Epoch [28/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [28/40], Step [150/375], Loss: 0.0037\n",
      "Epoch [28/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [160/375], Loss: 0.0090\n",
      "Epoch [28/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [170/375], Loss: 0.0031\n",
      "Epoch [28/40], Step [170/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [180/375], Loss: 0.0255\n",
      "Epoch [28/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [190/375], Loss: 0.0173\n",
      "Epoch [28/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [200/375], Loss: 0.0161\n",
      "Epoch [28/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [210/375], Loss: 0.0017\n",
      "Epoch [28/40], Step [210/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [220/375], Loss: 0.0003\n",
      "Epoch [28/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [230/375], Loss: 0.0182\n",
      "Epoch [28/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [28/40], Step [240/375], Loss: 0.0311\n",
      "Epoch [28/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [250/375], Loss: 0.0640\n",
      "Epoch [28/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [260/375], Loss: 0.0083\n",
      "Epoch [28/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [270/375], Loss: 0.0577\n",
      "Epoch [28/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [280/375], Loss: 0.0754\n",
      "Epoch [28/40], Step [280/375], Accuracy: 0.9766\n",
      "Epoch [28/40], Step [290/375], Loss: 0.0019\n",
      "Epoch [28/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [300/375], Loss: 0.0081\n",
      "Epoch [28/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [310/375], Loss: 0.0362\n",
      "Epoch [28/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [320/375], Loss: 0.0145\n",
      "Epoch [28/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [330/375], Loss: 0.0030\n",
      "Epoch [28/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [340/375], Loss: 0.0451\n",
      "Epoch [28/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [350/375], Loss: 0.0514\n",
      "Epoch [28/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [360/375], Loss: 0.0284\n",
      "Epoch [28/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [28/40], Step [370/375], Loss: 0.0011\n",
      "Epoch [28/40], Step [370/375], Accuracy: 1.0000\n",
      "Epoch [28/40], Step [0/94], Loss: 0.0009 Accuracy: 1.0000\n",
      "Epoch [28/40], Step [10/94], Loss: 0.0027 Accuracy: 1.0000\n",
      "Epoch [28/40], Step [20/94], Loss: 0.0117 Accuracy: 0.9922\n",
      "Epoch [28/40], Step [30/94], Loss: 0.0209 Accuracy: 0.9922\n",
      "Epoch [28/40], Step [40/94], Loss: 0.0067 Accuracy: 1.0000\n",
      "Epoch [28/40], Step [50/94], Loss: 0.0003 Accuracy: 1.0000\n",
      "Epoch [28/40], Step [60/94], Loss: 0.0120 Accuracy: 0.9922\n",
      "Epoch [28/40], Step [70/94], Loss: 0.0346 Accuracy: 0.9922\n",
      "Epoch [28/40], Step [80/94], Loss: 0.0334 Accuracy: 0.9922\n",
      "Epoch [28/40], Step [90/94], Loss: 0.0325 Accuracy: 0.9844\n",
      "Epoch: 27\tAverage Train Loss: 0.062326\tAverage Train Accuracy: 0.981834\n",
      "Epoch: 27\tAverage Validation Loss: 0.041426\tAverage Validation Accuracy: 0.988720\n",
      "Epoch: 27\tAverage Test Loss: 0.038578\tAverage Test Accuracy: 0.989927\n",
      "Epoch [29/40], Step [0/375], Loss: 0.0103\n",
      "Epoch [29/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [10/375], Loss: 0.0003\n",
      "Epoch [29/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [20/375], Loss: 0.0078\n",
      "Epoch [29/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [30/375], Loss: 0.0150\n",
      "Epoch [29/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [40/375], Loss: 0.0029\n",
      "Epoch [29/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [50/375], Loss: 0.0168\n",
      "Epoch [29/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [60/375], Loss: 0.0691\n",
      "Epoch [29/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [70/375], Loss: 0.0035\n",
      "Epoch [29/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [80/375], Loss: 0.0363\n",
      "Epoch [29/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [90/375], Loss: 0.0053\n",
      "Epoch [29/40], Step [90/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [100/375], Loss: 0.0378\n",
      "Epoch [29/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [110/375], Loss: 0.0114\n",
      "Epoch [29/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [120/375], Loss: 0.0153\n",
      "Epoch [29/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [130/375], Loss: 0.0672\n",
      "Epoch [29/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [140/375], Loss: 0.0024\n",
      "Epoch [29/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [150/375], Loss: 0.0673\n",
      "Epoch [29/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [160/375], Loss: 0.0834\n",
      "Epoch [29/40], Step [160/375], Accuracy: 0.9766\n",
      "Epoch [29/40], Step [170/375], Loss: 0.0240\n",
      "Epoch [29/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [180/375], Loss: 0.0321\n",
      "Epoch [29/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [190/375], Loss: 0.0010\n",
      "Epoch [29/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [200/375], Loss: 0.1087\n",
      "Epoch [29/40], Step [200/375], Accuracy: 0.9766\n",
      "Epoch [29/40], Step [210/375], Loss: 0.0344\n",
      "Epoch [29/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [220/375], Loss: 0.0053\n",
      "Epoch [29/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [230/375], Loss: 0.0010\n",
      "Epoch [29/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [240/375], Loss: 0.0108\n",
      "Epoch [29/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [250/375], Loss: 0.0581\n",
      "Epoch [29/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [260/375], Loss: 0.0049\n",
      "Epoch [29/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [270/375], Loss: 0.0226\n",
      "Epoch [29/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [280/375], Loss: 0.2011\n",
      "Epoch [29/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [290/375], Loss: 0.1304\n",
      "Epoch [29/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [300/375], Loss: 0.0015\n",
      "Epoch [29/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [310/375], Loss: 0.0174\n",
      "Epoch [29/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [320/375], Loss: 0.0326\n",
      "Epoch [29/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [29/40], Step [330/375], Loss: 0.0200\n",
      "Epoch [29/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [340/375], Loss: 0.2201\n",
      "Epoch [29/40], Step [340/375], Accuracy: 0.9766\n",
      "Epoch [29/40], Step [350/375], Loss: 0.0477\n",
      "Epoch [29/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [360/375], Loss: 0.0613\n",
      "Epoch [29/40], Step [360/375], Accuracy: 0.9844\n",
      "Epoch [29/40], Step [370/375], Loss: 0.0070\n",
      "Epoch [29/40], Step [370/375], Accuracy: 1.0000\n",
      "Epoch [29/40], Step [0/94], Loss: 0.0046 Accuracy: 1.0000\n",
      "Epoch [29/40], Step [10/94], Loss: 0.0038 Accuracy: 1.0000\n",
      "Epoch [29/40], Step [20/94], Loss: 0.0053 Accuracy: 1.0000\n",
      "Epoch [29/40], Step [30/94], Loss: 0.0118 Accuracy: 1.0000\n",
      "Epoch [29/40], Step [40/94], Loss: 0.0050 Accuracy: 1.0000\n",
      "Epoch [29/40], Step [50/94], Loss: 0.0010 Accuracy: 1.0000\n",
      "Epoch [29/40], Step [60/94], Loss: 0.0328 Accuracy: 0.9922\n",
      "Epoch [29/40], Step [70/94], Loss: 0.0700 Accuracy: 0.9766\n",
      "Epoch [29/40], Step [80/94], Loss: 0.0342 Accuracy: 0.9844\n",
      "Epoch [29/40], Step [90/94], Loss: 0.0579 Accuracy: 0.9844\n",
      "Epoch: 28\tAverage Train Loss: 0.061267\tAverage Train Accuracy: 0.982182\n",
      "Epoch: 28\tAverage Validation Loss: 0.041145\tAverage Validation Accuracy: 0.988802\n",
      "Epoch: 28\tAverage Test Loss: 0.038546\tAverage Test Accuracy: 0.989974\n",
      "Epoch [30/40], Step [0/375], Loss: 0.0725\n",
      "Epoch [30/40], Step [0/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [10/375], Loss: 0.0308\n",
      "Epoch [30/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [20/375], Loss: 0.0021\n",
      "Epoch [30/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [30/375], Loss: 0.0041\n",
      "Epoch [30/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [40/375], Loss: 0.0078\n",
      "Epoch [30/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [50/375], Loss: 0.0005\n",
      "Epoch [30/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [60/375], Loss: 0.0001\n",
      "Epoch [30/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [70/375], Loss: 0.0051\n",
      "Epoch [30/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [80/375], Loss: 0.0030\n",
      "Epoch [30/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [90/375], Loss: 0.0256\n",
      "Epoch [30/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [100/375], Loss: 0.0110\n",
      "Epoch [30/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [110/375], Loss: 0.0593\n",
      "Epoch [30/40], Step [110/375], Accuracy: 0.9766\n",
      "Epoch [30/40], Step [120/375], Loss: 0.0472\n",
      "Epoch [30/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [130/375], Loss: 0.0553\n",
      "Epoch [30/40], Step [130/375], Accuracy: 0.9766\n",
      "Epoch [30/40], Step [140/375], Loss: 0.0191\n",
      "Epoch [30/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [150/375], Loss: 0.0097\n",
      "Epoch [30/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [160/375], Loss: 0.0343\n",
      "Epoch [30/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [170/375], Loss: 0.0032\n",
      "Epoch [30/40], Step [170/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [180/375], Loss: 0.1927\n",
      "Epoch [30/40], Step [180/375], Accuracy: 0.9766\n",
      "Epoch [30/40], Step [190/375], Loss: 0.0217\n",
      "Epoch [30/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [200/375], Loss: 0.0068\n",
      "Epoch [30/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [210/375], Loss: 0.0474\n",
      "Epoch [30/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [220/375], Loss: 0.0986\n",
      "Epoch [30/40], Step [220/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [230/375], Loss: 0.0220\n",
      "Epoch [30/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [240/375], Loss: 0.0328\n",
      "Epoch [30/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [250/375], Loss: 0.0424\n",
      "Epoch [30/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [260/375], Loss: 0.0300\n",
      "Epoch [30/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [270/375], Loss: 0.0322\n",
      "Epoch [30/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [30/40], Step [280/375], Loss: 0.1022\n",
      "Epoch [30/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [290/375], Loss: 0.0121\n",
      "Epoch [30/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [300/375], Loss: 0.0014\n",
      "Epoch [30/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [310/375], Loss: 0.0038\n",
      "Epoch [30/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [320/375], Loss: 0.0277\n",
      "Epoch [30/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [330/375], Loss: 0.0603\n",
      "Epoch [30/40], Step [330/375], Accuracy: 0.9766\n",
      "Epoch [30/40], Step [340/375], Loss: 0.0283\n",
      "Epoch [30/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [350/375], Loss: 0.0014\n",
      "Epoch [30/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [360/375], Loss: 0.0028\n",
      "Epoch [30/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [30/40], Step [370/375], Loss: 0.0380\n",
      "Epoch [30/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [30/40], Step [0/94], Loss: 0.0164 Accuracy: 0.9922\n",
      "Epoch [30/40], Step [10/94], Loss: 0.0118 Accuracy: 0.9922\n",
      "Epoch [30/40], Step [20/94], Loss: 0.0237 Accuracy: 0.9844\n",
      "Epoch [30/40], Step [30/94], Loss: 0.0410 Accuracy: 0.9844\n",
      "Epoch [30/40], Step [40/94], Loss: 0.0691 Accuracy: 0.9922\n",
      "Epoch [30/40], Step [50/94], Loss: 0.0084 Accuracy: 1.0000\n",
      "Epoch [30/40], Step [60/94], Loss: 0.0389 Accuracy: 0.9922\n",
      "Epoch [30/40], Step [70/94], Loss: 0.0313 Accuracy: 0.9922\n",
      "Epoch [30/40], Step [80/94], Loss: 0.0696 Accuracy: 0.9688\n",
      "Epoch [30/40], Step [90/94], Loss: 0.0271 Accuracy: 0.9922\n",
      "Epoch: 29\tAverage Train Loss: 0.060337\tAverage Train Accuracy: 0.982489\n",
      "Epoch: 29\tAverage Validation Loss: 0.040936\tAverage Validation Accuracy: 0.988851\n",
      "Epoch: 29\tAverage Test Loss: 0.038270\tAverage Test Accuracy: 0.990018\n",
      "Epoch [31/40], Step [0/375], Loss: 0.0126\n",
      "Epoch [31/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [10/375], Loss: 0.0114\n",
      "Epoch [31/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [20/375], Loss: 0.0293\n",
      "Epoch [31/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [30/375], Loss: 0.0042\n",
      "Epoch [31/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [40/375], Loss: 0.0292\n",
      "Epoch [31/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [50/375], Loss: 0.0210\n",
      "Epoch [31/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [60/375], Loss: 0.0005\n",
      "Epoch [31/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [70/375], Loss: 0.0135\n",
      "Epoch [31/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [80/375], Loss: 0.1379\n",
      "Epoch [31/40], Step [80/375], Accuracy: 0.9766\n",
      "Epoch [31/40], Step [90/375], Loss: 0.0330\n",
      "Epoch [31/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [100/375], Loss: 0.0177\n",
      "Epoch [31/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [110/375], Loss: 0.1645\n",
      "Epoch [31/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [31/40], Step [120/375], Loss: 0.0989\n",
      "Epoch [31/40], Step [120/375], Accuracy: 0.9688\n",
      "Epoch [31/40], Step [130/375], Loss: 0.0228\n",
      "Epoch [31/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [140/375], Loss: 0.0496\n",
      "Epoch [31/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [31/40], Step [150/375], Loss: 0.0274\n",
      "Epoch [31/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [160/375], Loss: 0.0048\n",
      "Epoch [31/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [170/375], Loss: 0.0113\n",
      "Epoch [31/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [180/375], Loss: 0.0084\n",
      "Epoch [31/40], Step [180/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [190/375], Loss: 0.0142\n",
      "Epoch [31/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [200/375], Loss: 0.0157\n",
      "Epoch [31/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [210/375], Loss: 0.0099\n",
      "Epoch [31/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [220/375], Loss: 0.0055\n",
      "Epoch [31/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [230/375], Loss: 0.0069\n",
      "Epoch [31/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [240/375], Loss: 0.0596\n",
      "Epoch [31/40], Step [240/375], Accuracy: 0.9766\n",
      "Epoch [31/40], Step [250/375], Loss: 0.0911\n",
      "Epoch [31/40], Step [250/375], Accuracy: 0.9766\n",
      "Epoch [31/40], Step [260/375], Loss: 0.0012\n",
      "Epoch [31/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [270/375], Loss: 0.0448\n",
      "Epoch [31/40], Step [270/375], Accuracy: 0.9766\n",
      "Epoch [31/40], Step [280/375], Loss: 0.0200\n",
      "Epoch [31/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [290/375], Loss: 0.0568\n",
      "Epoch [31/40], Step [290/375], Accuracy: 0.9766\n",
      "Epoch [31/40], Step [300/375], Loss: 0.0658\n",
      "Epoch [31/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [310/375], Loss: 0.0128\n",
      "Epoch [31/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [320/375], Loss: 0.0387\n",
      "Epoch [31/40], Step [320/375], Accuracy: 0.9766\n",
      "Epoch [31/40], Step [330/375], Loss: 0.0390\n",
      "Epoch [31/40], Step [330/375], Accuracy: 0.9844\n",
      "Epoch [31/40], Step [340/375], Loss: 0.0011\n",
      "Epoch [31/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [350/375], Loss: 0.0461\n",
      "Epoch [31/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [31/40], Step [360/375], Loss: 0.0053\n",
      "Epoch [31/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [31/40], Step [370/375], Loss: 0.0183\n",
      "Epoch [31/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [31/40], Step [0/94], Loss: 0.0007 Accuracy: 1.0000\n",
      "Epoch [31/40], Step [10/94], Loss: 0.0046 Accuracy: 1.0000\n",
      "Epoch [31/40], Step [20/94], Loss: 0.0177 Accuracy: 0.9922\n",
      "Epoch [31/40], Step [30/94], Loss: 0.0159 Accuracy: 0.9922\n",
      "Epoch [31/40], Step [40/94], Loss: 0.0067 Accuracy: 1.0000\n",
      "Epoch [31/40], Step [50/94], Loss: 0.0056 Accuracy: 1.0000\n",
      "Epoch [31/40], Step [60/94], Loss: 0.0114 Accuracy: 1.0000\n",
      "Epoch [31/40], Step [70/94], Loss: 0.0350 Accuracy: 0.9766\n",
      "Epoch [31/40], Step [80/94], Loss: 0.0157 Accuracy: 0.9922\n",
      "Epoch [31/40], Step [90/94], Loss: 0.0207 Accuracy: 0.9922\n",
      "Epoch: 30\tAverage Train Loss: 0.059461\tAverage Train Accuracy: 0.982772\n",
      "Epoch: 30\tAverage Validation Loss: 0.040591\tAverage Validation Accuracy: 0.988905\n",
      "Epoch: 30\tAverage Test Loss: 0.038249\tAverage Test Accuracy: 0.990050\n",
      "Epoch [32/40], Step [0/375], Loss: 0.0056\n",
      "Epoch [32/40], Step [0/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [10/375], Loss: 0.0525\n",
      "Epoch [32/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [32/40], Step [20/375], Loss: 0.0660\n",
      "Epoch [32/40], Step [20/375], Accuracy: 0.9688\n",
      "Epoch [32/40], Step [30/375], Loss: 0.0225\n",
      "Epoch [32/40], Step [30/375], Accuracy: 0.9844\n",
      "Epoch [32/40], Step [40/375], Loss: 0.0194\n",
      "Epoch [32/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [50/375], Loss: 0.0355\n",
      "Epoch [32/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [60/375], Loss: 0.0040\n",
      "Epoch [32/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [70/375], Loss: 0.0384\n",
      "Epoch [32/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [80/375], Loss: 0.0126\n",
      "Epoch [32/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [90/375], Loss: 0.0173\n",
      "Epoch [32/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [100/375], Loss: 0.0011\n",
      "Epoch [32/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [110/375], Loss: 0.0008\n",
      "Epoch [32/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [120/375], Loss: 0.0432\n",
      "Epoch [32/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [130/375], Loss: 0.0475\n",
      "Epoch [32/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [32/40], Step [140/375], Loss: 0.0288\n",
      "Epoch [32/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [150/375], Loss: 0.0592\n",
      "Epoch [32/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [160/375], Loss: 0.0010\n",
      "Epoch [32/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [170/375], Loss: 0.0385\n",
      "Epoch [32/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [180/375], Loss: 0.0734\n",
      "Epoch [32/40], Step [180/375], Accuracy: 0.9766\n",
      "Epoch [32/40], Step [190/375], Loss: 0.0070\n",
      "Epoch [32/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [200/375], Loss: 0.1549\n",
      "Epoch [32/40], Step [200/375], Accuracy: 0.9688\n",
      "Epoch [32/40], Step [210/375], Loss: 0.0509\n",
      "Epoch [32/40], Step [210/375], Accuracy: 0.9766\n",
      "Epoch [32/40], Step [220/375], Loss: 0.0020\n",
      "Epoch [32/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [230/375], Loss: 0.0419\n",
      "Epoch [32/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [240/375], Loss: 0.0263\n",
      "Epoch [32/40], Step [240/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [250/375], Loss: 0.0018\n",
      "Epoch [32/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [260/375], Loss: 0.0029\n",
      "Epoch [32/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [270/375], Loss: 0.0328\n",
      "Epoch [32/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [280/375], Loss: 0.0001\n",
      "Epoch [32/40], Step [280/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [290/375], Loss: 0.0202\n",
      "Epoch [32/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [300/375], Loss: 0.1120\n",
      "Epoch [32/40], Step [300/375], Accuracy: 0.9844\n",
      "Epoch [32/40], Step [310/375], Loss: 0.0358\n",
      "Epoch [32/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [320/375], Loss: 0.0034\n",
      "Epoch [32/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [330/375], Loss: 0.0393\n",
      "Epoch [32/40], Step [330/375], Accuracy: 0.9766\n",
      "Epoch [32/40], Step [340/375], Loss: 0.0187\n",
      "Epoch [32/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [350/375], Loss: 0.0048\n",
      "Epoch [32/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [32/40], Step [360/375], Loss: 0.0103\n",
      "Epoch [32/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [32/40], Step [370/375], Loss: 0.0450\n",
      "Epoch [32/40], Step [370/375], Accuracy: 0.9844\n",
      "Epoch [32/40], Step [0/94], Loss: 0.0200 Accuracy: 0.9922\n",
      "Epoch [32/40], Step [10/94], Loss: 0.0037 Accuracy: 1.0000\n",
      "Epoch [32/40], Step [20/94], Loss: 0.0118 Accuracy: 0.9922\n",
      "Epoch [32/40], Step [30/94], Loss: 0.0159 Accuracy: 0.9922\n",
      "Epoch [32/40], Step [40/94], Loss: 0.0134 Accuracy: 0.9922\n",
      "Epoch [32/40], Step [50/94], Loss: 0.0026 Accuracy: 1.0000\n",
      "Epoch [32/40], Step [60/94], Loss: 0.0035 Accuracy: 1.0000\n",
      "Epoch [32/40], Step [70/94], Loss: 0.0426 Accuracy: 0.9922\n",
      "Epoch [32/40], Step [80/94], Loss: 0.0463 Accuracy: 0.9922\n",
      "Epoch [32/40], Step [90/94], Loss: 0.0074 Accuracy: 0.9922\n",
      "Epoch: 31\tAverage Train Loss: 0.058654\tAverage Train Accuracy: 0.983042\n",
      "Epoch: 31\tAverage Validation Loss: 0.040234\tAverage Validation Accuracy: 0.988986\n",
      "Epoch: 31\tAverage Test Loss: 0.037950\tAverage Test Accuracy: 0.990098\n",
      "Epoch [33/40], Step [0/375], Loss: 0.0373\n",
      "Epoch [33/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [10/375], Loss: 0.0055\n",
      "Epoch [33/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [20/375], Loss: 0.0004\n",
      "Epoch [33/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [30/375], Loss: 0.0297\n",
      "Epoch [33/40], Step [30/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [40/375], Loss: 0.0001\n",
      "Epoch [33/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [50/375], Loss: 0.0071\n",
      "Epoch [33/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [60/375], Loss: 0.0364\n",
      "Epoch [33/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [70/375], Loss: 0.0463\n",
      "Epoch [33/40], Step [70/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [80/375], Loss: 0.0210\n",
      "Epoch [33/40], Step [80/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [90/375], Loss: 0.0076\n",
      "Epoch [33/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [100/375], Loss: 0.0912\n",
      "Epoch [33/40], Step [100/375], Accuracy: 0.9766\n",
      "Epoch [33/40], Step [110/375], Loss: 0.0078\n",
      "Epoch [33/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [120/375], Loss: 0.0002\n",
      "Epoch [33/40], Step [120/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [130/375], Loss: 0.0130\n",
      "Epoch [33/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [140/375], Loss: 0.0280\n",
      "Epoch [33/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [150/375], Loss: 0.0188\n",
      "Epoch [33/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [160/375], Loss: 0.0005\n",
      "Epoch [33/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [170/375], Loss: 0.1196\n",
      "Epoch [33/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [180/375], Loss: 0.0124\n",
      "Epoch [33/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [190/375], Loss: 0.0935\n",
      "Epoch [33/40], Step [190/375], Accuracy: 0.9766\n",
      "Epoch [33/40], Step [200/375], Loss: 0.0265\n",
      "Epoch [33/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [210/375], Loss: 0.0286\n",
      "Epoch [33/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [220/375], Loss: 0.0265\n",
      "Epoch [33/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [230/375], Loss: 0.0493\n",
      "Epoch [33/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [240/375], Loss: 0.0838\n",
      "Epoch [33/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [250/375], Loss: 0.0103\n",
      "Epoch [33/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [260/375], Loss: 0.0133\n",
      "Epoch [33/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [270/375], Loss: 0.0269\n",
      "Epoch [33/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [280/375], Loss: 0.0078\n",
      "Epoch [33/40], Step [280/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [290/375], Loss: 0.0056\n",
      "Epoch [33/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [300/375], Loss: 0.0004\n",
      "Epoch [33/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [310/375], Loss: 0.0211\n",
      "Epoch [33/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [320/375], Loss: 0.0237\n",
      "Epoch [33/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [330/375], Loss: 0.0021\n",
      "Epoch [33/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [33/40], Step [340/375], Loss: 0.0390\n",
      "Epoch [33/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [350/375], Loss: 0.0366\n",
      "Epoch [33/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [33/40], Step [360/375], Loss: 0.0250\n",
      "Epoch [33/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [33/40], Step [370/375], Loss: 0.0518\n",
      "Epoch [33/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [33/40], Step [0/94], Loss: 0.0005 Accuracy: 1.0000\n",
      "Epoch [33/40], Step [10/94], Loss: 0.0051 Accuracy: 1.0000\n",
      "Epoch [33/40], Step [20/94], Loss: 0.0191 Accuracy: 0.9922\n",
      "Epoch [33/40], Step [30/94], Loss: 0.0153 Accuracy: 1.0000\n",
      "Epoch [33/40], Step [40/94], Loss: 0.0024 Accuracy: 1.0000\n",
      "Epoch [33/40], Step [50/94], Loss: 0.0003 Accuracy: 1.0000\n",
      "Epoch [33/40], Step [60/94], Loss: 0.0056 Accuracy: 1.0000\n",
      "Epoch [33/40], Step [70/94], Loss: 0.0934 Accuracy: 0.9766\n",
      "Epoch [33/40], Step [80/94], Loss: 0.0424 Accuracy: 0.9844\n",
      "Epoch [33/40], Step [90/94], Loss: 0.0263 Accuracy: 0.9922\n",
      "Epoch: 32\tAverage Train Loss: 0.057877\tAverage Train Accuracy: 0.983270\n",
      "Epoch: 32\tAverage Validation Loss: 0.040070\tAverage Validation Accuracy: 0.989080\n",
      "Epoch: 32\tAverage Test Loss: 0.037944\tAverage Test Accuracy: 0.990156\n",
      "Epoch [34/40], Step [0/375], Loss: 0.0086\n",
      "Epoch [34/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [10/375], Loss: 0.0231\n",
      "Epoch [34/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [20/375], Loss: 0.0204\n",
      "Epoch [34/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [30/375], Loss: 0.0135\n",
      "Epoch [34/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [40/375], Loss: 0.0026\n",
      "Epoch [34/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [50/375], Loss: 0.1354\n",
      "Epoch [34/40], Step [50/375], Accuracy: 0.9766\n",
      "Epoch [34/40], Step [60/375], Loss: 0.0027\n",
      "Epoch [34/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [70/375], Loss: 0.0018\n",
      "Epoch [34/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [80/375], Loss: 0.0228\n",
      "Epoch [34/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [90/375], Loss: 0.0574\n",
      "Epoch [34/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [100/375], Loss: 0.0067\n",
      "Epoch [34/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [110/375], Loss: 0.0512\n",
      "Epoch [34/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [120/375], Loss: 0.0406\n",
      "Epoch [34/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [130/375], Loss: 0.1049\n",
      "Epoch [34/40], Step [130/375], Accuracy: 0.9766\n",
      "Epoch [34/40], Step [140/375], Loss: 0.0413\n",
      "Epoch [34/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [150/375], Loss: 0.1032\n",
      "Epoch [34/40], Step [150/375], Accuracy: 0.9688\n",
      "Epoch [34/40], Step [160/375], Loss: 0.0178\n",
      "Epoch [34/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [170/375], Loss: 0.0287\n",
      "Epoch [34/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [180/375], Loss: 0.0111\n",
      "Epoch [34/40], Step [180/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [190/375], Loss: 0.0034\n",
      "Epoch [34/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [200/375], Loss: 0.0166\n",
      "Epoch [34/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [210/375], Loss: 0.0050\n",
      "Epoch [34/40], Step [210/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [220/375], Loss: 0.0731\n",
      "Epoch [34/40], Step [220/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [230/375], Loss: 0.0001\n",
      "Epoch [34/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [240/375], Loss: 0.0282\n",
      "Epoch [34/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [250/375], Loss: 0.0135\n",
      "Epoch [34/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [260/375], Loss: 0.0725\n",
      "Epoch [34/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [270/375], Loss: 0.0692\n",
      "Epoch [34/40], Step [270/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [280/375], Loss: 0.0040\n",
      "Epoch [34/40], Step [280/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [290/375], Loss: 0.0010\n",
      "Epoch [34/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [300/375], Loss: 0.0398\n",
      "Epoch [34/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [310/375], Loss: 0.0388\n",
      "Epoch [34/40], Step [310/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [320/375], Loss: 0.0124\n",
      "Epoch [34/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [330/375], Loss: 0.0302\n",
      "Epoch [34/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [34/40], Step [340/375], Loss: 0.0166\n",
      "Epoch [34/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [350/375], Loss: 0.0004\n",
      "Epoch [34/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [360/375], Loss: 0.0276\n",
      "Epoch [34/40], Step [360/375], Accuracy: 0.9844\n",
      "Epoch [34/40], Step [370/375], Loss: 0.0011\n",
      "Epoch [34/40], Step [370/375], Accuracy: 1.0000\n",
      "Epoch [34/40], Step [0/94], Loss: 0.0013 Accuracy: 1.0000\n",
      "Epoch [34/40], Step [10/94], Loss: 0.0417 Accuracy: 0.9922\n",
      "Epoch [34/40], Step [20/94], Loss: 0.0221 Accuracy: 0.9922\n",
      "Epoch [34/40], Step [30/94], Loss: 0.0409 Accuracy: 0.9844\n",
      "Epoch [34/40], Step [40/94], Loss: 0.0035 Accuracy: 1.0000\n",
      "Epoch [34/40], Step [50/94], Loss: 0.0016 Accuracy: 1.0000\n",
      "Epoch [34/40], Step [60/94], Loss: 0.0161 Accuracy: 0.9922\n",
      "Epoch [34/40], Step [70/94], Loss: 0.0303 Accuracy: 0.9844\n",
      "Epoch [34/40], Step [80/94], Loss: 0.0381 Accuracy: 0.9844\n",
      "Epoch [34/40], Step [90/94], Loss: 0.0053 Accuracy: 1.0000\n",
      "Epoch: 33\tAverage Train Loss: 0.056977\tAverage Train Accuracy: 0.983549\n",
      "Epoch: 33\tAverage Validation Loss: 0.039753\tAverage Validation Accuracy: 0.989169\n",
      "Epoch: 33\tAverage Test Loss: 0.038161\tAverage Test Accuracy: 0.990178\n",
      "Epoch [35/40], Step [0/375], Loss: 0.0057\n",
      "Epoch [35/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [10/375], Loss: 0.0485\n",
      "Epoch [35/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [20/375], Loss: 0.0377\n",
      "Epoch [35/40], Step [20/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [30/375], Loss: 0.0069\n",
      "Epoch [35/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [40/375], Loss: 0.0167\n",
      "Epoch [35/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [50/375], Loss: 0.0259\n",
      "Epoch [35/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [60/375], Loss: 0.0005\n",
      "Epoch [35/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [70/375], Loss: 0.0047\n",
      "Epoch [35/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [80/375], Loss: 0.0004\n",
      "Epoch [35/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [90/375], Loss: 0.0261\n",
      "Epoch [35/40], Step [90/375], Accuracy: 0.9766\n",
      "Epoch [35/40], Step [100/375], Loss: 0.0375\n",
      "Epoch [35/40], Step [100/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [110/375], Loss: 0.0043\n",
      "Epoch [35/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [120/375], Loss: 0.0013\n",
      "Epoch [35/40], Step [120/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [130/375], Loss: 0.0229\n",
      "Epoch [35/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [140/375], Loss: 0.0968\n",
      "Epoch [35/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [150/375], Loss: 0.0357\n",
      "Epoch [35/40], Step [150/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [160/375], Loss: 0.0020\n",
      "Epoch [35/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [170/375], Loss: 0.0808\n",
      "Epoch [35/40], Step [170/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [180/375], Loss: 0.0273\n",
      "Epoch [35/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [190/375], Loss: 0.0036\n",
      "Epoch [35/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [200/375], Loss: 0.0566\n",
      "Epoch [35/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [210/375], Loss: 0.0627\n",
      "Epoch [35/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [220/375], Loss: 0.0055\n",
      "Epoch [35/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [230/375], Loss: 0.0113\n",
      "Epoch [35/40], Step [230/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [240/375], Loss: 0.0388\n",
      "Epoch [35/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [250/375], Loss: 0.0031\n",
      "Epoch [35/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [260/375], Loss: 0.0073\n",
      "Epoch [35/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [270/375], Loss: 0.1576\n",
      "Epoch [35/40], Step [270/375], Accuracy: 0.9531\n",
      "Epoch [35/40], Step [280/375], Loss: 0.0004\n",
      "Epoch [35/40], Step [280/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [290/375], Loss: 0.0006\n",
      "Epoch [35/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [300/375], Loss: 0.0159\n",
      "Epoch [35/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [310/375], Loss: 0.0517\n",
      "Epoch [35/40], Step [310/375], Accuracy: 0.9766\n",
      "Epoch [35/40], Step [320/375], Loss: 0.0364\n",
      "Epoch [35/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [330/375], Loss: 0.0397\n",
      "Epoch [35/40], Step [330/375], Accuracy: 0.9844\n",
      "Epoch [35/40], Step [340/375], Loss: 0.0054\n",
      "Epoch [35/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [350/375], Loss: 0.0052\n",
      "Epoch [35/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [35/40], Step [360/375], Loss: 0.0583\n",
      "Epoch [35/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [370/375], Loss: 0.0156\n",
      "Epoch [35/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [35/40], Step [0/94], Loss: 0.0023 Accuracy: 1.0000\n",
      "Epoch [35/40], Step [10/94], Loss: 0.0150 Accuracy: 0.9922\n",
      "Epoch [35/40], Step [20/94], Loss: 0.0121 Accuracy: 0.9922\n",
      "Epoch [35/40], Step [30/94], Loss: 0.0149 Accuracy: 0.9922\n",
      "Epoch [35/40], Step [40/94], Loss: 0.0062 Accuracy: 1.0000\n",
      "Epoch [35/40], Step [50/94], Loss: 0.0071 Accuracy: 1.0000\n",
      "Epoch [35/40], Step [60/94], Loss: 0.0218 Accuracy: 0.9922\n",
      "Epoch [35/40], Step [70/94], Loss: 0.0730 Accuracy: 0.9844\n",
      "Epoch [35/40], Step [80/94], Loss: 0.0209 Accuracy: 0.9922\n",
      "Epoch [35/40], Step [90/94], Loss: 0.0091 Accuracy: 0.9922\n",
      "Epoch: 34\tAverage Train Loss: 0.056291\tAverage Train Accuracy: 0.983764\n",
      "Epoch: 34\tAverage Validation Loss: 0.039684\tAverage Validation Accuracy: 0.989239\n",
      "Epoch: 34\tAverage Test Loss: 0.037964\tAverage Test Accuracy: 0.990227\n",
      "Epoch [36/40], Step [0/375], Loss: 0.0235\n",
      "Epoch [36/40], Step [0/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [10/375], Loss: 0.0341\n",
      "Epoch [36/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [20/375], Loss: 0.0070\n",
      "Epoch [36/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [30/375], Loss: 0.0592\n",
      "Epoch [36/40], Step [30/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [40/375], Loss: 0.0513\n",
      "Epoch [36/40], Step [40/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [50/375], Loss: 0.0234\n",
      "Epoch [36/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [60/375], Loss: 0.0042\n",
      "Epoch [36/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [70/375], Loss: 0.0232\n",
      "Epoch [36/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [80/375], Loss: 0.0349\n",
      "Epoch [36/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [90/375], Loss: 0.0027\n",
      "Epoch [36/40], Step [90/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [100/375], Loss: 0.1251\n",
      "Epoch [36/40], Step [100/375], Accuracy: 0.9531\n",
      "Epoch [36/40], Step [110/375], Loss: 0.0859\n",
      "Epoch [36/40], Step [110/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [120/375], Loss: 0.0183\n",
      "Epoch [36/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [130/375], Loss: 0.0196\n",
      "Epoch [36/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [140/375], Loss: 0.0033\n",
      "Epoch [36/40], Step [140/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [150/375], Loss: 0.0080\n",
      "Epoch [36/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [160/375], Loss: 0.0016\n",
      "Epoch [36/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [170/375], Loss: 0.0236\n",
      "Epoch [36/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [180/375], Loss: 0.0364\n",
      "Epoch [36/40], Step [180/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [190/375], Loss: 0.0348\n",
      "Epoch [36/40], Step [190/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [200/375], Loss: 0.0973\n",
      "Epoch [36/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [210/375], Loss: 0.0433\n",
      "Epoch [36/40], Step [210/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [220/375], Loss: 0.0559\n",
      "Epoch [36/40], Step [220/375], Accuracy: 0.9766\n",
      "Epoch [36/40], Step [230/375], Loss: 0.0006\n",
      "Epoch [36/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [240/375], Loss: 0.0045\n",
      "Epoch [36/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [250/375], Loss: 0.0084\n",
      "Epoch [36/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [260/375], Loss: 0.0095\n",
      "Epoch [36/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [270/375], Loss: 0.0253\n",
      "Epoch [36/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [280/375], Loss: 0.0034\n",
      "Epoch [36/40], Step [280/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [290/375], Loss: 0.0226\n",
      "Epoch [36/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [300/375], Loss: 0.0423\n",
      "Epoch [36/40], Step [300/375], Accuracy: 0.9766\n",
      "Epoch [36/40], Step [310/375], Loss: 0.0486\n",
      "Epoch [36/40], Step [310/375], Accuracy: 0.9844\n",
      "Epoch [36/40], Step [320/375], Loss: 0.0020\n",
      "Epoch [36/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [330/375], Loss: 0.0003\n",
      "Epoch [36/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [340/375], Loss: 0.0431\n",
      "Epoch [36/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [350/375], Loss: 0.0551\n",
      "Epoch [36/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [360/375], Loss: 0.0066\n",
      "Epoch [36/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [36/40], Step [370/375], Loss: 0.0377\n",
      "Epoch [36/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [36/40], Step [0/94], Loss: 0.0031 Accuracy: 1.0000\n",
      "Epoch [36/40], Step [10/94], Loss: 0.0042 Accuracy: 1.0000\n",
      "Epoch [36/40], Step [20/94], Loss: 0.0144 Accuracy: 0.9922\n",
      "Epoch [36/40], Step [30/94], Loss: 0.0073 Accuracy: 1.0000\n",
      "Epoch [36/40], Step [40/94], Loss: 0.0146 Accuracy: 1.0000\n",
      "Epoch [36/40], Step [50/94], Loss: 0.0067 Accuracy: 1.0000\n",
      "Epoch [36/40], Step [60/94], Loss: 0.0169 Accuracy: 0.9922\n",
      "Epoch [36/40], Step [70/94], Loss: 0.0582 Accuracy: 0.9766\n",
      "Epoch [36/40], Step [80/94], Loss: 0.0206 Accuracy: 1.0000\n",
      "Epoch [36/40], Step [90/94], Loss: 0.0221 Accuracy: 0.9922\n",
      "Epoch: 35\tAverage Train Loss: 0.055510\tAverage Train Accuracy: 0.984005\n",
      "Epoch: 35\tAverage Validation Loss: 0.039456\tAverage Validation Accuracy: 0.989326\n",
      "Epoch: 35\tAverage Test Loss: 0.037857\tAverage Test Accuracy: 0.990245\n",
      "Epoch [37/40], Step [0/375], Loss: 0.0237\n",
      "Epoch [37/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [10/375], Loss: 0.0121\n",
      "Epoch [37/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [20/375], Loss: 0.0930\n",
      "Epoch [37/40], Step [20/375], Accuracy: 0.9844\n",
      "Epoch [37/40], Step [30/375], Loss: 0.0010\n",
      "Epoch [37/40], Step [30/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [40/375], Loss: 0.0109\n",
      "Epoch [37/40], Step [40/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [50/375], Loss: 0.0019\n",
      "Epoch [37/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [60/375], Loss: 0.0073\n",
      "Epoch [37/40], Step [60/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [70/375], Loss: 0.0147\n",
      "Epoch [37/40], Step [70/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [80/375], Loss: 0.0006\n",
      "Epoch [37/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [90/375], Loss: 0.0138\n",
      "Epoch [37/40], Step [90/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [100/375], Loss: 0.0497\n",
      "Epoch [37/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [110/375], Loss: 0.0001\n",
      "Epoch [37/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [120/375], Loss: 0.0890\n",
      "Epoch [37/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [130/375], Loss: 0.0153\n",
      "Epoch [37/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [140/375], Loss: 0.0283\n",
      "Epoch [37/40], Step [140/375], Accuracy: 0.9766\n",
      "Epoch [37/40], Step [150/375], Loss: 0.0031\n",
      "Epoch [37/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [160/375], Loss: 0.0011\n",
      "Epoch [37/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [170/375], Loss: 0.0105\n",
      "Epoch [37/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [180/375], Loss: 0.0394\n",
      "Epoch [37/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [190/375], Loss: 0.0014\n",
      "Epoch [37/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [200/375], Loss: 0.0040\n",
      "Epoch [37/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [210/375], Loss: 0.0023\n",
      "Epoch [37/40], Step [210/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [220/375], Loss: 0.0105\n",
      "Epoch [37/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [230/375], Loss: 0.0118\n",
      "Epoch [37/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [240/375], Loss: 0.0088\n",
      "Epoch [37/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [250/375], Loss: 0.0009\n",
      "Epoch [37/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [260/375], Loss: 0.0175\n",
      "Epoch [37/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [270/375], Loss: 0.1736\n",
      "Epoch [37/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [37/40], Step [280/375], Loss: 0.0205\n",
      "Epoch [37/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [290/375], Loss: 0.0681\n",
      "Epoch [37/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [300/375], Loss: 0.0051\n",
      "Epoch [37/40], Step [300/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [310/375], Loss: 0.0051\n",
      "Epoch [37/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [320/375], Loss: 0.0186\n",
      "Epoch [37/40], Step [320/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [330/375], Loss: 0.0118\n",
      "Epoch [37/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [340/375], Loss: 0.0113\n",
      "Epoch [37/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [350/375], Loss: 0.0019\n",
      "Epoch [37/40], Step [350/375], Accuracy: 1.0000\n",
      "Epoch [37/40], Step [360/375], Loss: 0.1489\n",
      "Epoch [37/40], Step [360/375], Accuracy: 0.9922\n",
      "Epoch [37/40], Step [370/375], Loss: 0.0405\n",
      "Epoch [37/40], Step [370/375], Accuracy: 0.9844\n",
      "Epoch [37/40], Step [0/94], Loss: 0.0117 Accuracy: 0.9922\n",
      "Epoch [37/40], Step [10/94], Loss: 0.0021 Accuracy: 1.0000\n",
      "Epoch [37/40], Step [20/94], Loss: 0.0112 Accuracy: 0.9922\n",
      "Epoch [37/40], Step [30/94], Loss: 0.0897 Accuracy: 0.9844\n",
      "Epoch [37/40], Step [40/94], Loss: 0.0144 Accuracy: 1.0000\n",
      "Epoch [37/40], Step [50/94], Loss: 0.0096 Accuracy: 1.0000\n",
      "Epoch [37/40], Step [60/94], Loss: 0.0276 Accuracy: 0.9844\n",
      "Epoch [37/40], Step [70/94], Loss: 0.0849 Accuracy: 0.9688\n",
      "Epoch [37/40], Step [80/94], Loss: 0.0314 Accuracy: 0.9922\n",
      "Epoch [37/40], Step [90/94], Loss: 0.0075 Accuracy: 0.9922\n",
      "Epoch: 36\tAverage Train Loss: 0.054819\tAverage Train Accuracy: 0.984218\n",
      "Epoch: 36\tAverage Validation Loss: 0.039658\tAverage Validation Accuracy: 0.989311\n",
      "Epoch: 36\tAverage Test Loss: 0.038217\tAverage Test Accuracy: 0.990212\n",
      "Epoch [38/40], Step [0/375], Loss: 0.0257\n",
      "Epoch [38/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [10/375], Loss: 0.0060\n",
      "Epoch [38/40], Step [10/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [20/375], Loss: 0.0031\n",
      "Epoch [38/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [30/375], Loss: 0.0931\n",
      "Epoch [38/40], Step [30/375], Accuracy: 0.9688\n",
      "Epoch [38/40], Step [40/375], Loss: 0.0749\n",
      "Epoch [38/40], Step [40/375], Accuracy: 0.9844\n",
      "Epoch [38/40], Step [50/375], Loss: 0.0348\n",
      "Epoch [38/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [60/375], Loss: 0.1456\n",
      "Epoch [38/40], Step [60/375], Accuracy: 0.9609\n",
      "Epoch [38/40], Step [70/375], Loss: 0.1990\n",
      "Epoch [38/40], Step [70/375], Accuracy: 0.9531\n",
      "Epoch [38/40], Step [80/375], Loss: 0.0075\n",
      "Epoch [38/40], Step [80/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [90/375], Loss: 0.0852\n",
      "Epoch [38/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [38/40], Step [100/375], Loss: 0.1023\n",
      "Epoch [38/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [110/375], Loss: 0.0059\n",
      "Epoch [38/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [120/375], Loss: 0.0972\n",
      "Epoch [38/40], Step [120/375], Accuracy: 0.9844\n",
      "Epoch [38/40], Step [130/375], Loss: 0.0106\n",
      "Epoch [38/40], Step [130/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [140/375], Loss: 0.0513\n",
      "Epoch [38/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [38/40], Step [150/375], Loss: 0.0293\n",
      "Epoch [38/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [160/375], Loss: 0.0091\n",
      "Epoch [38/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [170/375], Loss: 0.0058\n",
      "Epoch [38/40], Step [170/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [180/375], Loss: 0.0207\n",
      "Epoch [38/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [190/375], Loss: 0.0602\n",
      "Epoch [38/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [200/375], Loss: 0.1016\n",
      "Epoch [38/40], Step [200/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [210/375], Loss: 0.0157\n",
      "Epoch [38/40], Step [210/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [220/375], Loss: 0.0118\n",
      "Epoch [38/40], Step [220/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [230/375], Loss: 0.0175\n",
      "Epoch [38/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [240/375], Loss: 0.0027\n",
      "Epoch [38/40], Step [240/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [250/375], Loss: 0.0031\n",
      "Epoch [38/40], Step [250/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [260/375], Loss: 0.0060\n",
      "Epoch [38/40], Step [260/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [270/375], Loss: 0.0009\n",
      "Epoch [38/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [280/375], Loss: 0.0356\n",
      "Epoch [38/40], Step [280/375], Accuracy: 0.9844\n",
      "Epoch [38/40], Step [290/375], Loss: 0.0243\n",
      "Epoch [38/40], Step [290/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [300/375], Loss: 0.0343\n",
      "Epoch [38/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [310/375], Loss: 0.1398\n",
      "Epoch [38/40], Step [310/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [320/375], Loss: 0.0119\n",
      "Epoch [38/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [38/40], Step [330/375], Loss: 0.0177\n",
      "Epoch [38/40], Step [330/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [340/375], Loss: 0.0152\n",
      "Epoch [38/40], Step [340/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [350/375], Loss: 0.0200\n",
      "Epoch [38/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [360/375], Loss: 0.0674\n",
      "Epoch [38/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [38/40], Step [370/375], Loss: 0.0235\n",
      "Epoch [38/40], Step [370/375], Accuracy: 0.9922\n",
      "Epoch [38/40], Step [0/94], Loss: 0.0046 Accuracy: 1.0000\n",
      "Epoch [38/40], Step [10/94], Loss: 0.0005 Accuracy: 1.0000\n",
      "Epoch [38/40], Step [20/94], Loss: 0.0132 Accuracy: 0.9922\n",
      "Epoch [38/40], Step [30/94], Loss: 0.0148 Accuracy: 0.9922\n",
      "Epoch [38/40], Step [40/94], Loss: 0.0144 Accuracy: 0.9922\n",
      "Epoch [38/40], Step [50/94], Loss: 0.0019 Accuracy: 1.0000\n",
      "Epoch [38/40], Step [60/94], Loss: 0.0116 Accuracy: 1.0000\n",
      "Epoch [38/40], Step [70/94], Loss: 0.0265 Accuracy: 0.9766\n",
      "Epoch [38/40], Step [80/94], Loss: 0.0210 Accuracy: 0.9922\n",
      "Epoch [38/40], Step [90/94], Loss: 0.0123 Accuracy: 1.0000\n",
      "Epoch: 37\tAverage Train Loss: 0.054595\tAverage Train Accuracy: 0.984343\n",
      "Epoch: 37\tAverage Validation Loss: 0.039571\tAverage Validation Accuracy: 0.989380\n",
      "Epoch: 37\tAverage Test Loss: 0.037825\tAverage Test Accuracy: 0.990319\n",
      "Epoch [39/40], Step [0/375], Loss: 0.0273\n",
      "Epoch [39/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [10/375], Loss: 0.0252\n",
      "Epoch [39/40], Step [10/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [20/375], Loss: 0.0017\n",
      "Epoch [39/40], Step [20/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [30/375], Loss: 0.0280\n",
      "Epoch [39/40], Step [30/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [40/375], Loss: 0.0020\n",
      "Epoch [39/40], Step [40/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [50/375], Loss: 0.0259\n",
      "Epoch [39/40], Step [50/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [60/375], Loss: 0.0327\n",
      "Epoch [39/40], Step [60/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [70/375], Loss: 0.0072\n",
      "Epoch [39/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [80/375], Loss: 0.1150\n",
      "Epoch [39/40], Step [80/375], Accuracy: 0.9766\n",
      "Epoch [39/40], Step [90/375], Loss: 0.0035\n",
      "Epoch [39/40], Step [90/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [100/375], Loss: 0.0310\n",
      "Epoch [39/40], Step [100/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [110/375], Loss: 0.0049\n",
      "Epoch [39/40], Step [110/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [120/375], Loss: 0.0133\n",
      "Epoch [39/40], Step [120/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [130/375], Loss: 0.0501\n",
      "Epoch [39/40], Step [130/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [140/375], Loss: 0.0142\n",
      "Epoch [39/40], Step [140/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [150/375], Loss: 0.0063\n",
      "Epoch [39/40], Step [150/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [160/375], Loss: 0.0890\n",
      "Epoch [39/40], Step [160/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [170/375], Loss: 0.0059\n",
      "Epoch [39/40], Step [170/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [180/375], Loss: 0.0209\n",
      "Epoch [39/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [190/375], Loss: 0.0081\n",
      "Epoch [39/40], Step [190/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [200/375], Loss: 0.0936\n",
      "Epoch [39/40], Step [200/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [210/375], Loss: 0.0069\n",
      "Epoch [39/40], Step [210/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [220/375], Loss: 0.0009\n",
      "Epoch [39/40], Step [220/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [230/375], Loss: 0.0868\n",
      "Epoch [39/40], Step [230/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [240/375], Loss: 0.0510\n",
      "Epoch [39/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [250/375], Loss: 0.0146\n",
      "Epoch [39/40], Step [250/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [260/375], Loss: 0.0177\n",
      "Epoch [39/40], Step [260/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [270/375], Loss: 0.0488\n",
      "Epoch [39/40], Step [270/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [280/375], Loss: 0.0089\n",
      "Epoch [39/40], Step [280/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [290/375], Loss: 0.0768\n",
      "Epoch [39/40], Step [290/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [300/375], Loss: 0.0140\n",
      "Epoch [39/40], Step [300/375], Accuracy: 0.9922\n",
      "Epoch [39/40], Step [310/375], Loss: 0.0556\n",
      "Epoch [39/40], Step [310/375], Accuracy: 0.9688\n",
      "Epoch [39/40], Step [320/375], Loss: 0.0118\n",
      "Epoch [39/40], Step [320/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [330/375], Loss: 0.0075\n",
      "Epoch [39/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [340/375], Loss: 0.0114\n",
      "Epoch [39/40], Step [340/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [350/375], Loss: 0.0301\n",
      "Epoch [39/40], Step [350/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [360/375], Loss: 0.0017\n",
      "Epoch [39/40], Step [360/375], Accuracy: 1.0000\n",
      "Epoch [39/40], Step [370/375], Loss: 0.0323\n",
      "Epoch [39/40], Step [370/375], Accuracy: 0.9844\n",
      "Epoch [39/40], Step [0/94], Loss: 0.0049 Accuracy: 1.0000\n",
      "Epoch [39/40], Step [10/94], Loss: 0.0009 Accuracy: 1.0000\n",
      "Epoch [39/40], Step [20/94], Loss: 0.0287 Accuracy: 0.9922\n",
      "Epoch [39/40], Step [30/94], Loss: 0.0450 Accuracy: 0.9922\n",
      "Epoch [39/40], Step [40/94], Loss: 0.0131 Accuracy: 0.9922\n",
      "Epoch [39/40], Step [50/94], Loss: 0.0255 Accuracy: 0.9922\n",
      "Epoch [39/40], Step [60/94], Loss: 0.0226 Accuracy: 0.9922\n",
      "Epoch [39/40], Step [70/94], Loss: 0.0145 Accuracy: 0.9922\n",
      "Epoch [39/40], Step [80/94], Loss: 0.0429 Accuracy: 0.9844\n",
      "Epoch [39/40], Step [90/94], Loss: 0.0136 Accuracy: 0.9922\n",
      "Epoch: 38\tAverage Train Loss: 0.053932\tAverage Train Accuracy: 0.984544\n",
      "Epoch: 38\tAverage Validation Loss: 0.039330\tAverage Validation Accuracy: 0.989431\n",
      "Epoch: 38\tAverage Test Loss: 0.037451\tAverage Test Accuracy: 0.990400\n",
      "Epoch [40/40], Step [0/375], Loss: 0.0445\n",
      "Epoch [40/40], Step [0/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [10/375], Loss: 0.0480\n",
      "Epoch [40/40], Step [10/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [20/375], Loss: 0.0483\n",
      "Epoch [40/40], Step [20/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [30/375], Loss: 0.0470\n",
      "Epoch [40/40], Step [30/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [40/375], Loss: 0.0242\n",
      "Epoch [40/40], Step [40/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [50/375], Loss: 0.0071\n",
      "Epoch [40/40], Step [50/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [60/375], Loss: 0.0973\n",
      "Epoch [40/40], Step [60/375], Accuracy: 0.9766\n",
      "Epoch [40/40], Step [70/375], Loss: 0.0033\n",
      "Epoch [40/40], Step [70/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [80/375], Loss: 0.0322\n",
      "Epoch [40/40], Step [80/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [90/375], Loss: 0.0680\n",
      "Epoch [40/40], Step [90/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [100/375], Loss: 0.0012\n",
      "Epoch [40/40], Step [100/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [110/375], Loss: 0.0170\n",
      "Epoch [40/40], Step [110/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [120/375], Loss: 0.1298\n",
      "Epoch [40/40], Step [120/375], Accuracy: 0.9766\n",
      "Epoch [40/40], Step [130/375], Loss: 0.0159\n",
      "Epoch [40/40], Step [130/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [140/375], Loss: 0.0477\n",
      "Epoch [40/40], Step [140/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [150/375], Loss: 0.0445\n",
      "Epoch [40/40], Step [150/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [160/375], Loss: 0.0034\n",
      "Epoch [40/40], Step [160/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [170/375], Loss: 0.0083\n",
      "Epoch [40/40], Step [170/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [180/375], Loss: 0.0350\n",
      "Epoch [40/40], Step [180/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [190/375], Loss: 0.0118\n",
      "Epoch [40/40], Step [190/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [200/375], Loss: 0.0074\n",
      "Epoch [40/40], Step [200/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [210/375], Loss: 0.0058\n",
      "Epoch [40/40], Step [210/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [220/375], Loss: 0.0905\n",
      "Epoch [40/40], Step [220/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [230/375], Loss: 0.0003\n",
      "Epoch [40/40], Step [230/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [240/375], Loss: 0.0707\n",
      "Epoch [40/40], Step [240/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [250/375], Loss: 0.1228\n",
      "Epoch [40/40], Step [250/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [260/375], Loss: 0.1464\n",
      "Epoch [40/40], Step [260/375], Accuracy: 0.9766\n",
      "Epoch [40/40], Step [270/375], Loss: 0.0015\n",
      "Epoch [40/40], Step [270/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [280/375], Loss: 0.0001\n",
      "Epoch [40/40], Step [280/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [290/375], Loss: 0.0006\n",
      "Epoch [40/40], Step [290/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [300/375], Loss: 0.0393\n",
      "Epoch [40/40], Step [300/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [310/375], Loss: 0.0100\n",
      "Epoch [40/40], Step [310/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [320/375], Loss: 0.0514\n",
      "Epoch [40/40], Step [320/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [330/375], Loss: 0.0157\n",
      "Epoch [40/40], Step [330/375], Accuracy: 1.0000\n",
      "Epoch [40/40], Step [340/375], Loss: 0.0592\n",
      "Epoch [40/40], Step [340/375], Accuracy: 0.9844\n",
      "Epoch [40/40], Step [350/375], Loss: 0.0461\n",
      "Epoch [40/40], Step [350/375], Accuracy: 0.9922\n",
      "Epoch [40/40], Step [360/375], Loss: 0.1172\n",
      "Epoch [40/40], Step [360/375], Accuracy: 0.9766\n",
      "Epoch [40/40], Step [370/375], Loss: 0.0714\n",
      "Epoch [40/40], Step [370/375], Accuracy: 0.9766\n",
      "Epoch [40/40], Step [0/94], Loss: 0.0081 Accuracy: 1.0000\n",
      "Epoch [40/40], Step [10/94], Loss: 0.0118 Accuracy: 0.9922\n",
      "Epoch [40/40], Step [20/94], Loss: 0.0166 Accuracy: 0.9922\n",
      "Epoch [40/40], Step [30/94], Loss: 0.0174 Accuracy: 0.9922\n",
      "Epoch [40/40], Step [40/94], Loss: 0.0160 Accuracy: 0.9922\n",
      "Epoch [40/40], Step [50/94], Loss: 0.1623 Accuracy: 0.9922\n",
      "Epoch [40/40], Step [60/94], Loss: 0.0185 Accuracy: 0.9922\n",
      "Epoch [40/40], Step [70/94], Loss: 0.0575 Accuracy: 0.9844\n",
      "Epoch [40/40], Step [80/94], Loss: 0.0439 Accuracy: 0.9922\n",
      "Epoch [40/40], Step [90/94], Loss: 0.0034 Accuracy: 1.0000\n",
      "Epoch: 39\tAverage Train Loss: 0.053372\tAverage Train Accuracy: 0.984730\n",
      "Epoch: 39\tAverage Validation Loss: 0.039552\tAverage Validation Accuracy: 0.989437\n",
      "Epoch: 39\tAverage Test Loss: 0.037543\tAverage Test Accuracy: 0.990400\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_val = []\n",
    "loss_val = []\n",
    "acc_test = []\n",
    "loss_test = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        logits = model(features)\n",
    "        loss = loss_fn(logits, targets)\n",
    "        acc = accuracy(logits, targets)\n",
    "        \n",
    "        # log training\n",
    "        acc_train.append(acc.item())\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "        # log training\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Step [{batch_idx}/{NUM_BATCHES}], Loss: {loss.item():.4f}')\n",
    "            #writer.add_scalar('Training Loss(Every 10 batch)', loss.item(), epoch * NUM_BATCHES + batch_idx)\n",
    "            print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Step [{batch_idx}/{NUM_BATCHES}], Accuracy: {acc.item():.4f}')\n",
    "            #writer.add_scalar('Training Accuracy(Every 10 batch)', acc.item(), epoch * NUM_BATCHES + batch_idx)\n",
    "            \n",
    "            \n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (features, targets) in enumerate(val_loader):\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward\n",
    "            logits = model(features)\n",
    "            loss = loss_fn(logits, targets)\n",
    "            acc = accuracy(logits, targets)\n",
    "            \n",
    "            # log validation\n",
    "            acc_val.append(acc.item())\n",
    "            loss_val.append(loss.item())\n",
    "\n",
    "            # log validation\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Step [{batch_idx}/{NUM_BATCHES_VAL}], Loss: {loss.item():.4f}', f'Accuracy: {acc.item():.4f}')\n",
    "                #writer.add_scalar('Validation Loss (10 batch)', loss.item(), epoch * NUM_BATCHES_VAL + batch_idx) # Loss every 10 batch\n",
    "                #writer.add_scalar('Validation Accuracy (10 batch)', acc.item(), epoch * NUM_BATCHES_VAL + batch_idx) # Accuracy every 10 batch\n",
    "\n",
    "    # Calculate average loss and accuracy over an epoch\n",
    "    avg_loss_train = np.mean(loss_train)\n",
    "    avg_acc_train = np.mean(acc_train)\n",
    "    avg_loss_val = np.mean(loss_val)\n",
    "    avg_acc_val = np.mean(acc_val)\n",
    "    \n",
    "    # Log average loss and accuracy of an epoch\n",
    "    writer.add_scalar('Loss/train', avg_loss_train, epoch)\n",
    "    writer.add_scalar('Accuracy/train', avg_acc_train, epoch)\n",
    "    writer.add_scalar('Loss/val', avg_loss_val, epoch)\n",
    "    writer.add_scalar('Accuracy/val', avg_acc_val, epoch)\n",
    "    print(f'Epoch: {epoch}\\tAverage Train Loss: {avg_loss_train:.6f}\\tAverage Train Accuracy: {avg_acc_train:.6f}')\n",
    "    print(f'Epoch: {epoch}\\tAverage Validation Loss: {avg_loss_val:.6f}\\tAverage Validation Accuracy: {avg_acc_val:.6f}')\n",
    "    \n",
    "    # Test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            # Move data to device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "    \n",
    "            # Forward\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            acc = accuracy(output, target)\n",
    "    \n",
    "            # Log loss and accuracy\n",
    "            acc_test.append(acc.item())\n",
    "            loss_test.append(loss.item())\n",
    "            \n",
    "    # log test every epoch\n",
    "    avg_loss_test = np.mean(loss_test)\n",
    "    avg_acc_test = np.mean(acc_test)\n",
    "    writer.add_scalar('Loss/test', avg_loss_test, epoch)\n",
    "    writer.add_scalar('Accuracy/test', avg_acc_test, epoch)\n",
    "    print(f'Epoch: {epoch}\\tAverage Test Loss: {avg_loss_test:.6f}\\tAverage Test Accuracy: {avg_acc_test:.6f}')\n",
    "\n",
    "# clear cache\n",
    "torch.cuda.empty_cache()\n",
    "#torch.mps.empty_cache()\n",
    "features = None\n",
    "targets = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T06:50:39.861121299Z",
     "start_time": "2024-01-03T05:42:59.808007462Z"
    }
   },
   "id": "8375ff1459203cc2",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to AlexNet_v4_2024_01_03-12_42_59.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save the model checkpoint\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "VERSION = 4\n",
    "MODEL_NAME = f'AlexNet_v{VERSION}_{date_time}.ckpt'\n",
    "torch.save(model.state_dict(), os.path.join('models', MODEL_NAME))\n",
    "print(f'Saved PyTorch Model State to {MODEL_NAME}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T06:50:40.235899987Z",
     "start_time": "2024-01-03T06:50:39.860433708Z"
    }
   },
   "id": "5d4680b684d91c4e",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 98.77991661255646%\n"
     ]
    }
   ],
   "source": [
    "# Test the model load the model checkpoint\n",
    "model_loaded = AlexNet().to(device)\n",
    "\n",
    "# Load the model checkpoint\n",
    "model_loaded.load_state_dict(torch.load(os.path.join('models', MODEL_NAME)))\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model_loaded.eval()\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    acc_rate_lst = []\n",
    "    for features, targets in test_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits = model_loaded(features)\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        acc_rate = 100 * correct / total\n",
    "        writer.add_scalar('test accuracy', acc_rate, 0)\n",
    "        acc_rate_lst.append(acc_rate)\n",
    "\n",
    "    # average accuracy\n",
    "    avg_acc_rate = np.mean(acc_rate_lst)\n",
    "    print(f'Accuracy of the model on the test images: {avg_acc_rate}%')\n",
    "    \n",
    "features = None\n",
    "targets = None\n",
    "\n",
    "\n",
    "# Close the writer\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T06:50:52.838671909Z",
     "start_time": "2024-01-03T06:50:40.239561968Z"
    }
   },
   "id": "26bf759aa71e8e04",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released all variables\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model_loaded = None\n",
    "\n",
    "# release all loaders\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None\n",
    "\n",
    "# release all variables\n",
    "optimizer = None\n",
    "loss_fn = None\n",
    "accuracy = None\n",
    "\n",
    "# Clear cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print('Released all variables')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T06:50:52.853812235Z",
     "start_time": "2024-01-03T06:50:52.840538772Z"
    }
   },
   "id": "1fa78bb6c251d7c2",
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
