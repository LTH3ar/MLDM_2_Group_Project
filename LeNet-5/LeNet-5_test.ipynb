{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d2a3f2014bd2cc1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchmetrics import Accuracy\n",
    "from torchinfo import summary\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Setting up the device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7fbda54b585e3cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setting Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "683dbc9a19835f95",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Preparing the test_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e1ee151902d9175"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preparing Input Data\n",
    "# prepare the dataset MNIST(1x28x28) for LeNet\n",
    "param_transform = transforms.Compose([\n",
    "    transforms.Pad(2), # padding 2 pixels on each side\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.1307], std=[0.3081])  # Normalize to [-1, 1] range\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0832c7c80df6644",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "test_data = datasets.MNIST(\n",
    "    root='./dataset', \n",
    "    train=False, \n",
    "    transform=param_transform, \n",
    "    download=True)\n",
    "\n",
    "test_data_info = datasets.MNIST(\n",
    "    root='./dataset', \n",
    "    train=True,\n",
    "    download=False)\n",
    "print(\"MNIST dataset information:\")\n",
    "print(\" - Number of training samples: {}\".format(len(test_data_info)))\n",
    "print(\" - Number of test samples: {}\".format(len(test_data)))\n",
    "print(\" - Image Shape: {}\".format(test_data[0][0].shape))\n",
    "print(\" - Number of classes: {}\".format(len(test_data.classes)))\n",
    "print(\" - Samples number all classes: {}\".format(test_data.targets.bincount()))\n",
    "# info about the dataset\n",
    "print(test_data_info)\n",
    "\n",
    "# plot the train dataset samples count for each class\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.bar(test_data_info.classes, test_data_info.targets.bincount())\n",
    "plt.title('Train dataset samples count for each class')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Samples count')\n",
    "plt.savefig('train_dataset_samples_count.png')\n",
    "plt.show()\n",
    "\n",
    "# Dataset summary\n",
    "print('Test dataset:')\n",
    "print(' - Number of datapoints: {}'.format(len(test_data)))\n",
    "print(' - Image Shape: {}'.format(test_data[0][0].shape))\n",
    "print(' - Number of classes: {}'.format(len(test_data.classes)))\n",
    "print(\" - Samples number all classes: {}\".format(test_data.targets.bincount()))\n",
    "\n",
    "# plot the test dataset samples count for each class\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.bar(test_data.classes, test_data.targets.bincount())\n",
    "plt.title('Test dataset samples count for each class')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Samples count')\n",
    "plt.savefig('test_dataset_samples_count.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1a00d66cb86c92c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Dataset for visualization\n",
    "# get the 10 images from the test set for visualization\n",
    "vis_size = 10\n",
    "test_data_vis = torch.utils.data.Subset(test_data, range(vis_size))\n",
    "\n",
    "# Dataset summary\n",
    "print('Test dataset for visualization:')\n",
    "print(' - Number of datapoints: {}'.format(len(test_data_vis)))\n",
    "print(' - Image Shape: {}'.format(test_data_vis[0][0].shape))\n",
    "\n",
    "# loader\n",
    "test_loader_vis = DataLoader(test_data_vis, batch_size=vis_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33687e8221f2e0bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 128\n",
    "elif torch.backends.mps.is_available():\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 64\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Dataloader summary\n",
    "print('Test dataloader:')\n",
    "print(' - Number of batches: {}'.format(len(test_loader)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f17c02cc32e3e3ac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Loading the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "850d12ca1ef5d948"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Defining Model\n",
    "# LeNet-5 architecture implementation\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Feature extractor\n",
    "        self.feature = nn.Sequential(\n",
    "            # Convolutional layers\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # First conv layer\n",
    "            # input: 1 x 28 x 28 --> padding = 2 --> 1 x 32 x 32 --> 6 x 28 x 28\n",
    "            #nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            # activation function\n",
    "            nn.Tanh(),\n",
    "            # pooling layer 14 x 14\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # Second conv layer\n",
    "            # input: 6 x 14 x 14 --> 16 x 10 x 10\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            # activation function\n",
    "            nn.Tanh(),\n",
    "            # pooling layer 5 x 5\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            # ============================================================================== #\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Fully connected layers\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # First fc layer\n",
    "            # input: 16 x 5 x 5 = 400 --> 120\n",
    "            # flatten\n",
    "            nn.Flatten(),\n",
    "            # fc layer\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120),\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "            # ============================================================================== #\n",
    "\n",
    "            # ============================================================================== #\n",
    "            # Second fc layer\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # Third fc layer\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "            # ============================================================================== #\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    # Forward function\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f50ee3fa0bec292",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=10).to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1380f9ccb14480f4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Log the test\n",
    "date_time = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab78033ed9894490",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODE = \"multiple_tests\"\n",
    "if MODE == \"single_test\":\n",
    "    # Load the model\n",
    "    model = LeNet5().to(device)\n",
    "    print(model)\n",
    "    # Load the model weights\n",
    "    model_name = 'LeNet5_v1_2024_01_07-09_31_56.pth'\n",
    "    model.load_state_dict(torch.load(os.path.join('models', model_name), map_location=device))\n",
    "    # Model summary\n",
    "    # summary(model, input_size=(1, 1, 28, 28), verbose=2, device=device)\n",
    "    summary(model, input_size=(1, 1, 32, 32), verbose=2, device=device)\n",
    "    # Calculate model weights size\n",
    "    model_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'Model size: {model_size} parameters')\n",
    "    print('Model weights size: {:.2f} MB'.format(sum(p.numel() for p in model.parameters()) / (1024 * 1024)))\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Create the log directory\n",
    "    test_folder_name = f\"test_{model_name}_{date_time}\"\n",
    "    log_dir = os.path.join('test_logs', test_folder_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "elif MODE == \"multiple_tests\":\n",
    "    models_lst = os.listdir('models')\n",
    "    models_lst.sort()\n",
    "    print(models_lst)\n",
    "    # create the log directory\n",
    "    test_folder_name = f\"test_{date_time}\"\n",
    "    log_dir = os.path.join('test_logs', test_folder_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=log_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "effe2f732b3ca91a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Test the model\n",
    "y_true = []\n",
    "y_pred = []\n",
    "if MODE == \"single_test\":\n",
    "    with torch.no_grad():\n",
    "        loss_tmp = []\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            # Move the data to device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            # save the loss\n",
    "            loss_tmp.append(loss.item())\n",
    "\n",
    "            # save the true and predicted labels for confusion matrix\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "\n",
    "            # Print the loss and accuracy\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Test Batch {}/{}: Loss: {:.6f}'.format(\n",
    "                    batch_idx, len(test_loader), loss.item()))\n",
    "\n",
    "        # Calculate the average loss and accuracy\n",
    "        avg_loss = sum(loss_tmp) / len(loss_tmp)\n",
    "        # avg_acc using y_pred and y_true with accuracy\n",
    "        avg_acc = accuracy(torch.tensor(y_pred), torch.tensor(y_true)).item() * 100\n",
    "        print('Test: Average Loss: {:.6f}, Average Accuracy: {:.6f}'.format(avg_loss, avg_acc))\n",
    "        writer.add_scalar(tag=\"Accuracy\", scalar_value=avg_acc, global_step=0)\n",
    "        writer.add_scalar(tag=\"Loss\", scalar_value=avg_loss, global_step=0)\n",
    "elif MODE == \"multiple_tests\":\n",
    "    loss_lst = []\n",
    "    acc_lst = []\n",
    "    for model_name in models_lst:\n",
    "        # Load the model\n",
    "        model = LeNet5().to(device)\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(torch.load(os.path.join('models', model_name), map_location=device))\n",
    "        # Model summary\n",
    "        # summary(model, input_size=(1, 1, 28, 28), verbose=2, device=device)\n",
    "        summary(model, input_size=(1, 1, 32, 32), verbose=2, device=device)\n",
    "        # Calculate model weights size\n",
    "        model_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'Model size: {model_size} parameters')\n",
    "        print('Model weights size: {:.2f} MB'.format(sum(p.numel() for p in model.parameters()) / (1024 * 1024)))\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_tmp = []\n",
    "            y_true_tmp = []\n",
    "            y_pred_tmp = []\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Move the data to device\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                acc = accuracy(output, target)\n",
    "\n",
    "                # save the loss\n",
    "                loss_tmp.append(loss.item())\n",
    "\n",
    "                # save the true and predicted labels for confusion matrix\n",
    "                y_true_tmp.extend(target.cpu().numpy())\n",
    "                y_pred_tmp.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
    "\n",
    "                # Print the loss and accuracy\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print('Test Batch {}/{}: Loss: {:.6f}, Accuracy: {:.6f}'.format(\n",
    "                        batch_idx, len(test_loader), loss.item(), acc.item()))\n",
    "\n",
    "            # save the true and predicted labels for confusion matrix\n",
    "            y_true.append(y_true_tmp)\n",
    "            y_pred.append(y_pred_tmp)\n",
    "\n",
    "\n",
    "            # Calculate the average loss and accuracy\n",
    "            avg_loss = (sum(loss_tmp) / len(loss_tmp))\n",
    "            avg_acc = accuracy(torch.tensor(y_pred_tmp), torch.tensor(y_true_tmp)).item() * 100\n",
    "        print('Test: Average Loss: {:.6f}, Average Accuracy: {:.6f}'.format(avg_loss, avg_acc))\n",
    "        # for each model add the accuracy and loss to the tensorboard so that we can compare them like a line\n",
    "        acc_lst.append(avg_acc)\n",
    "        loss_lst.append(avg_loss)\n",
    "\n",
    "        # clean the GPU memory\n",
    "        # clear cache\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        elif torch.backends.mps.is_available():\n",
    "            torch.mps.empty_cache()\n",
    "        else:\n",
    "            torch.empty_cache()\n",
    "        # release the model from GPU memory\n",
    "        model = None\n",
    "\n",
    "    for i in range(len(models_lst)):\n",
    "        writer.add_scalar(tag=\"Accuracy\", scalar_value=acc_lst[i], global_step=int((i + 1) * 10))\n",
    "        writer.add_scalar(tag=\"Loss\", scalar_value=loss_lst[i], global_step=int((i + 1) * 10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18093e356e8ce545",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Confusion matrix all test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if MODE == \"single_test\":\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    # Classification report\n",
    "    print(classification_report(y_true, y_pred, target_names=test_data.classes))\n",
    "    # Plot the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.savefig(os.path.join(log_dir, 'confusion_matrix.png'))\n",
    "    plt.show()\n",
    "    with open(os.path.join(log_dir, 'classification_report.txt'), 'w') as f:\n",
    "        f.write(classification_report(y_true, y_pred, target_names=test_data.classes))\n",
    "elif MODE == \"multiple_tests\":\n",
    "    for i in range(len(models_lst)):\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true[i], y_pred[i])\n",
    "        print(cm)\n",
    "        # Classification report\n",
    "        print(classification_report(y_true[i], y_pred[i], target_names=test_data.classes))\n",
    "        # Plot the confusion matrix\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.savefig(os.path.join(log_dir, f'confusion_matrix_{models_lst[i]}.png'))\n",
    "        plt.show()\n",
    "        with open(os.path.join(log_dir, f'classification_report_{models_lst[i]}.txt'), 'w') as f:\n",
    "            f.write(classification_report(y_true[i], y_pred[i], target_names=test_data.classes))\n",
    "            f.write('\\n')\n",
    "            f.write('Confusion matrix:\\n')\n",
    "            f.write(str(cm))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aac017d28b6aa626",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the bar chart accuracy of models, V1, V2, V3, V4 (range 97-100%) add acc value to the top of the bar\n",
    "if MODE == \"multiple_tests\":\n",
    "    labels = ['V1', 'V2', 'V3', 'V4']\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(labels, acc_lst)\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_title('Accuracy of models')\n",
    "    ax.set_ylim([97, 100])\n",
    "    for i, v in enumerate(acc_lst):\n",
    "        ax.text(i - 0.1, v + 0.1, str(round(v, 2)), color='black', fontweight='bold')\n",
    "    plt.savefig(os.path.join(log_dir, 'accuracy_of_models.png'))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "624ef16d1078b69c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Close the writer\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "933039ffb09b144e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Release GPU memory cache\n",
    "# clear cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "else:\n",
    "    torch.empty_cache()\n",
    "\n",
    "# Release model from GPU memory\n",
    "model = None\n",
    "\n",
    "# release all loaded data\n",
    "data_vis = None\n",
    "target_vis = None\n",
    "data = None\n",
    "target = None\n",
    "data_loader = None\n",
    "data_loader_vis = None\n",
    "test_data = None\n",
    "test_data_vis = None\n",
    "test_loader = None\n",
    "test_loader_vis = None\n",
    "\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "246babdf15688305",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
