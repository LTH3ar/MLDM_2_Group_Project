{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2ceadb5fd0d01c3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchmetrics import Accuracy\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Setting Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a2c58e1a16e919"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setting Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df3edabffbb04506",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Preparing Input Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba8a02c3f56ede00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preparing Input Data\n",
    "# prepare the dataset MNIST(1x28x28) for LeNet\n",
    "param_transform = transforms.Compose([\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.1307], std=[0.3081])  # Normalize to [-1, 1] range\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb411009caf470c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "train_val_dataset = datasets.MNIST(root='./dataset', train=True, transform=param_transform, download=True)\n",
    "\n",
    "# Dataset summary\n",
    "print('train_val_dataset length:', len(train_val_dataset))\n",
    "print('train_val_dataset shape:', train_val_dataset[0][0].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd1be73a84cce511",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation\n",
    "train_size = int(0.8 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "# Dataset summary\n",
    "print('train_dataset length:', len(train_dataset))\n",
    "print('val_dataset length:', len(val_dataset))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "273bc621a4a0f7fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 128\n",
    "elif torch.backends.mps.is_available():\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# dataloaders summary\n",
    "print('train_loader length:', len(train_loader))\n",
    "print('val_loader length:', len(val_loader))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5049ff96154a5257",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Defining Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28fd785797f4ae14"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Defining Model\n",
    "# LeNet-5 architecture implementation\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Feature extractor\n",
    "        self.feature = nn.Sequential(\n",
    "            # Convolutional layers\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # First conv layer\n",
    "            # input: 1 x 28 x 28 --> padding = 2 --> 1 x 32 x 32 --> 6 x 28 x 28\n",
    "            #nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            # activation function\n",
    "            nn.Tanh(),\n",
    "            # pooling layer 14 x 14\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # Second conv layer\n",
    "            # input: 6 x 14 x 14 --> 16 x 10 x 10\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            # activation function\n",
    "            nn.Tanh(),\n",
    "            # pooling layer 5 x 5\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            # ============================================================================== #\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Fully connected layers\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # First fc layer\n",
    "            # input: 16 x 5 x 5 = 400 --> 120\n",
    "            # flatten\n",
    "            nn.Flatten(),\n",
    "            # fc layer\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120),\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "            # ============================================================================== #\n",
    "\n",
    "            # ============================================================================== #\n",
    "            # Second fc layer\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "            # ============================================================================== #\n",
    "            \n",
    "            # ============================================================================== #\n",
    "            # Third fc layer\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "            # ============================================================================== #\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    # Forward function\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a3fb55c77f5c9f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = LeNet5().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c38e8bcf5080383",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model summary\n",
    "# Detailed layer-wise summary\n",
    "#summary(model, input_size=(1, 1, 28, 28), verbose=2, device=device)\n",
    "summary(model, input_size=(1, 1, 32, 32), verbose=2, device=device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe84edf7c35a139b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=10).to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd7ed64aaca20e8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fed365ef49471e1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training\n",
    "# Log training process to TensorBoard\n",
    "date_time = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "log_dir = os.path.join('train_logs', date_time)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c78e1d31b2992e8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "NUM_EPOCHS = 40\n",
    "NUM_BATCHES = len(train_loader)\n",
    "NUM_BATCHES_VAL = len(val_loader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b61bff5fb0df2c4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "VERSION = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0dc84faf23b02df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "    y_pred_val = []\n",
    "    y_true_val = []\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "    epoch_count = epoch + 1\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        \n",
    "        # add y_pred and y_true\n",
    "        y_pred_train.append(output)\n",
    "        y_true_train.append(target)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # log training\n",
    "        print(f'Train Epoch: {epoch_count} [{batch_idx}/{NUM_BATCHES} ({100. * batch_idx / NUM_BATCHES:.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "    # Calculate average loss and accuracy over an epoch\n",
    "    avg_loss_train = loss_function(torch.cat(y_pred_train), torch.cat(y_true_train)).item()\n",
    "    avg_acc_train = accuracy(torch.cat(y_pred_train), torch.cat(y_true_train))*100\n",
    "    \n",
    "    print(f'Epoch: {epoch_count}\\tAverage Train Loss: {avg_loss_train:.6f}\\tAverage Train Accuracy: {avg_acc_train:.6f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # Move data to device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward\n",
    "            output = model(data)\n",
    "            \n",
    "            # add y_pred and y_true\n",
    "            y_pred_val.append(output)\n",
    "            y_true_val.append(target)\n",
    "\n",
    "            # log validation\n",
    "            print(f'Validation Epoch: {epoch_count} [{batch_idx}/{NUM_BATCHES_VAL} ({100. * batch_idx / NUM_BATCHES_VAL:.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "                \n",
    "    # Calculate average loss and accuracy over an epoch\n",
    "    avg_loss_val = loss_function(torch.cat(y_pred_val), torch.cat(y_true_val)).item()\n",
    "    avg_acc_val = accuracy(torch.cat(y_pred_val), torch.cat(y_true_val))*100\n",
    "    \n",
    "    print(f'Epoch: {epoch_count}\\tAverage Validation Loss: {avg_loss_val:.6f}\\tAverage Validation Accuracy: {avg_acc_val:.6f}')\n",
    "\n",
    "    # Log average loss and accuracy of an epoch \n",
    "    writer.add_scalars(main_tag='Accuracy train/validation', tag_scalar_dict={'TRAIN': avg_acc_train, 'VAL': avg_acc_val}, global_step=epoch_count)\n",
    "    writer.add_scalars(main_tag='Loss train/validation', tag_scalar_dict={'TRAIN': avg_loss_train, 'VAL': avg_loss_val}, global_step=epoch_count)\n",
    "    \n",
    "\n",
    "    if epoch_count % 10 == 0:\n",
    "        MODEL_NAME = f'LeNet5_v{VERSION}_{date_time}.pth'\n",
    "        torch.save(model.state_dict(), os.path.join('models', MODEL_NAME))\n",
    "        print(f'Saved PyTorch Model State to {MODEL_NAME}')\n",
    "        VERSION += 1\n",
    "        \n",
    "# clear cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "else:\n",
    "    torch.empty_cache()\n",
    "features = None\n",
    "targets = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87695106392bf66f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Close the writer\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec9270c256bcc7af",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = None\n",
    "model_loaded = None\n",
    "\n",
    "# release all loaders\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None\n",
    "\n",
    "# release all variables\n",
    "optimizer = None\n",
    "loss_fn = None\n",
    "accuracy = None\n",
    "\n",
    "print('Released all variables')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afbf7911c7ac0fad",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
