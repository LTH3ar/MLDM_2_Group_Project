{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "MNIST dataset preparation and analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c6d8cfba6ae9d5e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.361377Z",
     "start_time": "2023-12-30T03:37:42.333508Z"
    }
   },
   "id": "fe140334d5f735d7"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "train_val_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.399493Z",
     "start_time": "2023-12-30T03:37:42.340074Z"
    }
   },
   "id": "76255ea07b0d0c2"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "Class names: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "# Dataset summary\n",
    "print(\"Train/Validation dataset size:\", len(train_val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "\n",
    "class_names = train_val_dataset.classes\n",
    "print(\"Class names:\", class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.424319Z",
     "start_time": "2023-12-30T03:37:42.403107Z"
    }
   },
   "id": "2544bb767d509bdf"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 3 18 18 18 126 136 175 26 166 255 247 127 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 30 36 94 154 170 253 253 253 253 253 225 172 253 242 195 64 0 0 0 0 \n",
      "0 0 0 0 0 0 0 49 238 253 253 253 253 253 253 253 253 251 93 82 82 56 39 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 18 219 253 253 253 253 253 198 182 247 241 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 80 156 107 253 253 205 11 0 43 154 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 14 1 154 253 90 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 139 253 190 2 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 11 190 253 70 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 35 241 225 160 108 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 81 240 253 253 119 25 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 45 186 253 253 150 27 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 16 93 252 253 187 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 249 253 249 64 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 46 130 183 253 253 207 2 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 39 148 229 253 253 253 250 182 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 24 114 221 253 253 253 253 201 78 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 23 66 213 253 253 253 253 198 81 2 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 18 171 219 253 253 253 253 195 80 9 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 55 172 226 253 253 253 253 244 133 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 136 253 253 253 212 135 132 16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "# plot image with pixel values\n",
    "def img_pixel_superimpose(img):\n",
    "    img = img.numpy()\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(111)\n",
    "    w, h = img.shape\n",
    "    color_map = matplotlib.colormaps['gray_r']  # gray_reversed\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            color = color_map(img[x][y])\n",
    "            ax.annotate(str(img[x][y]), xy=(y,x), horizontalalignment='center', verticalalignment='center',\n",
    "                        color=color)\n",
    "            plt.axis(False)\n",
    "    plt.savefig(\"pixel_img.png\")\n",
    "    plt.show()\n",
    "\n",
    "def terminal_print(img):\n",
    "    img = img.numpy()\n",
    "    w, h = img.shape\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            print(img[x][y], end=\" \")\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "def csv_print(img):\n",
    "    img = img.numpy()\n",
    "    w, h = img.shape\n",
    "    with open(\"img.csv\", \"w\") as f:\n",
    "        for x in range(w):\n",
    "            for y in range(h):\n",
    "                f.write(str(img[x][y]) + \",\")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "img0 = train_val_dataset.data[0]\n",
    "# img_pixel_superimpose(img0)\n",
    "terminal_print(img0)\n",
    "# csv_print(img0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.424981Z",
     "start_time": "2023-12-30T03:37:42.411863Z"
    }
   },
   "id": "76f79b5e2931a776"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# convert the datasets into tensors\n",
    "transform = transforms.ToTensor()\n",
    "train_val_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.463501Z",
     "start_time": "2023-12-30T03:37:42.415614Z"
    }
   },
   "id": "2097a9432414ec9e"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.1307\n",
      "Std: 0.3081\n"
     ]
    }
   ],
   "source": [
    "# Data Normalization\n",
    "# Calculate mean and std\n",
    "#imgs = torch.stack([img for img, _ in train_val_dataset], dim=0)\n",
    "#mean = imgs.view(1, -1).mean(dim=1)    # or imgs.mean()\n",
    "mean = 0.1307\n",
    "#std = imgs.view(1, -1).std(dim=1)     # or imgs.std()\n",
    "std = 0.3081\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "# Composition of transforms\n",
    "mnist_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=mean, std=std)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.464184Z",
     "start_time": "2023-12-30T03:37:42.436596Z"
    }
   },
   "id": "34159b610268fdc0"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Apply transforms to datasets\n",
    "train_val_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True, transform=mnist_transforms)\n",
    "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=True, transform=mnist_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.487236Z",
     "start_time": "2023-12-30T03:37:42.440838Z"
    }
   },
   "id": "f94d8ea47718d811"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Split train and validation datasets\n",
    "train_size = int(0.9 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset=train_val_dataset, lengths=[train_size, val_size])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.487919Z",
     "start_time": "2023-12-30T03:37:42.468311Z"
    }
   },
   "id": "7b2ecbc68094df87"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 54000\n",
      "Validation dataset size: 6000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Dataset summary\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.488353Z",
     "start_time": "2023-12-30T03:37:42.476125Z"
    }
   },
   "id": "6faf5c15d95f286e"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Train dataloader size: 844\n",
      "Validation dataloader size: 94\n",
      "Test dataloader size: 157\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "# check memory available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# set batch size based on available memory\n",
    "BATCH_SIZE = 128 if device == \"cuda\" else 64\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Summary of dataloaders\n",
    "print(\"Train dataloader size:\", len(train_dataloader))\n",
    "print(\"Validation dataloader size:\", len(val_dataloader))\n",
    "print(\"Test dataloader size:\", len(test_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.512155Z",
     "start_time": "2023-12-30T03:37:42.480203Z"
    }
   },
   "id": "7245992420afb69b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LeNet-5 architecture implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2a5a20fc3c34952"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# LeNet-5 architecture implementation\n",
    "class LeNet5_V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Feature extractor\n",
    "        self.feature = nn.Sequential(\n",
    "            # Convolutional layers\n",
    "            # First conv layer\n",
    "            # input: 1 x 28 x 28 --> padding = 2 --> 1 x 32 x 32 --> 6 x 28 x 28\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
    "            # activation function\n",
    "            nn.Sigmoid(),\n",
    "            # pooling layer 14 x 14\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Second conv layer\n",
    "            # input: 6 x 14 x 14 --> 16 x 10 x 10\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            # activation function\n",
    "            nn.Sigmoid(),\n",
    "            # pooling layer 5 x 5\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Fully connected layers\n",
    "            # First fc layer\n",
    "            # input: 16 x 5 x 5 = 400 --> 120\n",
    "            # flatten\n",
    "            nn.Flatten(),\n",
    "            # fc layer\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120),\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "\n",
    "            # Second fc layer\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "\n",
    "            # Third fc layer\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.512887Z",
     "start_time": "2023-12-30T03:37:42.493518Z"
    }
   },
   "id": "271bab06acac5460"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5_V1(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (4): Sigmoid()\n",
      "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nLeNet5_V1                                [1, 10]                   --\n├─Sequential: 1-1                        [1, 16, 5, 5]             --\n│    └─Conv2d: 2-1                       [1, 6, 28, 28]            156\n│    └─Sigmoid: 2-2                      [1, 6, 28, 28]            --\n│    └─MaxPool2d: 2-3                    [1, 6, 14, 14]            --\n│    └─Conv2d: 2-4                       [1, 16, 10, 10]           2,416\n│    └─Sigmoid: 2-5                      [1, 16, 10, 10]           --\n│    └─MaxPool2d: 2-6                    [1, 16, 5, 5]             --\n├─Sequential: 1-2                        [1, 10]                   --\n│    └─Flatten: 2-7                      [1, 400]                  --\n│    └─Linear: 2-8                       [1, 120]                  48,120\n│    └─Sigmoid: 2-9                      [1, 120]                  --\n│    └─Linear: 2-10                      [1, 84]                   10,164\n│    └─Sigmoid: 2-11                     [1, 84]                   --\n│    └─Linear: 2-12                      [1, 10]                   850\n==========================================================================================\nTotal params: 61,706\nTrainable params: 61,706\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.42\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.05\nParams size (MB): 0.25\nEstimated Total Size (MB): 0.30\n=========================================================================================="
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model creation\n",
    "model_lenet5 = LeNet5_V1()\n",
    "print(model_lenet5)\n",
    "\n",
    "# move the model to the device\n",
    "model_lenet5.to(device)\n",
    "\n",
    "# Model summary\n",
    "summary(model=model_lenet5, input_size=(1, 1, 28, 28), device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.513635Z",
     "start_time": "2023-12-30T03:37:42.495932Z"
    }
   },
   "id": "35ca6ec406b1f368"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_lenet5.parameters(), lr=1e-3)\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.513948Z",
     "start_time": "2023-12-30T03:37:42.504714Z"
    }
   },
   "id": "95cfdbe9ac3cd902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c31163e3a6644870"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Training\n",
    "# Log Tracking use tensorboard to generate log dirs\n",
    "log_dir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:37:42.514242Z",
     "start_time": "2023-12-30T03:37:42.508402Z"
    }
   },
   "id": "39fc2dd50d9cf597"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/12] Batch 0/844 Loss 2.3801 Accuracy 0.0625\n",
      "Epoch [0/12] Batch 100/844 Loss 2.2940 Accuracy 0.0781\n",
      "Epoch [0/12] Batch 200/844 Loss 1.4097 Accuracy 0.6094\n",
      "Epoch [0/12] Batch 300/844 Loss 0.7941 Accuracy 0.8438\n",
      "Epoch [0/12] Batch 400/844 Loss 0.4350 Accuracy 0.9531\n",
      "Epoch [0/12] Batch 500/844 Loss 0.3340 Accuracy 0.9531\n",
      "Epoch [0/12] Batch 600/844 Loss 0.4450 Accuracy 0.8750\n",
      "Epoch [0/12] Batch 700/844 Loss 0.2204 Accuracy 0.9375\n",
      "Epoch [0/12] Batch 800/844 Loss 0.2410 Accuracy 0.9375\n",
      "Epoch [0/12] Batch 0/94 Loss 0.1123 Accuracy 0.9844\n",
      "Epoch [1/12] Batch 0/844 Loss 0.2014 Accuracy 0.9531\n",
      "Epoch [1/12] Batch 100/844 Loss 0.1246 Accuracy 0.9844\n",
      "Epoch [1/12] Batch 200/844 Loss 0.0538 Accuracy 1.0000\n",
      "Epoch [1/12] Batch 300/844 Loss 0.0629 Accuracy 0.9844\n",
      "Epoch [1/12] Batch 400/844 Loss 0.1972 Accuracy 0.9688\n",
      "Epoch [1/12] Batch 500/844 Loss 0.0839 Accuracy 1.0000\n",
      "Epoch [1/12] Batch 600/844 Loss 0.0815 Accuracy 0.9531\n",
      "Epoch [1/12] Batch 700/844 Loss 0.0552 Accuracy 0.9844\n",
      "Epoch [1/12] Batch 800/844 Loss 0.0961 Accuracy 0.9688\n",
      "Epoch [1/12] Batch 0/94 Loss 0.0898 Accuracy 0.9844\n",
      "Epoch [2/12] Batch 0/844 Loss 0.1851 Accuracy 0.9531\n",
      "Epoch [2/12] Batch 100/844 Loss 0.0339 Accuracy 1.0000\n",
      "Epoch [2/12] Batch 200/844 Loss 0.1779 Accuracy 0.9219\n",
      "Epoch [2/12] Batch 300/844 Loss 0.0757 Accuracy 0.9688\n",
      "Epoch [2/12] Batch 400/844 Loss 0.1161 Accuracy 0.9688\n",
      "Epoch [2/12] Batch 500/844 Loss 0.0370 Accuracy 1.0000\n",
      "Epoch [2/12] Batch 600/844 Loss 0.0506 Accuracy 0.9844\n",
      "Epoch [2/12] Batch 700/844 Loss 0.0606 Accuracy 0.9688\n",
      "Epoch [2/12] Batch 800/844 Loss 0.0656 Accuracy 0.9844\n",
      "Epoch [2/12] Batch 0/94 Loss 0.1375 Accuracy 0.9688\n",
      "Epoch [3/12] Batch 0/844 Loss 0.1079 Accuracy 0.9375\n",
      "Epoch [3/12] Batch 100/844 Loss 0.2223 Accuracy 0.9219\n",
      "Epoch [3/12] Batch 200/844 Loss 0.1206 Accuracy 0.9375\n",
      "Epoch [3/12] Batch 300/844 Loss 0.0329 Accuracy 1.0000\n",
      "Epoch [3/12] Batch 400/844 Loss 0.0649 Accuracy 0.9844\n",
      "Epoch [3/12] Batch 500/844 Loss 0.1263 Accuracy 0.9688\n",
      "Epoch [3/12] Batch 600/844 Loss 0.0485 Accuracy 0.9844\n",
      "Epoch [3/12] Batch 700/844 Loss 0.0328 Accuracy 1.0000\n",
      "Epoch [3/12] Batch 800/844 Loss 0.0570 Accuracy 0.9844\n",
      "Epoch [3/12] Batch 0/94 Loss 0.0879 Accuracy 0.9531\n",
      "Epoch [4/12] Batch 0/844 Loss 0.2472 Accuracy 0.8906\n",
      "Epoch [4/12] Batch 100/844 Loss 0.0824 Accuracy 0.9688\n",
      "Epoch [4/12] Batch 200/844 Loss 0.0315 Accuracy 0.9844\n",
      "Epoch [4/12] Batch 300/844 Loss 0.0567 Accuracy 0.9844\n",
      "Epoch [4/12] Batch 400/844 Loss 0.0357 Accuracy 1.0000\n",
      "Epoch [4/12] Batch 500/844 Loss 0.0693 Accuracy 0.9844\n",
      "Epoch [4/12] Batch 600/844 Loss 0.0428 Accuracy 0.9844\n",
      "Epoch [4/12] Batch 700/844 Loss 0.1071 Accuracy 0.9844\n",
      "Epoch [4/12] Batch 800/844 Loss 0.0947 Accuracy 0.9688\n",
      "Epoch [4/12] Batch 0/94 Loss 0.1650 Accuracy 0.9531\n",
      "Epoch [5/12] Batch 0/844 Loss 0.0460 Accuracy 0.9844\n",
      "Epoch [5/12] Batch 100/844 Loss 0.0826 Accuracy 0.9688\n",
      "Epoch [5/12] Batch 200/844 Loss 0.0565 Accuracy 0.9844\n",
      "Epoch [5/12] Batch 300/844 Loss 0.0232 Accuracy 1.0000\n",
      "Epoch [5/12] Batch 400/844 Loss 0.0103 Accuracy 1.0000\n",
      "Epoch [5/12] Batch 500/844 Loss 0.0019 Accuracy 1.0000\n",
      "Epoch [5/12] Batch 600/844 Loss 0.0057 Accuracy 1.0000\n",
      "Epoch [5/12] Batch 700/844 Loss 0.0471 Accuracy 0.9844\n",
      "Epoch [5/12] Batch 800/844 Loss 0.0900 Accuracy 0.9531\n",
      "Epoch [5/12] Batch 0/94 Loss 0.0880 Accuracy 0.9688\n",
      "Epoch [6/12] Batch 0/844 Loss 0.0081 Accuracy 1.0000\n",
      "Epoch [6/12] Batch 100/844 Loss 0.0399 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 200/844 Loss 0.0793 Accuracy 0.9688\n",
      "Epoch [6/12] Batch 300/844 Loss 0.1199 Accuracy 0.9688\n",
      "Epoch [6/12] Batch 400/844 Loss 0.0156 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 500/844 Loss 0.0240 Accuracy 1.0000\n",
      "Epoch [6/12] Batch 600/844 Loss 0.0584 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 700/844 Loss 0.1067 Accuracy 0.9688\n",
      "Epoch [6/12] Batch 800/844 Loss 0.0411 Accuracy 1.0000\n",
      "Epoch [6/12] Batch 0/94 Loss 0.0989 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 0/844 Loss 0.0170 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 100/844 Loss 0.0417 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 200/844 Loss 0.2034 Accuracy 0.9531\n",
      "Epoch [7/12] Batch 300/844 Loss 0.0223 Accuracy 1.0000\n",
      "Epoch [7/12] Batch 400/844 Loss 0.0026 Accuracy 1.0000\n",
      "Epoch [7/12] Batch 500/844 Loss 0.0324 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 600/844 Loss 0.0060 Accuracy 1.0000\n",
      "Epoch [7/12] Batch 700/844 Loss 0.0169 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 800/844 Loss 0.1723 Accuracy 0.9531\n",
      "Epoch [7/12] Batch 0/94 Loss 0.0488 Accuracy 0.9688\n",
      "Epoch [8/12] Batch 0/844 Loss 0.0045 Accuracy 1.0000\n",
      "Epoch [8/12] Batch 100/844 Loss 0.0217 Accuracy 1.0000\n",
      "Epoch [8/12] Batch 200/844 Loss 0.0032 Accuracy 1.0000\n",
      "Epoch [8/12] Batch 300/844 Loss 0.0159 Accuracy 1.0000\n",
      "Epoch [8/12] Batch 400/844 Loss 0.0909 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 500/844 Loss 0.0616 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 600/844 Loss 0.0049 Accuracy 1.0000\n",
      "Epoch [8/12] Batch 700/844 Loss 0.0560 Accuracy 0.9688\n",
      "Epoch [8/12] Batch 800/844 Loss 0.1125 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 0/94 Loss 0.0453 Accuracy 0.9844\n",
      "Epoch [9/12] Batch 0/844 Loss 0.0100 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 100/844 Loss 0.1123 Accuracy 0.9688\n",
      "Epoch [9/12] Batch 200/844 Loss 0.0057 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 300/844 Loss 0.0105 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 400/844 Loss 0.0203 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 500/844 Loss 0.0211 Accuracy 0.9844\n",
      "Epoch [9/12] Batch 600/844 Loss 0.0082 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 700/844 Loss 0.0082 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 800/844 Loss 0.0813 Accuracy 0.9688\n",
      "Epoch [9/12] Batch 0/94 Loss 0.0671 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 0/844 Loss 0.0567 Accuracy 0.9688\n",
      "Epoch [10/12] Batch 100/844 Loss 0.0232 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 200/844 Loss 0.0084 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 300/844 Loss 0.0603 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 400/844 Loss 0.0553 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 500/844 Loss 0.0073 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 600/844 Loss 0.0221 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 700/844 Loss 0.0696 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 800/844 Loss 0.0011 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 0/94 Loss 0.0036 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 0/844 Loss 0.0433 Accuracy 0.9688\n",
      "Epoch [11/12] Batch 100/844 Loss 0.0326 Accuracy 0.9844\n",
      "Epoch [11/12] Batch 200/844 Loss 0.0131 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 300/844 Loss 0.0031 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 400/844 Loss 0.0011 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 500/844 Loss 0.0646 Accuracy 0.9844\n",
      "Epoch [11/12] Batch 600/844 Loss 0.0053 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 700/844 Loss 0.0117 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 800/844 Loss 0.0841 Accuracy 0.9531\n",
      "Epoch [11/12] Batch 0/94 Loss 0.0621 Accuracy 0.9688\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "EPOCHS = 12\n",
    "for epoch in range(EPOCHS):\n",
    "    # training phase\n",
    "    model_lenet5.train()\n",
    "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
    "        # move data to device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        scores = model_lenet5(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc = accuracy(scores, targets)\n",
    "\n",
    "        # print\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{EPOCHS}] Batch {batch_idx}/{len(train_dataloader)} Loss {loss:.4f} Accuracy {acc:.4f}\")\n",
    "\n",
    "            # write to tensorboard\n",
    "            step = epoch * len(train_dataloader) + batch_idx\n",
    "            writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "            writer.add_scalar(\"Training accuracy\", acc, global_step=step)\n",
    "\n",
    "    # validation phase\n",
    "    model_lenet5.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(val_dataloader):\n",
    "            # move data to device\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward\n",
    "            scores = model_lenet5(data)\n",
    "            loss = loss_fn(scores, targets)\n",
    "\n",
    "            # calculate accuracy\n",
    "            acc = accuracy(scores, targets)\n",
    "\n",
    "            # print\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{EPOCHS}] Batch {batch_idx}/{len(val_dataloader)} Loss {loss:.4f} Accuracy {acc:.4f}\")\n",
    "\n",
    "                # write to tensorboard\n",
    "                step = epoch * len(val_dataloader) + batch_idx\n",
    "                writer.add_scalar(\"Validation loss\", loss, global_step=step)\n",
    "                writer.add_scalar(\"Validation accuracy\", acc, global_step=step)\n",
    "              \n",
    "writer.flush()  \n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:41:12.744926Z",
     "start_time": "2023-12-30T03:37:42.514828Z"
    }
   },
   "id": "dec2ba73b2651eda"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Save the model\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "num = 1\n",
    "model_filename = f\"LeNet-5_original_v{num}.pth\"\n",
    "torch.save(model_lenet5.state_dict(), os.path.join(\"models\", model_filename))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:41:12.753796Z",
     "start_time": "2023-12-30T03:41:12.746731Z"
    }
   },
   "id": "712503dfb42e9a09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cee4a1fa30e5974f"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "LeNet5_V1(\n  (feature): Sequential(\n    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): Sigmoid()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n    (4): Sigmoid()\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=400, out_features=120, bias=True)\n    (2): Sigmoid()\n    (3): Linear(in_features=120, out_features=84, bias=True)\n    (4): Sigmoid()\n    (5): Linear(in_features=84, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_lenet5_loaded = LeNet5_V1()\n",
    "model_lenet5_loaded.load_state_dict(torch.load(os.path.join(\"models\", \"lenet5.pth\")))\n",
    "model_lenet5_loaded.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:41:12.758360Z",
     "start_time": "2023-12-30T03:41:12.751213Z"
    }
   },
   "id": "e1b71d31bea794f5"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/157 Loss 0.0108 Accuracy 1.0000\n",
      "Batch 100/157 Loss 0.0263 Accuracy 0.9844\n"
     ]
    }
   ],
   "source": [
    "model_lenet5_loaded.eval()\n",
    "\n",
    "# test phase\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, targets) in enumerate(test_dataloader):\n",
    "        # move data to device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        scores = model_lenet5_loaded(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc = accuracy(scores, targets)\n",
    "\n",
    "        # print\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(test_dataloader)} Loss {loss:.4f} Accuracy {acc:.4f}\")\n",
    "\n",
    "        test_loss += loss\n",
    "        test_acc += acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T03:41:13.802472Z",
     "start_time": "2023-12-30T03:41:12.758629Z"
    }
   },
   "id": "be89d885d6c6366d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
