{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "MNIST dataset preparation and analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c6d8cfba6ae9d5e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:08.875249Z",
     "start_time": "2023-12-30T06:34:02.152567Z"
    }
   },
   "id": "fe140334d5f735d7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "train_val_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:08.941095Z",
     "start_time": "2023-12-30T06:34:08.876049Z"
    }
   },
   "id": "76255ea07b0d0c2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "Class names: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "# Dataset summary\n",
    "print(\"Train/Validation dataset size:\", len(train_val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "\n",
    "class_names = train_val_dataset.classes\n",
    "print(\"Class names:\", class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:08.947196Z",
     "start_time": "2023-12-30T06:34:08.942145Z"
    }
   },
   "id": "2544bb767d509bdf"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 3 18 18 18 126 136 175 26 166 255 247 127 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 30 36 94 154 170 253 253 253 253 253 225 172 253 242 195 64 0 0 0 0 \n",
      "0 0 0 0 0 0 0 49 238 253 253 253 253 253 253 253 253 251 93 82 82 56 39 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 18 219 253 253 253 253 253 198 182 247 241 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 80 156 107 253 253 205 11 0 43 154 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 14 1 154 253 90 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 139 253 190 2 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 11 190 253 70 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 35 241 225 160 108 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 81 240 253 253 119 25 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 45 186 253 253 150 27 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 16 93 252 253 187 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 249 253 249 64 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 46 130 183 253 253 207 2 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 39 148 229 253 253 253 250 182 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 24 114 221 253 253 253 253 201 78 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 23 66 213 253 253 253 253 198 81 2 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 18 171 219 253 253 253 253 195 80 9 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 55 172 226 253 253 253 253 244 133 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 136 253 253 253 212 135 132 16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "# plot image with pixel values\n",
    "def img_pixel_superimpose(img):\n",
    "    img = img.numpy()\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(111)\n",
    "    w, h = img.shape\n",
    "    color_map = matplotlib.colormaps['gray_r']  # gray_reversed\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            color = color_map(img[x][y])\n",
    "            ax.annotate(str(img[x][y]), xy=(y,x), horizontalalignment='center', verticalalignment='center',\n",
    "                        color=color)\n",
    "            plt.axis(False)\n",
    "    plt.savefig(\"pixel_img.png\")\n",
    "    plt.show()\n",
    "\n",
    "def terminal_print(img):\n",
    "    img = img.numpy()\n",
    "    w, h = img.shape\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            print(img[x][y], end=\" \")\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "def csv_print(img):\n",
    "    img = img.numpy()\n",
    "    w, h = img.shape\n",
    "    with open(\"img.csv\", \"w\") as f:\n",
    "        for x in range(w):\n",
    "            for y in range(h):\n",
    "                f.write(str(img[x][y]) + \",\")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "img0 = train_val_dataset.data[0]\n",
    "# img_pixel_superimpose(img0)\n",
    "terminal_print(img0)\n",
    "# csv_print(img0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:08.956022Z",
     "start_time": "2023-12-30T06:34:08.951772Z"
    }
   },
   "id": "76f79b5e2931a776"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# convert the datasets into tensors\n",
    "transform = transforms.ToTensor()\n",
    "train_val_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.058493Z",
     "start_time": "2023-12-30T06:34:08.957491Z"
    }
   },
   "id": "2097a9432414ec9e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.1307\n",
      "Std: 0.3081\n"
     ]
    }
   ],
   "source": [
    "# Data Normalization\n",
    "# Calculate mean and std\n",
    "#imgs = torch.stack([img for img, _ in train_val_dataset], dim=0)\n",
    "#mean = imgs.view(1, -1).mean(dim=1)    # or imgs.mean()\n",
    "mean = 0.1307\n",
    "#std = imgs.view(1, -1).std(dim=1)     # or imgs.std()\n",
    "std = 0.3081\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "# Composition of transforms\n",
    "mnist_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=mean, std=std)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.059593Z",
     "start_time": "2023-12-30T06:34:09.007554Z"
    }
   },
   "id": "34159b610268fdc0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Apply transforms to datasets\n",
    "train_val_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True, transform=mnist_transforms)\n",
    "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=True, transform=mnist_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.083522Z",
     "start_time": "2023-12-30T06:34:09.012594Z"
    }
   },
   "id": "f94d8ea47718d811"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Split train and validation datasets\n",
    "train_size = int(0.9 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset=train_val_dataset, lengths=[train_size, val_size])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.084079Z",
     "start_time": "2023-12-30T06:34:09.061792Z"
    }
   },
   "id": "7b2ecbc68094df87"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 54000\n",
      "Validation dataset size: 6000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Dataset summary\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.084557Z",
     "start_time": "2023-12-30T06:34:09.070209Z"
    }
   },
   "id": "6faf5c15d95f286e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Train dataloader size: 844\n",
      "Validation dataloader size: 94\n",
      "Test dataloader size: 157\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "# check memory available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# set batch size based on available memory\n",
    "BATCH_SIZE = 128 if device == \"cuda\" else 64\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Summary of dataloaders\n",
    "print(\"Train dataloader size:\", len(train_dataloader))\n",
    "print(\"Validation dataloader size:\", len(val_dataloader))\n",
    "print(\"Test dataloader size:\", len(test_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.084950Z",
     "start_time": "2023-12-30T06:34:09.074770Z"
    }
   },
   "id": "7245992420afb69b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LeNet-5 architecture implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2a5a20fc3c34952"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# LeNet-5 architecture implementation\n",
    "class LeNet5_V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Feature extractor\n",
    "        self.feature = nn.Sequential(\n",
    "            # Convolutional layers\n",
    "            # First conv layer\n",
    "            # input: 1 x 28 x 28 --> padding = 2 --> 1 x 32 x 32 --> 6 x 28 x 28\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
    "            # activation function\n",
    "            nn.Sigmoid(),\n",
    "            # pooling layer 14 x 14\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Second conv layer\n",
    "            # input: 6 x 14 x 14 --> 16 x 10 x 10\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            # activation function\n",
    "            nn.Sigmoid(),\n",
    "            # pooling layer 5 x 5\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Fully connected layers\n",
    "            # First fc layer\n",
    "            # input: 16 x 5 x 5 = 400 --> 120\n",
    "            # flatten\n",
    "            nn.Flatten(),\n",
    "            # fc layer\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120),\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "\n",
    "            # Second fc layer\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "\n",
    "            # activation function\n",
    "            nn.Sigmoid(), # sigmoid\n",
    "\n",
    "            # Third fc layer\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.085285Z",
     "start_time": "2023-12-30T06:34:09.077722Z"
    }
   },
   "id": "271bab06acac5460"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5_V1(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Sigmoid()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (4): Sigmoid()\n",
      "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nLeNet5_V1                                [1, 10]                   --\n├─Sequential: 1-1                        [1, 16, 5, 5]             --\n│    └─Conv2d: 2-1                       [1, 6, 28, 28]            156\n│    └─Sigmoid: 2-2                      [1, 6, 28, 28]            --\n│    └─AvgPool2d: 2-3                    [1, 6, 14, 14]            --\n│    └─Conv2d: 2-4                       [1, 16, 10, 10]           2,416\n│    └─Sigmoid: 2-5                      [1, 16, 10, 10]           --\n│    └─AvgPool2d: 2-6                    [1, 16, 5, 5]             --\n├─Sequential: 1-2                        [1, 10]                   --\n│    └─Flatten: 2-7                      [1, 400]                  --\n│    └─Linear: 2-8                       [1, 120]                  48,120\n│    └─Sigmoid: 2-9                      [1, 120]                  --\n│    └─Linear: 2-10                      [1, 84]                   10,164\n│    └─Sigmoid: 2-11                     [1, 84]                   --\n│    └─Linear: 2-12                      [1, 10]                   850\n==========================================================================================\nTotal params: 61,706\nTrainable params: 61,706\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.42\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.05\nParams size (MB): 0.25\nEstimated Total Size (MB): 0.30\n=========================================================================================="
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model creation\n",
    "model_lenet5 = LeNet5_V1()\n",
    "print(model_lenet5)\n",
    "\n",
    "# move the model to the device\n",
    "model_lenet5.to(device)\n",
    "\n",
    "# Model summary\n",
    "summary(model=model_lenet5, input_size=(1, 1, 28, 28), device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.138955Z",
     "start_time": "2023-12-30T06:34:09.084246Z"
    }
   },
   "id": "35ca6ec406b1f368"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_lenet5.parameters(), lr=1e-3)\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.139449Z",
     "start_time": "2023-12-30T06:34:09.108686Z"
    }
   },
   "id": "95cfdbe9ac3cd902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c31163e3a6644870"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Training\n",
    "# Log Tracking use tensorboard to generate log dirs\n",
    "log_dir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:34:09.139864Z",
     "start_time": "2023-12-30T06:34:09.114758Z"
    }
   },
   "id": "39fc2dd50d9cf597"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/12] Batch 0/844 Loss 2.3796 Accuracy 0.0625\n",
      "Epoch [0/12] Batch 100/844 Loss 2.2677 Accuracy 0.1719\n",
      "Epoch [0/12] Batch 200/844 Loss 1.5034 Accuracy 0.5625\n",
      "Epoch [0/12] Batch 300/844 Loss 0.9353 Accuracy 0.8125\n",
      "Epoch [0/12] Batch 400/844 Loss 0.5573 Accuracy 0.8750\n",
      "Epoch [0/12] Batch 500/844 Loss 0.4329 Accuracy 0.8906\n",
      "Epoch [0/12] Batch 600/844 Loss 0.3068 Accuracy 0.9375\n",
      "Epoch [0/12] Batch 700/844 Loss 0.2818 Accuracy 0.9219\n",
      "Epoch [0/12] Batch 800/844 Loss 0.4311 Accuracy 0.8750\n",
      "Epoch [0/12] Batch 0/94 Loss 0.3167 Accuracy 0.9219\n",
      "Epoch [1/12] Batch 0/844 Loss 0.3086 Accuracy 0.8906\n",
      "Epoch [1/12] Batch 100/844 Loss 0.3100 Accuracy 0.9219\n",
      "Epoch [1/12] Batch 200/844 Loss 0.2918 Accuracy 0.9219\n",
      "Epoch [1/12] Batch 300/844 Loss 0.3059 Accuracy 0.9062\n",
      "Epoch [1/12] Batch 400/844 Loss 0.1597 Accuracy 0.9688\n",
      "Epoch [1/12] Batch 500/844 Loss 0.2353 Accuracy 0.9219\n",
      "Epoch [1/12] Batch 600/844 Loss 0.1025 Accuracy 0.9844\n",
      "Epoch [1/12] Batch 700/844 Loss 0.1863 Accuracy 0.9219\n",
      "Epoch [1/12] Batch 800/844 Loss 0.1640 Accuracy 0.9688\n",
      "Epoch [1/12] Batch 0/94 Loss 0.1723 Accuracy 0.9531\n",
      "Epoch [2/12] Batch 0/844 Loss 0.2362 Accuracy 0.9062\n",
      "Epoch [2/12] Batch 100/844 Loss 0.1004 Accuracy 0.9688\n",
      "Epoch [2/12] Batch 200/844 Loss 0.1643 Accuracy 0.9219\n",
      "Epoch [2/12] Batch 300/844 Loss 0.1895 Accuracy 0.9375\n",
      "Epoch [2/12] Batch 400/844 Loss 0.2892 Accuracy 0.9219\n",
      "Epoch [2/12] Batch 500/844 Loss 0.0844 Accuracy 0.9688\n",
      "Epoch [2/12] Batch 600/844 Loss 0.1199 Accuracy 0.9688\n",
      "Epoch [2/12] Batch 700/844 Loss 0.2421 Accuracy 0.9375\n",
      "Epoch [2/12] Batch 800/844 Loss 0.1655 Accuracy 0.9375\n",
      "Epoch [2/12] Batch 0/94 Loss 0.1735 Accuracy 0.9375\n",
      "Epoch [3/12] Batch 0/844 Loss 0.3351 Accuracy 0.9219\n",
      "Epoch [3/12] Batch 100/844 Loss 0.2061 Accuracy 0.9688\n",
      "Epoch [3/12] Batch 200/844 Loss 0.1825 Accuracy 0.9375\n",
      "Epoch [3/12] Batch 300/844 Loss 0.0462 Accuracy 1.0000\n",
      "Epoch [3/12] Batch 400/844 Loss 0.2114 Accuracy 0.9219\n",
      "Epoch [3/12] Batch 500/844 Loss 0.1312 Accuracy 0.9531\n",
      "Epoch [3/12] Batch 600/844 Loss 0.0804 Accuracy 0.9844\n",
      "Epoch [3/12] Batch 700/844 Loss 0.1256 Accuracy 0.9531\n",
      "Epoch [3/12] Batch 800/844 Loss 0.1056 Accuracy 0.9688\n",
      "Epoch [3/12] Batch 0/94 Loss 0.1477 Accuracy 0.9531\n",
      "Epoch [4/12] Batch 0/844 Loss 0.1813 Accuracy 0.9219\n",
      "Epoch [4/12] Batch 100/844 Loss 0.0741 Accuracy 0.9688\n",
      "Epoch [4/12] Batch 200/844 Loss 0.0285 Accuracy 1.0000\n",
      "Epoch [4/12] Batch 300/844 Loss 0.1438 Accuracy 0.9062\n",
      "Epoch [4/12] Batch 400/844 Loss 0.0118 Accuracy 1.0000\n",
      "Epoch [4/12] Batch 500/844 Loss 0.1918 Accuracy 0.9531\n",
      "Epoch [4/12] Batch 600/844 Loss 0.1558 Accuracy 0.9531\n",
      "Epoch [4/12] Batch 700/844 Loss 0.0839 Accuracy 0.9688\n",
      "Epoch [4/12] Batch 800/844 Loss 0.0432 Accuracy 1.0000\n",
      "Epoch [4/12] Batch 0/94 Loss 0.0471 Accuracy 1.0000\n",
      "Epoch [5/12] Batch 0/844 Loss 0.0267 Accuracy 1.0000\n",
      "Epoch [5/12] Batch 100/844 Loss 0.1552 Accuracy 0.9688\n",
      "Epoch [5/12] Batch 200/844 Loss 0.0667 Accuracy 0.9688\n",
      "Epoch [5/12] Batch 300/844 Loss 0.0149 Accuracy 1.0000\n",
      "Epoch [5/12] Batch 400/844 Loss 0.1957 Accuracy 0.9688\n",
      "Epoch [5/12] Batch 500/844 Loss 0.1222 Accuracy 0.9375\n",
      "Epoch [5/12] Batch 600/844 Loss 0.1245 Accuracy 0.9531\n",
      "Epoch [5/12] Batch 700/844 Loss 0.0927 Accuracy 0.9688\n",
      "Epoch [5/12] Batch 800/844 Loss 0.0817 Accuracy 0.9688\n",
      "Epoch [5/12] Batch 0/94 Loss 0.0184 Accuracy 1.0000\n",
      "Epoch [6/12] Batch 0/844 Loss 0.0460 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 100/844 Loss 0.0344 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 200/844 Loss 0.0620 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 300/844 Loss 0.0997 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 400/844 Loss 0.2089 Accuracy 0.9219\n",
      "Epoch [6/12] Batch 500/844 Loss 0.0414 Accuracy 0.9844\n",
      "Epoch [6/12] Batch 600/844 Loss 0.1200 Accuracy 0.9688\n",
      "Epoch [6/12] Batch 700/844 Loss 0.0863 Accuracy 0.9688\n",
      "Epoch [6/12] Batch 800/844 Loss 0.1060 Accuracy 0.9375\n",
      "Epoch [6/12] Batch 0/94 Loss 0.1102 Accuracy 0.9688\n",
      "Epoch [7/12] Batch 0/844 Loss 0.0311 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 100/844 Loss 0.0878 Accuracy 0.9688\n",
      "Epoch [7/12] Batch 200/844 Loss 0.0477 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 300/844 Loss 0.0356 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 400/844 Loss 0.0219 Accuracy 1.0000\n",
      "Epoch [7/12] Batch 500/844 Loss 0.0302 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 600/844 Loss 0.0356 Accuracy 0.9844\n",
      "Epoch [7/12] Batch 700/844 Loss 0.0247 Accuracy 1.0000\n",
      "Epoch [7/12] Batch 800/844 Loss 0.1762 Accuracy 0.9375\n",
      "Epoch [7/12] Batch 0/94 Loss 0.0482 Accuracy 0.9688\n",
      "Epoch [8/12] Batch 0/844 Loss 0.0127 Accuracy 1.0000\n",
      "Epoch [8/12] Batch 100/844 Loss 0.0360 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 200/844 Loss 0.0231 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 300/844 Loss 0.0955 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 400/844 Loss 0.0243 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 500/844 Loss 0.0312 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 600/844 Loss 0.0342 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 700/844 Loss 0.0718 Accuracy 0.9844\n",
      "Epoch [8/12] Batch 800/844 Loss 0.0173 Accuracy 1.0000\n",
      "Epoch [8/12] Batch 0/94 Loss 0.1220 Accuracy 0.9531\n",
      "Epoch [9/12] Batch 0/844 Loss 0.0523 Accuracy 0.9688\n",
      "Epoch [9/12] Batch 100/844 Loss 0.0202 Accuracy 0.9844\n",
      "Epoch [9/12] Batch 200/844 Loss 0.0648 Accuracy 0.9844\n",
      "Epoch [9/12] Batch 300/844 Loss 0.0433 Accuracy 0.9688\n",
      "Epoch [9/12] Batch 400/844 Loss 0.0043 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 500/844 Loss 0.0138 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 600/844 Loss 0.0055 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 700/844 Loss 0.0345 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 800/844 Loss 0.0144 Accuracy 1.0000\n",
      "Epoch [9/12] Batch 0/94 Loss 0.0219 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 0/844 Loss 0.0295 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 100/844 Loss 0.0092 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 200/844 Loss 0.0261 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 300/844 Loss 0.0047 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 400/844 Loss 0.0486 Accuracy 0.9844\n",
      "Epoch [10/12] Batch 500/844 Loss 0.0884 Accuracy 0.9688\n",
      "Epoch [10/12] Batch 600/844 Loss 0.0177 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 700/844 Loss 0.0107 Accuracy 1.0000\n",
      "Epoch [10/12] Batch 800/844 Loss 0.1382 Accuracy 0.9688\n",
      "Epoch [10/12] Batch 0/94 Loss 0.0085 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 0/844 Loss 0.0285 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 100/844 Loss 0.0794 Accuracy 0.9531\n",
      "Epoch [11/12] Batch 200/844 Loss 0.0306 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 300/844 Loss 0.0472 Accuracy 0.9844\n",
      "Epoch [11/12] Batch 400/844 Loss 0.0466 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 500/844 Loss 0.0869 Accuracy 0.9688\n",
      "Epoch [11/12] Batch 600/844 Loss 0.0861 Accuracy 0.9844\n",
      "Epoch [11/12] Batch 700/844 Loss 0.0390 Accuracy 0.9844\n",
      "Epoch [11/12] Batch 800/844 Loss 0.0161 Accuracy 1.0000\n",
      "Epoch [11/12] Batch 0/94 Loss 0.0222 Accuracy 0.9844\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "EPOCHS = 12\n",
    "for epoch in range(EPOCHS):\n",
    "    # training phase\n",
    "    model_lenet5.train()\n",
    "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
    "        # move data to device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        scores = model_lenet5(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc = accuracy(scores, targets)\n",
    "\n",
    "        # print\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{EPOCHS}] Batch {batch_idx}/{len(train_dataloader)} Loss {loss:.4f} Accuracy {acc:.4f}\")\n",
    "\n",
    "            # write to tensorboard\n",
    "            step = epoch * len(train_dataloader) + batch_idx\n",
    "            writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "            writer.add_scalar(\"Training accuracy\", acc, global_step=step)\n",
    "\n",
    "    # validation phase\n",
    "    model_lenet5.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(val_dataloader):\n",
    "            # move data to device\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward\n",
    "            scores = model_lenet5(data)\n",
    "            loss = loss_fn(scores, targets)\n",
    "\n",
    "            # calculate accuracy\n",
    "            acc = accuracy(scores, targets)\n",
    "\n",
    "            # print\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{EPOCHS}] Batch {batch_idx}/{len(val_dataloader)} Loss {loss:.4f} Accuracy {acc:.4f}\")\n",
    "\n",
    "                # write to tensorboard\n",
    "                step = epoch * len(val_dataloader) + batch_idx\n",
    "                writer.add_scalar(\"Validation loss\", loss, global_step=step)\n",
    "                writer.add_scalar(\"Validation accuracy\", acc, global_step=step)\n",
    "              \n",
    "writer.flush()  \n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:36:58.136826Z",
     "start_time": "2023-12-30T06:34:09.117595Z"
    }
   },
   "id": "dec2ba73b2651eda"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Save the model\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "num = 2\n",
    "model_filename = f\"LeNet-5_original_v{num}.pth\"\n",
    "torch.save(model_lenet5.state_dict(), os.path.join(\"models\", model_filename))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:36:58.142513Z",
     "start_time": "2023-12-30T06:36:58.140523Z"
    }
   },
   "id": "712503dfb42e9a09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cee4a1fa30e5974f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "LeNet5_V1(\n  (feature): Sequential(\n    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): Sigmoid()\n    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n    (4): Sigmoid()\n    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=400, out_features=120, bias=True)\n    (2): Sigmoid()\n    (3): Linear(in_features=120, out_features=84, bias=True)\n    (4): Sigmoid()\n    (5): Linear(in_features=84, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_lenet5_loaded = LeNet5_V1()\n",
    "model_lenet5_loaded.load_state_dict(torch.load(os.path.join(\"models\", model_filename)))\n",
    "model_lenet5_loaded.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:36:58.152264Z",
     "start_time": "2023-12-30T06:36:58.147708Z"
    }
   },
   "id": "e1b71d31bea794f5"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/157 Loss 0.0124 Accuracy 1.0000\n",
      "Batch 100/157 Loss 0.0173 Accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_lenet5_loaded.eval()\n",
    "\n",
    "# test phase\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, targets) in enumerate(test_dataloader):\n",
    "        # move data to device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        scores = model_lenet5_loaded(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc = accuracy(scores, targets)\n",
    "\n",
    "        # print\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(test_dataloader)} Loss {loss:.4f} Accuracy {acc:.4f}\")\n",
    "\n",
    "        test_loss += loss\n",
    "        test_acc += acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:36:58.828947Z",
     "start_time": "2023-12-30T06:36:58.153379Z"
    }
   },
   "id": "be89d885d6c6366d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
